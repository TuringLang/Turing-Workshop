{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=Turing.jl=\n",
    "===========\n",
    "\n",
    "**Author:** Tor Erlend Fjelde\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you're in the correct directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T21:42:20.260000Z",
     "start_time": "2023-01-25T21:42:12.045Z"
    }
   },
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run something like (depending on which OS you are on)\n",
    "\n",
    "or if you're already in a REPL, do\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T21:42:50.870000Z",
     "start_time": "2023-01-25T21:42:50.249Z"
    }
   },
   "outputs": [],
   "source": [
    "]activate ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to activate the project\n",
    "\n",
    "And just to check that you're in the correct one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T21:42:54.581000Z",
     "start_time": "2023-01-25T21:42:52.165Z"
    }
   },
   "outputs": [],
   "source": [
    "]status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and install dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, do\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeiloWinterSchool2023Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get some functionality I've implemented for the occasion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The story of a little Norwegian boy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There once was a little Norwegian boy\n",
    "\n",
    "![img](.notes/attachments/A_litle_Norwegian_boy/2023-01-18_14-49-24_471337_3317365246956_1262712540_o.jpg)\n",
    "\n",
    "When this little boy was 20 years old, he was working as a parking guard near Preikestolen/Pulpit rock\n",
    "\n",
    "![img](.notes/attachments/A_litle_Norwegian_boy/2023-01-18_14-57-08_Preikestolen-plateau-Go-Fjords-Bob-Engelsen-P1026771_kljg5o.jpeg)\n",
    "\n",
    "One day it was raining and there was nobody hiking, and so there was no cars in sight for the little boy to point\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "When his boss wasn't looking, the little 20 year-old boy had an amazing idea\n",
    "\n",
    "> Maybe I can use this method of Mr. Bayes I learned a bit about yesteday to model football / Premier League?#+HTML: </div>\n",
    "\n",
    "The little boy got very excited and started looking for stuff on the big interwebs\n",
    "\n",
    "The little boy came across this\n",
    "\n",
    "![img](.notes/attachments/A_litle_Norwegian_boy/2023-01-18_14-46-02_Screenshot_20230118_144454.png)\n",
    "\n",
    "And got <u>very</u> excited\n",
    "\n",
    "But at the time, the little boy knew next to <u>nothing</u> about programming\n",
    "\n",
    "The little boy couldn't write the code to do the inference\n",
    "\n",
    "Whence the little boy became a <u>sad</u> little boy :(\n",
    "\n",
    "But time heals all wounds, and at some point the little boy learned Python\n",
    "\n",
    "And in Python, the boy found the *probabilistic programming language* `pymc3`\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "> Maybe I can use `pymc3` to perform inference in that football / Premier League model?And so the sad boy once more became an <u>excited</u> little boy :)\n",
    "\n",
    "</div>\n",
    "\n",
    "But there was a problem\n",
    "\n",
    "The boy wanted to write a for-loop in his model, but the model didn't want it to be so and complained!\n",
    "\n",
    "The boy got frustrated and gave up, once more becoming a <u>sad</u> little boy :(\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n",
    "The boy should have known that the computational backend `theano` that was used by `pymc3` at the time couldn't handle a for-loop, and instead he should have used `scan`. But the boy was only 20-something years old; he didn't know.\n",
    "\n",
    "</div>\n",
    "\n",
    "Some years later the boy discovers a programming language called <u>Julia</u>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Julia makes a few promises\n",
    "\n",
    "1.  It's fast. Like *really* fast.\n",
    "2.  It's interactive; doesn't require full compilation for you to play with it.\n",
    "3.  You don't have to specify types everywhere.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "The boy thinks\n",
    "\n",
    "> Wait, but this sounds like Python but the only difference is that&#x2026;I CAN WRITE FOR-LOOPS WITHOUT FEELING BAD ABOUT IT?!Yes, yes he could\n",
    "\n",
    "And 3.5 years later, he's still writing for-loops. Well, sort of.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Turing.jl?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duh, you should use Turing.jl <u>so you get to use Julia</u>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "But even in Julia, other PPLS exist\n",
    "\n",
    "But Turing.jl is very similar to Julia in \"philosophy\":\n",
    "\n",
    "-   Flexiblility\n",
    "-   Ease-of-use\n",
    "-   Speed (potentially with a bit of effort)\n",
    "\n",
    "So it's a pretty good candidate\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with an outbreak of influenza A (H1N1) in 1978 at a British boarding school\n",
    "\n",
    "-   763 male students -> 512 of which became ill\n",
    "-   Reported that one infected boy started the epidemic\n",
    "-   Observations are number of boys in bed over 14 days\n",
    "\n",
    "Data are freely available in the R package `outbreaks`, maintained as part of the [R Epidemics Consortium](http://www.repidemicsconsortium.org/)\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Data + part of the analysis is *heavily* inspired by [https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html](https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html)\n",
    "\n",
    "Stan definitively beats Turing.jl when it comes to great write-ups like these\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into Julia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe.\n",
    "using Dates\n",
    "using DataFrames, CSV\n",
    "\n",
    "N = 763\n",
    "data = DataFrame(CSV.File(joinpath(\"data\", \"influenza_england_1978_school.csv\")));\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each of the columns have associated types\n",
    "\n",
    "Let's visualize the samples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StatsPlots.jl provides this convenient macro `@df` for plotting a `DataFrame`.\n",
    "@df data scatter(:date, :in_bed, label=nothing, ylabel=\"Number of students in bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential equations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have some function $f$ which describes how a state $x$ evolves wrt. $t$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\mathrm{d} x}{\\mathrm{d} t} = f(x, t)\n",
    "\\end{equation*}\n",
    "\n",
    "which we then need to integrate to obtain the actual state at some time $t$\n",
    "\n",
    "\\begin{equation*}\n",
    "x(t) = \\int_{0}^{t} \\frac{\\mathrm{d} x}{\\mathrm{d} t} \\mathrm{d} t = \\int_{0}^{t} f(x, t) \\mathrm{d} t\n",
    "\\end{equation*}\n",
    "\n",
    "In many interesting scenarios numerical methods are required to obtain $x(t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Julia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything related to differential equations is provided by [`DifferentialEquations.jl`](https://docs.sciml.ai/DiffEqDocs/stable/)\n",
    "\n",
    "And I really do mean [*everything*](https://docs.sciml.ai/DiffEqDocs/stable/)\n",
    "\n",
    "<div class=\"side-by-side\">\n",
    "\n",
    "![img](.notes/attachments/Differential_equations/2023-01-19_19-48-23_Screenshot_20230119_194737.png)\n",
    "\n",
    "![img](.notes/attachments/Differential_equations/2023-01-19_19-48-41_Screenshot_20230119_194838.png)\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: SIR model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One particular example of an (ordinary) differential equation that you might have seen recently is the **SIR model** used in epidemiology\n",
    "\n",
    "![img](.notes/attachments/Differential_equations/2023-01-19_19-56-00_sir_illu.png \"[https://covid19.uclaml.org/model.html>](https://covid19.uclaml.org/model.html>)(2023-01-19)\")\n",
    "\n",
    "The temporal dynamics of the sizes of each of the compartments are governed by the following system of ODEs:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  \\frac{\\mathrm{d} S}{\\mathrm{d} t} &= - \\beta S \\frac{I}{N} \\\\\n",
    "  \\frac{\\mathrm{d} I}{\\mathrm{d} t} &= \\beta S \\frac{I}{N} - \\gamma I \\\\\n",
    "  \\frac{\\mathrm{d} R}{\\mathrm{d} t} &= \\gamma I\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "\n",
    "-   $S(t)$ is the number of people susceptible to becoming infected,\n",
    "-   $I(t)$ is the number of people currently infected,\n",
    "-   $R(t)$ is the number of recovered people,\n",
    "-   $β$ is the constant rate of infectious contact between people,\n",
    "-   $\\gamma$ the constant recovery rate of infected individuals\n",
    "\n",
    "Converting this ODE into code is just\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DifferentialEquations\n",
    "\n",
    "function SIR!(\n",
    "    du,  # buffer for the updated differential equation\n",
    "    u,   # current state\n",
    "    p,   # parameters\n",
    "    t    # current time\n",
    ")\n",
    "    N = 763  # population\n",
    "    S, I, R = u\n",
    "    β, γ = p\n",
    "\n",
    "    du[1] = dS = -β * I * S / N\n",
    "    du[2] = dI = β * I * S / N - γ * I\n",
    "    du[3] = dR = γ * I\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad!\n",
    "\n",
    "Initial conditions are then\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  S(0) &= N - 1 \\\\\n",
    "  I(0) &= 1 \\\\\n",
    "  R(0) &= 0\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "and we want to integrate from $t = 0$ to $t = 14$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include 0 because that's the initial condition before any observations.\n",
    "tspan = (0.0, 14.0)\n",
    "\n",
    "# Initial conditions are:\n",
    "#   S(0) = N - 1; I(0) = 1; R(0) = 0\n",
    "u0 = [N - 1, 1, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to define the overall problem and we can solve:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check that everything works, we'll just use some \"totally random\" values for β and γ:\n",
    "problem_sir = let β = 2.0, γ = 0.6\n",
    "    ODEProblem(SIR!, u0, tspan, (β, γ))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve(problem_sir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't specify a solver\n",
    "\n",
    "DifferentialEquations.jl uses `AutoTsit5(Rosenbrock32())` by default \n",
    "\n",
    "Which is a composition between\n",
    "\n",
    "-   `Tsit5` (4th order Runge-Kutta), and\n",
    "-   `Rosenbrock32` (3rd order stiff solver)\n",
    "\n",
    "with automatic switching between the two\n",
    "\n",
    "`AutoTsit5(Rosenbrock32())` covers many use-cases well, but see\n",
    "\n",
    "-   [https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/](https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/)\n",
    "-   [https://www.stochasticlifestyle.com/comparison-differential-equation-solver-suites-matlab-r-julia-python-c-fortran/](https://www.stochasticlifestyle.com/comparison-differential-equation-solver-suites-matlab-r-julia-python-c-fortran/)\n",
    "\n",
    "for more info on choosing a solver\n",
    "\n",
    "This is the resulting solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    sol,\n",
    "    linewidth=2, xaxis=\"Time in days\", label=[\"Suspectible\" \"Infected\" \"Recovered\"],\n",
    "    alpha=0.5, size=(500, 300)\n",
    ")\n",
    "scatter!(1:14, data.in_bed, label=\"Data\", color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't really match the data though; let's do better\n",
    "\n",
    "Approach #1: find optimal values of $\\beta$ and $\\gamma$ by minimizing some loss, e.g. sum-of-squares\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ell(\\beta, \\gamma) = \\sum_{i = 1}^{14} \\bigg( F(u_0, t_i;\\ \\beta, \\gamma) - y_i \\bigg)^2\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\big( y_i \\big)_{i = 1}^{14}$ are the observations, $F$ is the integrated system\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "First we define the loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function.\n",
    "function loss_sir(problem_orig, p)\n",
    "    # `remake` just, well, remakes the `problem` with `p` replaced.\n",
    "    problem = remake(problem_orig, p=p)\n",
    "    # To ensure we get solutions _exactly_ at the timesteps of interest,\n",
    "    # i.e. every day we have observations, we use `saveat=1` to tell `solve`\n",
    "    # to save at every timestep (which is one day).\n",
    "    sol = solve(problem, saveat=1)\n",
    "    # Extract the 2nd state, the (I)infected, for the dates with observations.\n",
    "    sol_for_observed = sol[2, 2:15]\n",
    "    # Compute the sum-of-squares of the infected vs. data.\n",
    "    sum(abs2.(sol_for_observed - data.in_bed))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "And the go-to for optimization in Julia is [Optim.jl](https://julianlsolvers.github.io/Optim.jl/stable/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "# An alternative to writing `y -> f(x, y)` is `Base.Fix1(f, x)` which\n",
    "# avoids potential performance issues with global variables (as our `problem` here).\n",
    "opt = optimize(\n",
    "    p -> loss_sir(problem_sir, p), # function to minimize\n",
    "    [0, 0],                # lower bounds on variables\n",
    "    [Inf, Inf],            # upper bounds on variables\n",
    "    [2.0, 0.5],            # initial values\n",
    "    Fminbox(NelderMead())  # optimization alg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the minimizers of the loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β, λ = Optim.minimizer(opt)\n",
    "β, λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for the obtained parameters.\n",
    "problem = remake(problem_sir, p=(β, λ))\n",
    "sol = solve(problem_sir)\n",
    "\n",
    "# Plot the solution.\n",
    "plot(sol, linewidth=2, xaxis=\"Time in days\", label=[\"Suspectible\" \"Infected\" \"Recovered\"], alpha=0.5)\n",
    "# And the data.\n",
    "scatter!(1:14, data.in_bed, label=\"Data\", color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better than our *totally* \"random\" guess from earlier!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: SEIR model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding another compartment to our SIR model: the <u>(E)xposed</u> state\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  \\frac{\\mathrm{d} S}{\\mathrm{d} t} &= - \\beta S \\frac{I}{N} \\\\\n",
    "  \\frac{\\mathrm{d} {\\color{blue} E}}{\\mathrm{d} t} &= \\beta S \\frac{I}{N} - {\\color{orange} \\sigma} {\\color{blue} E} \\\\\n",
    "  \\frac{\\mathrm{d} I}{\\mathrm{d} t} &= {\\color{orange} \\sigma} {\\color{blue} E} - \\gamma I \\\\\n",
    "  \\frac{\\mathrm{d} R}{\\mathrm{d} t} &= \\gamma I\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "where we've added a new parameter ${\\color{orange} \\sigma}$ describing the fraction of people who develop observable symptoms in this time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK Solve the SEIR model using Julia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SEIR!(\n",
    "    du,  # buffer for the updated differential equation\n",
    "    u,   # current state\n",
    "    p,   # parameters\n",
    "    t    # current time\n",
    ")\n",
    "    N = 763  # population\n",
    "\n",
    "    S, E, I, R = u  # have ourselves an additional state!\n",
    "    β, γ, σ = p     # and an additional parameter!\n",
    "\n",
    "    # TODO: Implement yah fool!\n",
    "    du[1] = nothing\n",
    "    du[2] = nothing\n",
    "    du[3] = nothing\n",
    "    du[4] = nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS:** Use `Optim.jl` to find minimizers of sum-of-squares\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION Solve the SEIR model using Julia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SEIR!(\n",
    "    du,  # buffer for the updated differential equation\n",
    "    u,   # current state\n",
    "    p,   # parameters\n",
    "    t    # current time\n",
    ")\n",
    "    N = 763  # population\n",
    "    S, E, I, R = u  # have ourselves an additional state!\n",
    "    β, γ, σ = p     # and an additional parameter!\n",
    "\n",
    "    # Might as well cache these computations.\n",
    "    βSI = β * S * I / N\n",
    "    σE = σ * E\n",
    "    γI = γ * I\n",
    "\n",
    "    du[1] = -βSI\n",
    "    du[2] = βSI - σE\n",
    "    du[3] = σE - γI\n",
    "    du[4] = γI\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_seir = let u0 = [N - 1, 0, 1, 0], β = 2.0, γ = 0.6, σ = 0.8\n",
    "    ODEProblem(SEIR!, u0, tspan, (β, γ, σ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_seir = solve(problem_seir, saveat=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sol_seir, linewidth=2, xaxis=\"Time in days\", label=[\"Suspectible\" \"Exposed\" \"Infected\" \"Recovered\"], alpha=0.5)\n",
    "scatter!(1:14, data.in_bed, label=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't look so good. Let's try Optim.jl again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_seir(problem, p)\n",
    "    problem = remake(problem, p=p)\n",
    "    sol = solve(problem, saveat=1)\n",
    "    # NOTE: 3rd state is now the (I)nfectious compartment!!!\n",
    "    sol_for_observed = sol[3, 2:15]\n",
    "    return sum(abs2.(sol_for_observed - data.in_bed))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimize(Base.Fix1(loss_seir, problem_seir), [0, 0, 0], [Inf, Inf, Inf], [2.0, 0.5, 0.9], Fminbox(NelderMead()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β, γ, σ = Optim.minimizer(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_seir = solve(remake(problem_seir, p=(β, γ, σ)), saveat=1)\n",
    "plot(sol_seir, linewidth=2, xaxis=\"Time in days\", label=[\"Suspectible\" \"Exposed\" \"Infected\" \"Recovered\"], alpha=0.5)\n",
    "scatter!(1:14, data.in_bed, label=\"Data\", color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But&#x2026;but these are <u>point estimates</u>! What about distributions? WHAT ABOUT UNCERTAINTY?!No, no that's fair.\n",
    "\n",
    "Let's do some Bayesian inference then.\n",
    "\n",
    "BUT FIRST!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our future selves less annoyed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's annoying to have all these different loss-functions for *both* `SIR!` and `SEIR!`\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract type which we can use to dispatch on.\n",
    "abstract type AbstractEpidemicProblem end\n",
    "\n",
    "struct SIRProblem{P} <: AbstractEpidemicProblem\n",
    "    problem::P\n",
    "    N::Int\n",
    "end\n",
    "\n",
    "function SIRProblem(N::Int; u0 = [N - 1, 1, 0.], tspan = (0, 14), p = [2.0, 0.6])\n",
    "    return SIRProblem(ODEProblem(SIR!, u0, tspan, p), N)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can just construct the problem as\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sir = SIRProblem(N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "And to make it a bit easier to work with, we add some utility functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General.\n",
    "parameters(prob::AbstractEpidemicProblem) = prob.problem.p\n",
    "initial_state(prob::AbstractEpidemicProblem) = prob.problem.u0\n",
    "population(prob::AbstractEpidemicProblem) = prob.N\n",
    "\n",
    "# Specializations.\n",
    "susceptible(::SIRProblem, u::AbstractMatrix) = u[1, :]\n",
    "infected(::SIRProblem, u::AbstractMatrix) = u[2, :]\n",
    "recovered(::SIRProblem, u::AbstractMatrix) = u[3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that once we've solved the problem, we can easily extract the compartment we want, e.g.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve(sir.problem, saveat=1)\n",
    "infected(sir, sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK Implement `SEIRProblem`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SEIRProblem <: AbstractEpidemicProblem\n",
    "    # ...\n",
    "end\n",
    "\n",
    "function SEIRProblem end\n",
    "\n",
    "susceptible\n",
    "exposed\n",
    "infected\n",
    "recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION Implement `SEIRProblem`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SEIRProblem{P} <: AbstractEpidemicProblem\n",
    "    problem::P\n",
    "    N::Int\n",
    "end\n",
    "\n",
    "function SEIRProblem(N::Int; u0 = [N - 1, 0, 1, 0.], tspan = (0, 14), p = [4.5, 0.45, 0.8])\n",
    "    return SEIRProblem(ODEProblem(SEIR!, u0, tspan, p), N)\n",
    "end\n",
    "\n",
    "susceptible(::SEIRProblem, u::AbstractMatrix) = u[1, :]\n",
    "exposed(::SEIRProblem, u::AbstractMatrix) = u[2, :]\n",
    "infected(::SEIRProblem, u::AbstractMatrix) = u[3, :]\n",
    "recovered(::SEIRProblem, u::AbstractMatrix) = u[4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given a `problem` and a `sol`, we can query the `sol` for the `infected` state without explicit handling of which `problem` we're working with\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seir = SEIRProblem(N);\n",
    "sol = solve(seir.problem, saveat=1)\n",
    "infected(seir, sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same `loss` for both!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(problem_wrapper::AbstractEpidemicProblem, p)\n",
    "    # NOTE: Extract the `problem` from `problem_wrapper`.\n",
    "    problem = remake(problem_wrapper.problem, p=p)\n",
    "    sol = solve(problem, saveat=1)\n",
    "    # NOTE: Now this is completely general!\n",
    "    sol_for_observed = infected(problem_wrapper, sol)[2:end]\n",
    "    return sum(abs2.(sol_for_observed - data.in_bed))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the same `loss` for both `SIR` and `SEIR`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(SIRProblem(N), [2.0, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(SEIRProblem(N), [2.0, 0.6, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset really doesn't have too many observations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So reporting a single number for parameters is maybe being a *bit* too confident\n",
    "\n",
    "We'll use the following model\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  \\beta &\\sim \\mathcal{N}_{ + }(2, 1) \\\\\n",
    "  \\gamma &\\sim \\mathcal{N}_{ + }(0.4, 0.5) \\\\\n",
    "  \\phi^{-1} &\\sim \\mathrm{Exponential}(1/5) \\\\\n",
    "   y_i &\\sim \\mathrm{NegativeBinomial2}\\big(F(u_0, t_i;\\ \\beta, \\gamma), \\phi \\big)\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "where \n",
    "\n",
    "-   $\\big( y_i \\big)_{i = 1}^{14}$ are the observations,\n",
    "-   $F$ is the integrated system, and\n",
    "-   $\\phi$ is the over-dispersion parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    plot(truncated(Normal(2, 1); lower=0), label=nothing, title=\"β\"),\n",
    "    plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title=\"γ\"),\n",
    "    plot(Exponential(1/5), label=nothing, title=\"ϕ⁻¹\"),\n",
    "    layout=(3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `NegativeBinomial(r, p)` represents the number of trials to achieve $r$ successes, where each trial has a probability $p$ of success\n",
    "\n",
    "A `NegativeBinomial2(μ, ϕ)` is the same, but parameterized using the mean $μ$ and *dispersion* $\\phi$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `NegativeBinomial` already exists, so let's just make an alternative constructor instead.\n",
    "function NegativeBinomial2(μ, ϕ)\n",
    "    p = 1/(1 + μ/ϕ)\n",
    "    r = ϕ\n",
    "    return NegativeBinomial(r, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure we didn't do something stupid.\n",
    "μ = 2; ϕ = 3;\n",
    "dist = NegativeBinomial2(μ, ϕ)\n",
    "# Source: https://mc-stan.org/docs/2_20/functions-reference/nbalt.html\n",
    "mean(dist) ≈ μ && var(dist) ≈ μ + μ^2 / ϕ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be considered a generalization of `Poisson`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = 2.0\n",
    "anim = @animate for ϕ ∈ [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 25.0, 100.0]\n",
    "    p = plot(size=(500, 300))\n",
    "    plot!(p, Poisson(μ); label=\"Poisson($μ)\")\n",
    "    plot!(p, NegativeBinomial2(μ, ϕ), label=\"NegativeBinomial2($μ, $ϕ)\")\n",
    "    xlims!(0, 20); ylims!(0, 0.35);\n",
    "    p\n",
    "end\n",
    "gif(anim, \"negative_binomial.gif\", fps=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./negative_binomial.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function sir_model(\n",
    "    num_days;                                  # Number of days to model\n",
    "    tspan = (0.0, float(num_days)),            # Timespan to model\n",
    "    u0 = [N - 1, 1, 0.0],                      # Initial state\n",
    "    p0 = [2.0, 0.6],                           # Placeholder parameters\n",
    "    problem = ODEProblem(SIR!, u0, tspan, p0)  # Create problem once so we can `remake`.\n",
    ")\n",
    "    β ~ truncated(Normal(2, 1); lower=0)\n",
    "    γ ~ truncated(Normal(0.4, 0.5); lower=0)\n",
    "    ϕ⁻¹ ~ Exponential(1/5)\n",
    "    ϕ = inv(ϕ⁻¹)\n",
    "\n",
    "    problem_new = remake(problem, p=[β, γ])  # Replace parameters `p`.\n",
    "    sol = solve(problem_new, saveat=1)       # Solve!\n",
    "\n",
    "    sol_for_observed = sol[2, 2:num_days + 1]  # Timesteps we have observations for.\n",
    "    in_bed = Vector{Int}(undef, num_days)\n",
    "    for i = 1:length(sol_for_observed)\n",
    "        # Add a small constant to `sol_for_observed` to make things more stable.\n",
    "        in_bed[i] ~ NegativeBinomial2(sol_for_observed[i] + 1e-5, ϕ)\n",
    "    end\n",
    "\n",
    "    # Some quantities we might be interested in.\n",
    "    return (R0 = β / γ, recovery_time = 1 / γ, infected = sol_for_observed)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break it down\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β ~ truncated(Normal(2, 1); lower=0)\n",
    "γ ~ truncated(Normal(0.4, 0.5); lower=0)\n",
    "ϕ⁻¹ ~ Exponential(1/5)\n",
    "ϕ = inv(ϕ⁻¹)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defines our prior\n",
    "\n",
    "`truncated` is just a way of restricting the domain of the distribution you pass it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_new = remake(problem, p=[β, γ])  # Replace parameters `p`.\n",
    "sol = solve(problem_new, saveat=1)       # Solve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then remake the problem, now with the parameters `[β, γ]` sampled above\n",
    "\n",
    "`saveat = 1` gets us the solution at the timesteps `[0, 1, 2, ..., 14]`\n",
    "\n",
    "Then we extract the timesteps we have observations for\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_for_observed = sol[2, 2:num_days + 1]  # Timesteps we have observations for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and define what's going to be a likelihood (once we add observations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bed = Vector{Int}(undef, num_days)\n",
    "for i = 1:length(sol_for_observed)\n",
    "    # Add a small constant to `sol_for_observed` to make things more stable.\n",
    "    in_bed[i] ~ NegativeBinomial2(sol_for_observed[i] + 1e-5, ϕ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we return some values that might be of interest to\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some quantities we might be interested in.\n",
    "return (R0 = β / γ, recovery_time = 1 / γ, infected = sol_for_observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful for a post-sampling diagnostics, debugging, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sir_model(length(data.in_bed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is just another function, so we can call it to check that it works\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model().infected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, it does!\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the prior reasonable?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any inference, we should check if the prior is reasonable\n",
    "\n",
    "From domain knowledge we know that (for influenza at least)\n",
    "\n",
    "-   $R_0$ is typically between 1 and 2\n",
    "-   `recovery_time` ($1 / \\gamma$) is usually ~1 week\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "We want to make sure that your prior belief reflects this knowledge while still being flexible enough to accommodate the observations\n",
    "\n",
    "</div>\n",
    "\n",
    "To check this we'll just simulate some draws from our prior model, i.e. the model *without* conditioning on `in_bed`\n",
    "\n",
    "There are two ways to sample form the prior\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. By just calling the `model`, which returns a `NamedTuple` containing the quantities of interest\n",
    "print(model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Or by just calling `sample` using `Prior`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from prior.\n",
    "chain_prior = sample(model, Prior(), 10_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the prior predictive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(legend=false, size=(600, 300))\n",
    "plot_trajectories!(p, group(chain_prior, :in_bed); n = 1000)\n",
    "hline!([N], color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain values we get number of infected *larger* than the actual population\n",
    "\n",
    "But this is includes the randomness from `NegativeBinomial2` likelihood\n",
    "\n",
    "Maybe more useful to inspect the (I)nfected state from the ODE solution?\n",
    "\n",
    "We can also look at the `generated_quantities`, i.e. the values from the `return` statement in our model\n",
    "\n",
    "Our `return` looked like this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some quantities we might be interested in.\n",
    "return (R0 = β / γ, recovery_time = 1 / γ, infected = sol_for_observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so `generated_quantities` (conditioned on `chain_prior`) gives us\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantities_prior = generated_quantities(\n",
    "    model,\n",
    "    MCMCChains.get_sections(chain_prior, :parameters)\n",
    ")\n",
    "print(quantities_prior[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert it into a `Chains` using a utility function of mine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to `Chains`.\n",
    "chain_quantities_prior = to_chains(quantities_prior);\n",
    "\n",
    "# Plot.\n",
    "p = plot(legend=false, size=(600, 300))\n",
    "plot_trajectories!(p, group(chain_quantities_prior, :infected); n = 1000)\n",
    "hline!([N], color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"x-small-text\">\n",
    "\n",
    "**NOTE:** `to_chains` is not part of \"official\" Turing.jl because the `return` can contain *whatever* you want, and so it's not always possible to convert into a `Chains`\n",
    "\n",
    "</div>\n",
    "\n",
    "And the quantiles for the trajectories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(legend=false, size=(600, 300))\n",
    "plot_trajectory_quantiles!(p, group(chain_quantities_prior, :infected))\n",
    "hline!(p, [N], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(quantile(chain_quantities_prior[:, [:R0, :recovery_time], :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to our prior knowledge of $R_0 \\in [1, 2]$ and $(1/\\gamma) \\approx 1$ for influenza\n",
    "\n",
    "Do we really need probability mass on $R_0 \\ge 10$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK What's wrong with the current prior?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"side-by-side\">\n",
    "\n",
    "<div style=\"margin: auto;\">\n",
    "\n",
    "The SIR model\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  \\frac{\\mathrm{d} S}{\\mathrm{d} t} &= - \\beta S \\frac{I}{N} \\\\\n",
    "  \\frac{\\mathrm{d} I}{\\mathrm{d} t} &= \\beta S \\frac{I}{N} - \\gamma I \\\\\n",
    "  \\frac{\\mathrm{d} R}{\\mathrm{d} t} &= \\gamma I\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "And here's the current priors\n",
    "\n",
    "<div class=\"x-small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    plot(truncated(Normal(2, 1); lower=0), label=nothing, title=\"β\"),\n",
    "    plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title=\"γ\"),\n",
    "    plot(Exponential(1/5), label=nothing, title=\"ϕ⁻¹\"),\n",
    "    layout=(3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION Recovery time shouldn't be several years\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned that `recovery_time`, which is expressed as $1 / \\gamma$, is ~1 week\n",
    "\n",
    "We're clearly putting high probability on regions near 0, i.e. *long* recovery times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title=\"γ\", size=(500, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Should probably be putting less probability mass near 0</u>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION ${\\color{red} \\gamma}$ should not be larger than 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "  \\frac{\\mathrm{d} S}{\\mathrm{d} t} &= - \\beta S \\frac{I}{N} \\\\\n",
    "  \\frac{\\mathrm{d} I}{\\mathrm{d} t} &= \\beta S \\frac{I}{N} - {\\color{red} \\gamma I} \\\\\n",
    "  \\frac{\\mathrm{d} R}{\\mathrm{d} t} &= {\\color{red} \\gamma I}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "If ${\\color{red} \\gamma} > 1$ ⟹ (R)ecovered increase by *more* than the (I)nfected\n",
    "\n",
    "⟹ <u>healthy people are recovering</u>\n",
    "\n",
    "Now, I'm no epidemiologist, but that doesn't seem right\n",
    "\n",
    "Maybe something like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Beta(2, 5), label=\"new\", size=(500, 300))\n",
    "plot!(truncated(Normal(0.4, 0.5); lower=0), label=\"old\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [X] Bounded at 1\n",
    "-   [X] Allows smaller values (i.e. longer recovery time) but rapidly decreases near zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION What if ${\\color{red} \\beta} > N$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for $t = 0$ we have\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\mathrm{d} S}{\\mathrm{d} t} \\bigg|_{t = 0} = - {\\color{red} \\beta} S \\frac{I}{N} > - N (N - 1) \\frac{1}{N} = - (N - 1)\n",
    "\\end{equation*}\n",
    "\n",
    "i.e. we *immediately* infect everyone on the very first time-step\n",
    "\n",
    "Also doesn't seem very realistic\n",
    "\n",
    "*But* under our current prior does this matter?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ℙ(β > N) = 1 - ℙ(β ≤ N)\n",
    "1 - cdf(truncated(Normal(2, 1); lower=0), N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better yet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(truncated(Normal(2, 1); lower=0), 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. 95% of the probability mass falls below ~3.65\n",
    "\n",
    "⟹ <u>Current prior for $\\beta$ seems fine (✓)</u>\n",
    "\n",
    "Before we change the prior, let's also make it a bit easier to change the prior using `@submodel`\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "`@submodel` allows you call models within models, e.g.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function A()\n",
    "    x_hidden_from_B ~ Normal()\n",
    "    x = x_hidden_from_B + 100\n",
    "    return x\n",
    "end\n",
    "\n",
    "@model function B()\n",
    "    @submodel x = A()\n",
    "    y ~ Normal(x, 1)\n",
    "\n",
    "    return (; x, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So if we call `B` we only see `x` and `y`\n",
    "println(B()())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While if we sample from `B` we get the latent variables\n",
    "println(rand(B()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "To avoid clashes of variable-names, we can specify a `prefix`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model A() = (x ~ Normal(); return x + 100)\n",
    "\n",
    "@model function B()\n",
    "    # Given it a prefix to use for the variables in `A`.\n",
    "    @submodel prefix=:inner x_inner = A()\n",
    "    x ~ Normal(x_inner, 1)\n",
    "\n",
    "    return (; x_inner, x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand(B()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@submodel` is useful as it allows you to:\n",
    "\n",
    "1.  Easy to swap out certain parts of your model.\n",
    "2.  Can re-use models across projects and packages.\n",
    "\n",
    "When working on larger projects, this really shines\n",
    "\n",
    "Equipped with `@submodel` we can replace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β ~ truncated(Normal(2, 1); lower=0)\n",
    "γ ~ truncated(Normal(0.4, 0.5); lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@submodel p = prior(problem_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "where `prior` can be something like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function prior_original(problem_wrapper::SIRProblem)\n",
    "    β ~ truncated(Normal(2, 1); lower=0)\n",
    "    γ ~ truncated(Normal(0.4, 0.5); lower=0)\n",
    "\n",
    "    return [β, γ]\n",
    "end\n",
    "\n",
    "@model function prior_improved(problem_wrapper::SIRProblem)\n",
    "    # NOTE: Should probably also lower mean for `β` since\n",
    "    # more probability mass on small `γ` ⟹ `R0 =  β / γ` grows.\n",
    "    β ~ truncated(Normal(1, 1); lower=0)\n",
    "    # NOTE: New prior for `γ`.\n",
    "    γ ~ Beta(2, 5)\n",
    "\n",
    "    return [β, γ]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function epidemic_model(\n",
    "    problem_wrapper::AbstractEpidemicProblem,\n",
    "    prior  # NOTE: now we just pass the prior as an argument\n",
    ")\n",
    "    # NOTE: And use `@submodel` to embed the `prior` in our model.\n",
    "    @submodel p = prior(problem_wrapper)\n",
    "\n",
    "    ϕ⁻¹ ~ Exponential(1/5)\n",
    "    ϕ = inv(ϕ⁻¹)\n",
    "\n",
    "    problem_new = remake(problem_wrapper.problem, p=p)  # Replace parameters `p`.\n",
    "    sol = solve(problem_new, saveat=1)                  # Solve!\n",
    "\n",
    "    # Extract the `infected`.\n",
    "    sol_for_observed = infected(problem_wrapper, sol)[2:end]\n",
    "\n",
    "    # NOTE: `arraydist` is faster for larger dimensional problems,\n",
    "    # and it does not require explicit allocation of the vector.\n",
    "    in_bed ~ arraydist(NegativeBinomial2.(sol_for_observed .+ 1e-5, ϕ))\n",
    "\n",
    "    β, γ = p[1:2]\n",
    "    return (R0 = β / γ, recovery_time = 1 / γ, infected = sol_for_observed)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"x-small-text\">\n",
    "\n",
    "Another neat trick is to return early if integration fail\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function epidemic_model(\n",
    "    problem_wrapper::AbstractEpidemicProblem,\n",
    "    prior  # now we just pass the prior as an argument\n",
    ")\n",
    "    # And use `@submodel` to embed the `prior` in our model.\n",
    "    @submodel p = prior(problem_wrapper)\n",
    "\n",
    "    ϕ⁻¹ ~ Exponential(1/5)\n",
    "    ϕ = inv(ϕ⁻¹)\n",
    "\n",
    "    problem_new = remake(problem_wrapper.problem, p=p)  # Replace parameters `p`.\n",
    "    sol = solve(problem_new, saveat=1)                  # Solve!\n",
    "\n",
    "    # NOTE: Return early if integration failed.\n",
    "    if !issuccess(sol)\n",
    "        Turing.@addlogprob! -Inf  # NOTE: Causes automatic rejection.\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    # Extract the `infected`.\n",
    "    sol_for_observed = infected(problem_wrapper, sol)[2:end]\n",
    "\n",
    "    # `arraydist` is faster for larger dimensional problems,\n",
    "    # and it does not require explicit allocation of the vector.\n",
    "    in_bed ~ arraydist(NegativeBinomial2.(sol_for_observed .+ 1e-5, ϕ))\n",
    "\n",
    "    β, γ = p[1:2]\n",
    "    return (R0 = β / γ, recovery_time = 1 / γ, infected = sol_for_observed)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipped with this we can now easily construct *two* models using different priors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sir = SIRProblem(N);\n",
    "model_original = epidemic_model(sir, prior_original);\n",
    "model_improved = epidemic_model(sir, prior_improved);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but using the same underlying `epidemic_model`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_prior_original = sample(model_original, Prior(), 10_000; progress=false);\n",
    "chain_prior_improved = sample(model_improved, Prior(), 10_000; progress=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the resulting priors over some of the quantities of interest\n",
    "\n",
    "Let's compare the `generated_quantities`, e.g. $R_0$\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_quantities_original = to_chains(\n",
    "    generated_quantities(\n",
    "        model_original,\n",
    "        MCMCChains.get_sections(chain_prior_original, :parameters)\n",
    "    );\n",
    ");\n",
    "\n",
    "chain_quantities_improved = to_chains(\n",
    "    generated_quantities(\n",
    "        model_improved,\n",
    "        MCMCChains.get_sections(chain_prior_improved, :parameters)\n",
    "    );\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(; legend=false, size=(500, 200))\n",
    "plot_trajectories!(p, group(chain_quantities_original, :infected); n = 100, trajectory_color=\"red\")\n",
    "plot_trajectories!(p, group(chain_quantities_improved, :infected); n = 100, trajectory_color=\"blue\")\n",
    "hline!([N], color=\"red\", linestyle=:dash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1 = plot(legend=false)\n",
    "plot_trajectory_quantiles!(plt1, group(chain_quantities_original, :infected))\n",
    "hline!(plt1, [N], color=\"red\", linestyle=:dash)\n",
    "\n",
    "plt2 = plot(legend=false)\n",
    "plot_trajectory_quantiles!(plt2, group(chain_quantities_improved, :infected))\n",
    "hline!(plt2, [N], color=\"red\", linestyle=:dash)\n",
    "\n",
    "plot(plt1, plt2, layout=(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "This makes sense: if half of the population is immediately infected ⟹ number of infected tapers wrt. time as they recover\n",
    "\n",
    "For `model_improved` we then have\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(quantile(chain_quantities_improved[:, [:R0, :recovery_time], :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to `model_original`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(quantile(chain_quantities_original[:, [:R0, :recovery_time], :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK Make `epidemic_model` work for `SEIRProblem`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [ ] Implement a prior which also includes $\\sigma$ and execute\n",
    "    `epidemic_model` with it\n",
    "2.  [ ] Can we make a better prior for $\\sigma$? Do we even need one?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function prior_original(problem_wrapper::SEIRProblem)\n",
    "    # TODO: Implement\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function prior_original(problem_wrapper::SEIRProblem)\n",
    "    β ~ truncated(Normal(2, 1); lower=0)\n",
    "    γ ~ truncated(Normal(0.4, 0.5); lower=0)\n",
    "    σ ~ truncated(Normal(0.8, 0.5); lower=0)\n",
    "\n",
    "    return [β, γ, σ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seir = epidemic_model(SEIRProblem(N), prior_original)\n",
    "print(model_seir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING Consult with domain experts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guy should <u>not</u> be the one setting your priors!\n",
    "\n",
    "![img](.notes/attachments/A_litle_Norwegian_boy/2023-01-18_14-49-24_471337_3317365246956_1262712540_o.jpg)\n",
    "\n",
    "Get an actual scientist to do that&#x2026;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually involve the data\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "We can condition a `Model` as so\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition on the observations.\n",
    "model = epidemic_model(SIRProblem(N), prior_improved)\n",
    "model_conditioned = model | (in_bed = data.in_bed,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "You know what time it is: *inference time*!\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings (MH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_mh = sample(model_conditioned, MH(), MCMCThreads(), 10_000, 4; discard_initial=5_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rhat is *okay-ish* but not great, and ESS is pretty low innit?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(chain_mh; size=(800, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeehh doesn't look the greatest\n",
    "\n",
    "Difficult to trust these results, but let's check if it at least did *something* useful\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using the unconditioned model!\n",
    "predictions_mh = predict(model, chain_mh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories!(plot(legend=false, size=(600, 300)), predictions_mh; data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_quantiles!(plot(legend=false, size=(600, 300)), predictions_mh; data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's not *completely* useless, but my trust-issues are still present.\n",
    "\n",
    "Metropolis-Hastings have disappointed me one too many times before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So instead, let's go `NUTS`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, we're reaching to the **No U-Turn sampler (NUTS)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :PROPERTIES:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://chi-feng.github.io/mcmc-demo/app.html](https://chi-feng.github.io/mcmc-demo/app.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*\\*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wooaah there! `NUTS` requires gradient information!\n",
    "> \n",
    "> How are you going to get that through that `solve`?Good question, voice in my head\n",
    "\n",
    "I'm obviously not going to it myself\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation (AD) in Julia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl): forward-mode AD *(default in Turing.jl)*\n",
    "-   [ReverseDiff.jl](https://github.com/JuliaDiff/ReverseDiff.jl): tape-based reverse-mode AD\n",
    "-   [Zygote.jl](https://github.com/FluxML/Zygote.jl): source-to-source reverse-mode AD\n",
    "-   And more&#x2026;\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Up-and-coming\n",
    "\n",
    "-   [Enzyme.jl](https://github.com/EnzymeAD/Enzyme.jl): Julia bindings for [Enzyme](https://github.com/EnzymeAD/Enzyme.jl) which ADs LLVM (low-level)\n",
    "-   [Diffractor.jl](https://github.com/JuliaDiff/Diffractor.jl): experimental mixed-mode AD meant to replace Zygote.jl\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Of importance\n",
    "\n",
    "-   [ChainRulesCore.jl](https://github.com/JuliaDiff/ChainRulesCore.jl): light-weight package for defining rules, compatible with many of the above\n",
    "\n",
    "</div>\n",
    "\n",
    "**Important**\n",
    "\n",
    "> When you write code, you don't have to make a choice which one you\n",
    "> want to use!All the (stable) ones, will (mostly) work\n",
    "\n",
    "*But* how you write code will affect performance characteristics\n",
    "\n",
    "Takes a bit of know-how + a bit of digging to go properly \"vroom!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiating through `solve`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that being said, differentiating through numerical `solve` is not necessarily trivial to do efficiently\n",
    "\n",
    "There are numerous ways of approaching this problem\n",
    "\n",
    "![img](.notes/attachments/Bayesian_inference/2023-01-22_12-30-07_Screenshot_20230122_122936.png)\n",
    "\n",
    "[https://arxiv.org/abs/1812.01892](https://arxiv.org/abs/1812.01892) is *great* resource\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "But this is why we have [`SciMLSensitivity.jl`](https://github.com/SciML/SciMLSensitivity.jl)\n",
    "\n",
    "[SciMLSensitivity.jl docs](https://docs.sciml.ai/SciMLSensitivity/stable/manual/differential_equation_sensitivities/#Choosing-a-Sensitivity-Algorithm) also provides a great overview of different approaches\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SciMLSensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It offers\n",
    "\n",
    "1.  *Discrete sensitivity analysis* or the *\"Direct\" method*: just use\n",
    "    `ForwardDiff.Dual` in the `solve`.\n",
    "2.  *Continuous local sensitivity analysis (CSA)*: extends the original\n",
    "    system such that the `solve` gives you both the solution and the the\n",
    "    gradient simultaenously.\n",
    "3.  *Adjoint methods*: construct a backwards system whose solution gives\n",
    "    us the gradient.\n",
    "\n",
    "Just do `solve(problem, solver, sensealg = ...)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to being `NUTS`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = sample(model_conditioned, NUTS(0.8), MCMCThreads(), 1000, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muuuch better! Both ESS and Rhat is looking good\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(chain; size=(800, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the results from NUTS.\n",
    "predictions = predict(model, chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories!(plot(legend=false, size=(600, 300)), predictions; n = 1000, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_quantiles!(plot(legend=false, size=(600, 300)), predictions; data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation-based calibration (SBC) [Talts et. al. (2018)](https://arxiv.org/abs/1804.06788)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Sample from prior $\\theta_1, \\dots, \\theta_n \\sim p(\\theta)$.\n",
    "2.  Sample datasets $\\mathcal{D}_i \\sim p(\\cdot \\mid \\theta_i)$ for $i = 1, \\dots, n$.\n",
    "3.  Obtain (approximate) $p(\\theta \\mid \\mathcal{D}_i)$ for $i = 1, \\dots, n$.\n",
    "\n",
    "For large enough (n), the \"combination\" of the posteriors should recover the prior!\n",
    "\n",
    "\"Combination\" here usually means computing some statistic and comparing against what it should be\n",
    "\n",
    "![img](.notes/attachments/Bayesian_inference/2023-01-22_12-09-24_Screenshot_20230122_120848.png)\n",
    "\n",
    "That's very expensive → in practice we just do this once or twice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the conditioned model so we don't get the `in_bed` variables too\n",
    "using Random  # Just making usre the numbers of somewhat interesting\n",
    "rng = MersenneTwister(43);\n",
    "test_values = rand(rng, NamedTuple, model_conditioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we condition on those values and run once to generate data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model | test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_best_test = rand(rng, model_test).in_bed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, inference!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_conditioned = model | (in_bed = in_best_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just do a single chain here.\n",
    "chain_test = sample(model_test_conditioned, NUTS(0.8), 1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we recover the parameters?\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sym in [:β, :γ, :ϕ⁻¹]\n",
    "    p = density(chain_test[:, [sym], :])\n",
    "    vline!([test_values[sym]])\n",
    "    push!(ps, p)\n",
    "end\n",
    "plot(ps..., layout=(3, 1), size=(600, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "Yay!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samplers in Turing.jl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Metropolis-Hastings, emcee, SGLD ([AdvancedMH.jl](https://github.com/TuringLang/AdvancedMH.jl))\n",
    "-   Hamiltonian Monte Carlo, NUTS ([AdvancedHMC.jl](https://github.com/TuringLang/AdvancedMH.jl))\n",
    "-   SMC ([AdvancedPS.jl](https://github.com/TuringLang/AdvancedPS.jl))\n",
    "-   Elliptical Slice Sampling ([EllipticalSliceSampling.jl](https://github.com/TuringLang/EllipticalSliceSampling.jl))\n",
    "-   Nested sampling ([NestedSamplers.jl](https://github.com/TuringLang/NestedSamplers.jl))\n",
    "\n",
    "You can also combine some of these in Turing.jl\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra: I\n",
    "\n",
    "@model function linear_regression(X)\n",
    "    num_params = size(X, 1)\n",
    "    β ~ MvNormal(ones(num_params))\n",
    "    σ² ~ InverseGamma(2, 3)\n",
    "    y ~ MvNormal(vec(β' * X), σ² * I)\n",
    "end\n",
    "\n",
    "# Generate some dummy data.\n",
    "X = randn(2, 1_000); lin_reg = linear_regression(X); true_vals = rand(lin_reg)\n",
    "\n",
    "# Condition.\n",
    "lin_reg_conditioned = lin_reg | (y = true_vals.y,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "We can then do `Gibbs` but sampling $β$ using `ESS` and $\\sigma^2$ using `HMC`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_ess_hmc = sample(lin_reg_conditioned, Gibbs(ESS(:β), HMC(1e-3, 16, :σ²)), 1_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could potentially lead to improvements\n",
    "\n",
    "**NOTE:** Usually *very* difficult to choose sampler parameters in this case\n",
    "\n",
    "Means one can also mix discrete and continuous\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function mixture(n)\n",
    "    cluster ~ filldist(Categorical([0.25, 0.75]), n)\n",
    "    μ ~ MvNormal([-10.0, 10.0], I)\n",
    "    x ~ arraydist(Normal.(μ[cluster], 1))\n",
    "end\n",
    "\n",
    "model_mixture = mixture(10)\n",
    "fake_values_mixture = rand(model_mixture)\n",
    "model_mixture_conditioned = model_mixture | (x = fake_values_mixture.x, )\n",
    "chain_discrete = sample(\n",
    "    model_mixture_conditioned, Gibbs(PG(10, :cluster), HMC(1e-3, 16, :μ)), MCMCThreads(), 1_000, 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "<div class=\"x-small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for (i, realizations) in enumerate(eachcol(Array(group(chain_discrete, :cluster))))\n",
    "    p = density(realizations, legend=false, ticks=false); vline!(p, [fake_values_mixture.cluster[i]])\n",
    "    push!(ps, p)\n",
    "end\n",
    "plot(ps..., layout=(length(ps) ÷ 2, 2), size=(600, 40 * length(ps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "Again, this is difficult to get to work properly on non-trivial examples\n",
    "\n",
    "<u>But</u> it is possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities for Turing.jl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [TuringGLM.jl](https://github.com/TuringLang/TuringGLM.jl): GLMs using the formula-syntax from R but using Turing.jl under the hood\n",
    "-   [TuringBenchmarking.jl](https://github.com/TuringLang/TuringBenchmarking.jl): useful for benchmarking Turing.jl models\n",
    "-   [TuringCallbacks.jl](https://github.com/TuringLang/TuringCallbacks.jl): on-the-fly visualizations using `tensorboard`\n",
    "\n",
    "![img](.notes/attachments/Bayesian_inference/2023-01-25_20-50-11_tensorboard_demo_histograms_screen.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsides of using Turing.jl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Don't do any depedency-extraction of the model ⟹ can't do things like automatic marginalization\n",
    "    -   *But* it's not impossible; just a matter of development effort\n",
    "    -   Ongoing work in `TuringLang` to make a [BUGS](https://www.mrc-bsu.cam.ac.uk/software/bugs/) compatible model \"compiler\" / parser (in colab with Andrew Thomas & others)\n",
    "-   NUTS performance is at the mercy of AD in Julia\n",
    "-   You <u>can</u> put anything in your model, but whether you <u>should</u> is a another matter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SciMLSensitivity\n",
    "using BenchmarkTools\n",
    "using TuringBenchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ReverseDiff, Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TuringBenchmarking.make_turing_suite(\n",
    "    model_conditioned;\n",
    "    adbackends=[\n",
    "        TuringBenchmarking.ForwardDiffAD{40,true}(),\n",
    "        TuringBenchmarking.ReverseDiffAD{false}(),\n",
    "        TuringBenchmarking.ZygoteAD()\n",
    "    ]\n",
    ");\n",
    "run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We now use 10 000 days instead of just 14.\n",
    "model_fake = epidemic_model(SIRProblem(N; tspan=(0, 10_000)), prior_improved);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rand(model_fake)\n",
    "model_fake_conditioned = model_fake | (in_bed = res.in_bed,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fake_conditioned().infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TuringBenchmarking.make_turing_suite(\n",
    "    model_fake_conditioned;\n",
    "    adbackends=[\n",
    "        TuringBenchmarking.ForwardDiffAD{40,true}(),\n",
    "        TuringBenchmarking.ReverseDiffAD{false}(),\n",
    "        TuringBenchmarking.ZygoteAD()\n",
    "    ]\n",
    ");\n",
    "run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia: The Good, the Bad, and the Ugly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An honest take from a little 27-year old Norwegian boy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Good\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Speed\n",
    "-   Composability (thank you multiple dispatch)\n",
    "-   No need to tie yourself to an underlying computational framework\n",
    "-   Interactive\n",
    "-   Transparency\n",
    "-   Very easy to call into other languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think you got this already&#x2026;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen some of that\n",
    "\n",
    "Defining `infected(problem_wrapper, u)` allowed us to abstract away how to extract the compartment of interest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transparency\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, almost all the code you'll end up using is pure Julia\n",
    "\n",
    "Hence, you can always look at the code\n",
    "\n",
    "You can find the implementation by using `@which`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without arguments\n",
    "@which sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With arguments\n",
    "@which sum([1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And yeah, you can even look into the macros\n",
    "\n",
    "<div class=\"small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@macroexpand @model f() = x ~ Normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "I told you didn't want to see that.\n",
    "\n",
    "Can make it *a bit* cleaner by removing linenums:\n",
    "\n",
    "<div class=\"x-small-text\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@macroexpand(@model f() = x ~ Normal()) |> Base.remove_linenums!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the type-inferred and lowered code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the LLVM code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even the resulting machine code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native f(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It really just depends on which level of \"I hate my life\" you're currently at\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling into other languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [C and Fortran comes built-in stdlib](https://docs.julialang.org/en/v1/manual/calling-c-and-fortran-code/)\n",
    "-   [RCall.jl](https://juliainterop.github.io/RCall.jl/stable/): call into `R`\n",
    "-   [PyCall.jl](https://github.com/JuliaPy/PyCall.jl): call into `python`\n",
    "-   Etc.\n",
    "\n",
    "When working with `Array`, etc. memory is usually shared ⟹ fairly low overhead\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C and Fortran\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Julia function\n",
    "function mycompare(a, b)::Cint\n",
    "    println(\"mycompare($a, $b)\")  # NOTE: Let's look at the comparisons made.\n",
    "    return (a < b) ? -1 : ((a > b) ? +1 : 0)\n",
    "end\n",
    "\n",
    "# Get the corresponding C function pointer.\n",
    "mycompare_c = @cfunction(mycompare, Cint, (Ref{Cdouble}, Ref{Cdouble}))\n",
    "\n",
    "# Array to sort.\n",
    "A = [1.3, -2.7, 4.4, 3.1];\n",
    "\n",
    "# Call in-place quicksort.\n",
    "ccall(:qsort, Cvoid, (Ptr{Cdouble}, Csize_t, Csize_t, Ptr{Cvoid}),\n",
    "      A, length(A), sizeof(eltype(A)), mycompare_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All sorted!\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example is from Julia docs](https://docs.julialang.org/en/v1/manual/calling-c-and-fortran-code/#Creating-C-Compatible-Julia-Function-Pointers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes\n",
    "\n",
    "-   your code might just slow down without a seemingly good reason,\n",
    "-   someone did bad, and Julia can't tell which method to call, or\n",
    "-   someone forces the Julia compiler to compile insane amounts of code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Why is my code suddenly slow?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One word: **type-instability**\n",
    "\n",
    "Sometimes the Julia compiler can't quite infer what types fully\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "**Result:** python-like performance (for those particular function calls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is NOT `const`, and so it could become some other type\n",
    "# at any given point without `my_func` knowing about it!\n",
    "global_variable = 1\n",
    "my_func_unstable(x) = global_variable * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime my_func_unstable(2.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "\n",
    "Luckily there are tools for inspecting this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype my_func_unstable(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that `Any` there? <u>'tis a big no-no!</u>\n",
    "\n",
    "Once discovered, it can be fixed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const constant_global_variable = 1\n",
    "my_func_fixed(x) = constant_global_variable * x\n",
    "@code_warntype my_func_fixed(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So long Python performance!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime my_func_fixed(2.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But* this is not always so easy to discover (though this is generally rare)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: Here we explicitly tell Julia what type `my_func_unstable`\n",
    "# returns. This is _very_ rarely a good idea because it just hides\n",
    "# the underlying problem from `@code_warntype`!\n",
    "my_func_forced(x) = my_func_unstable(x)::typeof(x)\n",
    "@code_warntype my_func_forced(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still see the `Any` in there, but on a first glance it looks like `my_func_forced` is type-stable\n",
    "\n",
    "There are more natural cases where this might occur, e.g. unfortunate closures deep in your callstack\n",
    "\n",
    "To discovery these there are a couple of more advanced tools:\n",
    "\n",
    "-   [Cthulhu.jl](https://github.com/JuliaDebug/Cthulhu.jl): Allows you to step through your code like a debugger and perform `@code_warntype`\n",
    "-   [JET.jl](https://github.com/aviatesk/JET.jl): Experimental package which attempts to automate the process\n",
    "\n",
    "And even simpler: profile using [ProfileView.jl](https://github.com/timholy/ProfileView.jl) and look for code-paths that *should* be fast but take up a lot of the runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProfileView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profview foreach(_ -> my_func_unstable(2.0), 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](.notes/attachments/Julia:_The_Good,_the_Bad,_and_the_Ugly/2023-01-25_01-16-13_Screenshot_20230125_011603.png)\n",
    "\n",
    "Note that there's no sign of multiplication here\n",
    "\n",
    "But most of the runtime is the `./reflection.jl` at the top there\n",
    "\n",
    "That's Julia looking up the type at runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method ambiguity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_function(x, y::Int) = y\n",
    "ambiguous_function(x::Int, y) = x\n",
    "\n",
    "# NOTE: Here we have `ambiguous_function(x::Int, y::Int)`\n",
    "# Which one should we hit?!\n",
    "ambiguous_function(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here Julia warns us, and so we can fix this by just doing as it says: define `ambiguous_function(::Int64, ::Int64)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_function(::Int64, ::Int64) = \"neato\"\n",
    "ambiguous_function(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long compilation times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia, for better or worse, we can generate code\n",
    "\n",
    "**Problem:** it can be *lots* of code of we really want to\n",
    "\n",
    "**Result:** first execution can be *slow*\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "**Time to first plot (TTFP)** is Julia's worst enemy\n",
    "\n",
    "But things are always improving\n",
    "\n",
    "![img](.notes/attachments/Julia:_The_Good,_the_Bad,_and_the_Ugly/2023-01-25_01-29-05_Screenshot_20230125_012853.png)\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example: mis-use of `@generated`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: `@generated` only has access to static information, e.g. types of arguments.\n",
    "# Here I'm using the special type `Val` to make a number `N` static.\n",
    "@generated function unrolled_addition(::Val{N}) where {N}\n",
    "    expr = Expr(:block)\n",
    "    push!(expr.args, :(x = 0))\n",
    "    for i = 1:N\n",
    "        push!(expr.args, :(x += $(3.14 * i)))\n",
    "    end\n",
    "\n",
    "    return expr\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I call this with some `Val(N)`, Julia will execute this *at compile-time*!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: At runtime, it then just returns the result immediately\n",
    "@code_typed unrolled_addition(Val(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if I just change the value `10` to `11`, it's a *completely* different type!\n",
    "\n",
    "So Julia has to compile `unrolled_addition` from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @eval unrolled_addition(Val(11));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a bit crazier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @eval unrolled_addition(Val(10_001));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it took ~0.4s, of which 99.95% was compilation time\n",
    "\n",
    "I think you get the idea\n",
    "\n",
    "But boy is it fast to run!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime unrolled_addition(Val(10_001));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function not_unrolled_addition(N)\n",
    "    x = 0\n",
    "    for i = 1:N\n",
    "        x += 3.14 * i\n",
    "    end\n",
    "\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime not_unrolled_addition(10_001);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funny side-note:** at first I did the following\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generated function unrolled_addition_old(::Val{N}) where {N}\n",
    "    expr = Expr(:block)\n",
    "    push!(expr.args, :(x = 0))\n",
    "    for i = 1:N\n",
    "        push!(expr.args, :(x += $i))  # NOTE: No 3.14!\n",
    "    end\n",
    "    return expr\n",
    "end\n",
    "function not_unrolled_addition_old(N)\n",
    "    x = 0\n",
    "    for i = 1:N\n",
    "        x += i  # NOTE: No 3.14!\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime unrolled_addition_old(Val(10_001));\n",
    "@btime not_unrolled_addition_old(10_001);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLVM probably recognized the pattern of `not_unrolled_addition_old` and unrolls it for us\n",
    "\n",
    "Let's check!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The one LLVM failed to unroll\n",
    "@code_llvm not_unrolled_addition(10_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The one LLVM seems to have unrolled.\n",
    "@code_llvm not_unrolled_addition_old(10_001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Ugly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Reverse-mode automatic differentiation**</u>\n",
    "\n",
    "ForwardDiff.jl is a pure joy, but slows down as dimensionality grows\n",
    "\n",
    "Then one should reach for ReverseDiff.jl or Zygote.jl\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "Most of the time it works really well, but sometimes you hit a real sharp edge\n",
    "\n",
    "And sharp edges cut; they cut *deep*\n",
    "\n",
    "Like <u>\"16X slower when the function is implemented more efficiently\"-deep</u>\n",
    "\n",
    "![img](.notes/attachments/Julia:_The_Good,_the_Bad,_and_the_Ugly/2023-01-25_01-01-31_Screenshot_20230125_010111.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"fragment (appear)\">\n",
    "\n",
    "If you want to see a man in pain, you can find the full issue [here](https://github.com/TuringLang/Turing.jl/issues/1934)\n",
    "\n",
    "On the flip-side, once addressed (a type-instability), it's [3X faster than before](https://github.com/TuringLang/DistributionsAD.jl/pull/231)\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is pretty darn awesome\n",
    "\n",
    "Easy to get going, and you can always make it faster by just optimizing your Julia code\n",
    "\n",
    "No need to drop down to C++\n",
    "\n",
    "Buuuut it can't beat Python at deep learning\n",
    "\n",
    "Otherwise, it's worth a try\n",
    "\n",
    "Godspeed to you\n",
    "\n",
    "Fin.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
