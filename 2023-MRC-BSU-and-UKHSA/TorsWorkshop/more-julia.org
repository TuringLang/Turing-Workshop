#+SETUPFILE: ~/org-blog/setup.org
#+OPTIONS: tex:t toc:nil date:nil
#+PROPERTY: header-args:R :session :exports both :eval no
#+PROPERTY: header-args:julia :session mrc-biostats-2023-more-julia :tangle more-julia.jl :exports both :kernel julia-4-threads-1.9 :async yes :file (f-join "assets" "outputs" "more-julia" (sha1 (plist-get (cadr (org-element-at-point)) :value)))
#+EXCLUDE_TAGS: noexport
#+TODO: TODO(t) TASK(q) WARNING(w) | DONE(d) SOLUTION(s)

#+REVEAL_ROOT: assets/reveal.js-4.1.0/
#+REVEAL_MATHJAX_URL: assets/MathJax-2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML
#+REVEAL_TITLE_SLIDE: <div><div style="margin: -200px auto; opacity: 0.2;"><p><object data="assets/images/turing-logo-wide.svg"></object></p></div><h1>Bayesian inference and other things</h1><h2>with the TuringLang ecosystem</h2><p><a href="https://github.com/TuringLang">https://github.com/TuringLang</a></p><p><a href="https://github.com/TuringLang/Turing-Workshop/tree/main/2023-Geilo-Winter-School/Part-2-Turing-and-other-things">The workshop is found here</a></p></div>
#+REVEAL_EXTRA_CSS: assets/css/custom.css
#+REVEAL_THEME: white
#+REVEAL_PLUGINS: (markdown zoom)
#+REVEAL_INIT_OPTIONS: slideNumber:true
#+HTML_HEAD: <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

#+AUTHOR: Tor Erlend Fjelde
#+TITLE: More Julia

* Notes                                                            :noexport:

- [ ] How much do I need to cover of LinearAlgebra?
  - Xianda covers
    - A bit of IO
    - A
- [X] Problem: estimate pi
- [ ] distriubtions.jl
  - Show a table of distrubiotns
  - Show a table of API
- [X] turing
  - use product dist
  - debugging
    - broken simple model
      - Explicitly running the model
  - quick slide demonstrating TuringCallbacks.jl + TensorBoard
- [X] Pidgeon and MCMCTempering
- [X] TuringGLM example
- [ ] Starting a project from scratch
  - +Maybe use the rats example from https://github.com/kskyten/BayesWorkshop2021/tree/generated/notebooks/Turing+
  - [ ] Use infectious disease example instead
- [ ] Case studies
  - Rats example
    - Simple to get started
    - Can progressively make more and more complicated models
    - Project will have relatively simple models, and so will focus more on analysis of results and comparisons of models.
  - Lotka-Volterra
    - https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html
    - https://turinglang.org/v0.29/tutorials/10-bayesian-differential-equations/
    - Involves ODEs
    - Not many different models
  - ImperialReport13
    - The model itself is quite complex
  - S(?)IR model for influenza dataset
    - We've already gone through this partially
    - Maybe they want to try to implement something else?
- [ ] Implement Adaptive MH from [cite:@journal.pcbi.1011088]
  - Adaptive MH and PMMH methods are more explicitly talked about here: [cite:@kxs052]
- [ ] =EpimapSimple=
  - Show off the submodel stuff.
- [X] Add some more stuff to TuringCallbacks.jl sectione
- [X] For condtioning:
  - [X] Maybe =missing=
  - [X] Example of failure to do constnat prop
- [ ] Regarding case-studies
  - [ ] Can we make MiniEpimap.jl work?
    - [ ] Can we give them a =chain= and let them work with this?
  - [ ] Tutorials
  - [ ] Make some minor notes on the different case studies
- [ ] Quick slide on GPUs
* Aim of these two days

/Ideally/, you walk away from this workshop with the ability to _solve whatever research problem you have with Julia and Turing.jl_

#+HTML: <div class="fragment (appear)>"
/Likely/, you walk away from this workshop with _slightly_ better understanding of how to solve your research problems with Julia and Turing.jl + _a whole lot of questions_.
#+HTML: </div>

#+HTML: <div class="fragment (appear)>"
But we will do our best
#+HTML: </div>

* The story of a little Norwegian boy
:PROPERTIES:
:ID:       2023-01-29-16-57-28-The-story-of-a-little-Norwegian-boy
:CUSTOM_ID: 2023-01-29-16-57-28-The-story-of-a-little-Norwegian-boy
:END:

#+REVEAL: split

There once was a little Norwegian boy

#+DOWNLOADED: file:///home/tor/Downloads/471337_3317365246956_1262712540_o.jpg @ 2023-01-18 14:49:24
#+ATTR_HTML: :height 400px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-18_14-49-24_471337_3317365246956_1262712540_o.jpg]]


#+REVEAL: split

When this little boy was 20 years old, he was working as a parking guard near Preikestolen/Pulpit rock


#+DOWNLOADED: file:///home/tor/Downloads/Preikestolen-plateau-Go-Fjords-Bob-Engelsen-P1026771_kljg5o.jpeg @ 2023-01-18 14:57:08
#+ATTR_HTML: :height 400px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-18_14-57-08_Preikestolen-plateau-Go-Fjords-Bob-Engelsen-P1026771_kljg5o.jpeg]]


#+REVEAL: split

One day it was raining and there was nobody hiking, and so there was no cars in sight for the little boy to point

#+HTML: <div class="fragment (appear)">

When his boss wasn't looking, the little 20 year-old boy had an amazing idea

#+begin_quote
Maybe I can use this method of Mr. Bayes I learned a bit about yesterday to model football / Premier League?
#+end_quote

#+HTML: </div>

#+ATTR_REVEAL: :frag (appear)
The little boy got very excited and started looking for stuff on the big interwebs

#+REVEAL: split

The little boy came across this

#+DOWNLOADED: file:///tmp/Spectacle.jWiYMk/Screenshot_20230118_144454.png @ 2023-01-18 14:46:02
[[file:assets/attachments/2023-01-18_14-46-02_Screenshot_20230118_144454.png]]

And got _very_ excited

#+REVEAL: split

But at the time, the little boy knew next to _nothing_ about programming

The little boy couldn't write the code to do the inference

#+ATTR_REVEAL: :frag (appear)
Whence the little boy became a _sad_ little boy :(

#+REVEAL: split

But time heals all wounds, and at some point the little boy learned Python

And in Python, the boy found the /probabilistic programming language/ =pymc3=

#+HTML: <div class="fragment (appear)">
#+begin_quote
Maybe I can use =pymc3= to perform inference in that football / Premier League model?
#+end_quote

And so the sad boy once more became an _excited_ little boy :)
#+HTML: </div>

#+REVEAL: split

But there was a problem

The boy wanted to write a for-loop in his model, but the model didn't want it to be so and complained!

#+ATTR_REVEAL: :frag (appear)
The boy got frustrated and gave up, once more becoming a _sad_ little boy :(

#+HTML: <div class="small-text">

#+ATTR_REVEAL: :frag (appear)
The boy should have known that the computational backend =theano= that was used by =pymc3= at the time couldn't handle a for-loop, and instead he should have used =scan=. But the boy was only 20-something years old; he didn't know.

#+HTML: </div>

#+REVEAL: split

Some years later the boy discovers a programming language called _Julia_

#+HTML: <div class="fragment (appear)">
Julia makes a few promises
#+ATTR_REVEAL: :frag (appear)
1. It's fast. Like /really/ fast.
2. It's interactive; doesn't require full compilation for you to play with it.
3. You don't have to specify types everywhere.
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
The boy thinks

#+begin_quote
Wait, but this sounds like Python but the only difference is that...I CAN WRITE FOR-LOOPS WITHOUT FEELING BAD ABOUT IT?!
#+end_quote

Yes, yes he could

#+ATTR_REVEAL: :frag (appear)
And 3.5 years later, he's still writing for-loops. Well, sort of.
#+HTML: </div>

** But it really is fast
:PROPERTIES:
:ID:       2023-01-29-16-57-28-But-it-really-is-fast
:CUSTOM_ID: 2023-01-29-16-57-28-But-it-really-is-fast
:END:


#+DOWNLOADED: file:///tmp/Spectacle.jWiYMk/Screenshot_20230118_153122.png @ 2023-01-18 15:31:28
#+CAPTION: https://julialang.org/benchmarks/ (2023-01-18)
#+ATTR_HTML: :height 400px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-18_15-31-28_Screenshot_20230118_153122.png]]

#+REVEAL: split

And the consequences are
#+ATTR_REVEAL: :frag (appear)
- Even a naive implementation will be fairly fast!
  - If you want to go faster, you just optimize the code /in Julia/!
  - No need to drop down to C(++)
- ‚üπ "Every" package is written in Julia!
  - Encountered a bug? Have to debug the _Julia_ code
  - Same language as you're writing in!
- ‚üπ Same for /extending/ packages!
  - Can change functions to experiment with code you don't even own!


#+HTML: <div class="fragment (appear)"
So all in all, it can be quite nice
#+HTML: </div>

* Before we begin
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Before-we-begin
:CUSTOM_ID: 2023-01-29-16-57-28-Before-we-begin
:END:

Make sure you're in the correct directory

#+begin_src julia
pwd()
#+end_src

#+RESULTS:
: "/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop"

#+begin_src julia :exports none
outputdir(args...) = joinpath("assets", "outputs", "more-julia", args...)
#+end_src

#+RESULTS:
: outputdir (generic function with 1 method)

Then run something like (depending on which OS you are on)

#+begin_src sh :eval no
julia --project
#+end_src

or if you're already in a REPL, do

#+begin_src julia :tangle no
]activate .
#+end_src

#+RESULTS:
: [32m[1m  Activating[22m[39m project at `/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop`

to activate the project

#+REVEAL: split

And just to check that you're in the correct one

#+begin_src julia :tangle no
]status
#+end_src

#+RESULTS:
#+begin_example
[36m[1mProject[22m[39m TorsWorkshop v0.1.0
[32m[1mStatus[22m[39m `/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop/Project.toml`
  [90m[336ed68f] [39mCSV v0.10.11
  [90m[124859b0] [39mDataDeps v0.7.11
  [90m[a93c6f00] [39mDataFrames v1.6.1
  [90m[2b5f629d] [39mDiffEqBase v6.129.0
  [90m[0c46a032] [39mDifferentialEquations v7.9.1
  [90m[31c24e10] [39mDistributions v0.25.100
  [90m[7073ff75] [39mIJulia v1.24.2
  [90m[7f7a1694] [39mOptimization v3.17.0
  [90m[36348300] [39mOptimizationOptimJL v0.1.9
  [90m[e4faabce] [39mPProf v2.3.0
  [90m[91a5bcdd] [39mPlots v1.39.0
  [90m[37e2e3b7] [39mReverseDiff v1.15.1
  [90m[4c63d2b9] [39mStatsFuns v1.3.0
  [90m[f3b207a7] [39mStatsPlots v0.15.6
  [90m[fce5fe82] [39mTuring v0.29.1
  [90m[0db1332d] [39mTuringBenchmarking v0.3.1
  [90m[ea0860ee] [39mTuringCallbacks v0.4.0
  [90m[0004c1f4] [39mTuringGLM v2.8.1
  [90m[1986cc42] [39mUnitful v1.17.0
  [90m[ade2ca70] [39mDates
#+end_example

Download and install dependencies

#+begin_src julia :tangle no
]instantiate
#+end_src

#+RESULTS:

#+REVEAL: split

And finally, do

#+begin_src julia 
using TorsWorkshop
#+end_src

#+RESULTS:


to get some functionality I've implemented for the occasion

* Base & Standard library
Julia is mainly a programing language for scientific computing

‚üπ Julia comes with tons of useful functionality built-in
** =Base=


[[https://docs.julialang.org/en/v1/base/base/][=Base=]] is the only module which is /always/ imported

It contains the most fundamental functionality of the language, e.g.

#+begin_src julia
@which map
#+end_src

#+RESULTS:
: Base

#+REVEAL: split

Relevant modules you'll find in =Base=

- [[https://docs.julialang.org/en/v1/base/file/][Filesystem]]
- [[https://docs.julialang.org/en/v1/base/io-network/][I/O and Network]]
- [[https://docs.julialang.org/en/v1/base/iterators/][Iterators]]
- [[https://docs.julialang.org/en/v1/base/multi-threading/][Threads]]

*** Filesystem
#+begin_src julia
pwd()  # current working directory
#+end_src

#+RESULTS:
: "/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop"

#+begin_src julia
@which pwd
#+end_src

#+RESULTS:
: Base.Filesystem

https://docs.julialang.org/en/v1/base/file/

*** Multi-threading

#+begin_src julia 
Threads
#+end_src

#+RESULTS:
: Base.Threads

#+begin_src julia
Threads.nthreads()
#+end_src

#+RESULTS:
: 4

Or we can call =using Threads= so so we don't have to write =Threads.=

#+begin_src julia 
using Base.Threads
#+end_src

#+RESULTS:

#+begin_src julia
nthreads()
#+end_src

#+RESULTS:
: 4

#+REVEAL: split

Making use of the threads is trivial

#+begin_src julia
Threads.@threads for i in 1:10
    println("Thread $(Threads.threadid()): $i")
end
#+end_src

#+RESULTS:
: Thread 1: 1
: Thread 4: 2
: Thread 4: 3
: Thread 4: 9
: Thread 4: 10
: Thread 3: 7
: Thread 3: 8
: Thread 2: 4
: Thread 2: 5
: Thread 2: 6

https://docs.julialang.org/en/v1/base/multi-threading/

** Standard library
These are all the packages that come with Julia but you explicitly have to load with =using=

#+HTML: <div class="side-by-side">
- [[https://docs.julialang.org/en/v1/stdlib/Pkg/][Pkg]]
- [[https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/][LinearAlgebra]]
- [[https://docs.julialang.org/en/v1/stdlib/SparseArrays/][SparseArrays]]
- [[https://docs.julialang.org/en/v1/stdlib/Statistics/][Statistics]]
- [[https://docs.julialang.org/en/v1/stdlib/Random/][Random]]
- [[https://docs.julialang.org/en/v1/stdlib/Distributed/][Distributed]]
#+HTML: </div>

#+HTML: <div class="side-by-side">
- [[https://docs.julialang.org/en/v1/stdlib/Logging/][Logging]]
- [[https://docs.julialang.org/en/v1/stdlib/Dates/][Dates]]
- [[https://docs.julialang.org/en/v1/stdlib/Serialization/][Serialization]]
- [[https://docs.julialang.org/en/v1/stdlib/Downloads/][Downloads]]
- [[https://docs.julialang.org/en/v1/stdlib/Test/][Unit testing]]
#+HTML: </div>

*** =Dates=

#+begin_src julia 
using Dates
before = Dates.now()
#+end_src

#+RESULTS:
: 2023-09-19T20:52:35.850

#+begin_src julia
Dates.now() - before
#+end_src

#+RESULTS:
: 704 milliseconds

#+begin_src julia
dump(before)
#+end_src

#+RESULTS:
: DateTime
:   instant: Dates.UTInstant{Millisecond}
:     periods: Millisecond
:       value: Int64 63830839955850

https://docs.julialang.org/en/v1/stdlib/Dates/

*** =Random=

#+begin_src julia 
using Random
#+end_src

#+RESULTS:

We can set the "global" seed

#+begin_src julia 
Random.seed!(1234)
#+end_src

#+RESULTS:
: TaskLocalRNG()

#+begin_src julia
rand()
#+end_src

#+RESULTS:
: 0.32597672886359486

#+HTML: <div class="fragment (appear)>"
Or provide the RNG explicitly

#+begin_src julia
# Xoshiro is what Julia uses by default
rng = Random.Xoshiro(1234)
rand(rng) # <= same as before
#+end_src

#+RESULTS:
: 0.32597672886359486
#+HTML: </div>

#+HTML: <div class="fragment (appear)>"
Most functions using RNGs follow this pattern of optionally accepting an RNG as the first argument
#+HTML: </div>

#+REVEAL: split

To sample multiple values, we just specify how many we want

#+begin_src julia
rand(3)
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  0.5490511363155669
:  0.21858665481883066
:  0.8942454282009883

#+begin_src julia
rand(3, 3)
#+end_src

#+RESULTS:
: 3√ó3 Matrix{Float64}:
:  0.520355  0.967143  0.951162
:  0.639562  0.205168  0.0739957
:  0.839622  0.527184  0.571586

#+HTML: <div class="fragment (appear)>"
And we can also specify the type of the output

#+begin_src julia
rand(Float32)
#+end_src

#+RESULTS:
: 0.07271612f0
#+HTML: </div>

#+REVEAL: split

And of course other standard sampling functions are available
#+begin_src julia 
randn()
#+end_src

#+RESULTS:
: 1.724189934074888

#+begin_src julia
randexp()
#+end_src

#+RESULTS:
: 0.04221258127478853

#+begin_src julia
# Sample uniformly from a vector
rand([1, 2, 3])
#+end_src

#+RESULTS:
: 3

And more: https://docs.julialang.org/en/v1/stdlib/Random/

*** =LinearAlgebra=

#+begin_src julia 
A = [1 2 3; 4 1 6; 7 8 1]
#+end_src

#+RESULTS:
: 3√ó3 Matrix{Int64}:
:  1  2  3
:  4  1  6
:  7  8  1

#+begin_src julia :results scalar
using LinearAlgebra

norm(A), dot(A[:, 1], A[:, 3])
#+end_src

#+RESULTS:
: (13.45362404707371, 34)

#+begin_src julia
@which norm
#+end_src

#+RESULTS:
: LinearAlgebra

Other functions are =det=, =dot=, =cholesky=, and much, much more.

https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/

*** =SparseArrays=

#+begin_src julia 
using SparseArrays
A_sparse = sparse([1, 1, 2, 3], [1, 3, 2, 3], [0, 1, 2, 0])
#+end_src

#+RESULTS:
: 3√ó3 SparseMatrixCSC{Int64, Int64} with 4 stored entries:
:  0  ‚ãÖ  1
:  ‚ãÖ  2  ‚ãÖ
:  ‚ãÖ  ‚ãÖ  0

#+begin_src julia
dropzeros(A_sparse)
#+end_src

#+RESULTS:
: 3√ó3 SparseMatrixCSC{Int64, Int64} with 2 stored entries:
:  ‚ãÖ  ‚ãÖ  1
:  ‚ãÖ  2  ‚ãÖ
:  ‚ãÖ  ‚ãÖ  ‚ãÖ

And standard array methods are applicable

#+begin_src julia
# `A` is the dense array from earlier
A * A_sparse
#+end_src

#+RESULTS:
: 3√ó3 Matrix{Int64}:
:  0   4  1
:  0   2  4
:  0  16  7

https://docs.julialang.org/en/v1/stdlib/SparseArrays/

*** =Statistics=

#+begin_src julia 
using Statistics
#+end_src

#+RESULTS:

#+begin_src julia :results scalar
mean(A), std(A)
#+end_src

#+RESULTS:
: (3.6666666666666665, 2.7386127875258306)

https://docs.julialang.org/en/v1/stdlib/Statistics/

*** =Distributed=

Functionality for parallel computation across workers (either local or remote)

#+begin_src julia 
using Distributed
nprocs()
#+end_src

#+RESULTS:
: 1

#+begin_src julia
# Spawn a local worker
addprocs(1)
#+end_src

#+RESULTS:
: 1-element Vector{Int64}:
:  2

#+begin_src julia
# Spawn a remote worker (this machine won't work on your computer)
addprocs(["tor@beastly"], tunnel=true, dir="/tmp/")
#+end_src

#+RESULTS:
: 1-element Vector{Int64}:
:  3

#+begin_src julia
nprocs()
#+end_src

#+RESULTS:
: 3

#+REVEAL: split

#+begin_src julia
# Define something on all workers
@everywhere function hostname_and_number(i)
    # Execute shell command on worker to get hostname.
    # NOTE: Using `...` syntax for shell commands.
    # This creates a `Cmd`, which is run once we call `read on it.
    hostname = read(`hostname`, String)
    # Return a tuple of worker ID, hostname and the number.
    return (myid(), i, chomp(hostname))
end
#+end_src

#+RESULTS:

#+begin_src julia
# Run the function on all workers
pmap(hostname_and_number, 1:12)
#+end_src

#+RESULTS:
#+begin_example
12-element Vector{Tuple{Int64, Int64, SubString{String}}}:
 (2, 1, "tor-Prestige-15-A10SC")
 (3, 2, "beastly")
 (2, 3, "tor-Prestige-15-A10SC")
 (3, 4, "beastly")
 (2, 5, "tor-Prestige-15-A10SC")
 (2, 6, "tor-Prestige-15-A10SC")
 (2, 7, "tor-Prestige-15-A10SC")
 (2, 8, "tor-Prestige-15-A10SC")
 (2, 9, "tor-Prestige-15-A10SC")
 (2, 10, "tor-Prestige-15-A10SC")
 (2, 11, "tor-Prestige-15-A10SC")
 (2, 12, "tor-Prestige-15-A10SC")
#+end_example

https://docs.julialang.org/en/v1/stdlib/Distributed/

*** =Logging=

#+begin_src julia 
A = ones(Int, 4, 4)
v = ones(100)
@info "Some variables"  A  s=sum(v)
#+end_src

#+RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mSome variables
: [36m[1m‚îÇ [22m[39m  A =
: [36m[1m‚îÇ [22m[39m   4√ó4 Matrix{Int64}:
: [36m[1m‚îÇ [22m[39m    1  1  1  1
: [36m[1m‚îÇ [22m[39m    1  1  1  1
: [36m[1m‚îÇ [22m[39m    1  1  1  1
: [36m[1m‚îÇ [22m[39m    1  1  1  1
: [36m[1m‚îî [22m[39m  s = 100.0

https://docs.julialang.org/en/v1/stdlib/Logging/

** TASK Estimate $\pi$

[[./assets/outputs/more-julia/pi.gif]]

*Extra:* Parallelize it.


#+begin_src julia :exports (by-backend (reveal "none") (t "code")) :tangle yes
# Some space so you don't cheat.



















# Are you sure?
#+end_src

#+RESULTS:


** SOLUTION Estimate $\pi$

Well, Julia has irrational numbers built-in

#+begin_src julia
œÄ
#+end_src

#+RESULTS:
: œÄ = 3.1415926535897...

So you could just do

#+begin_src julia
Float64(œÄ)
#+end_src

#+RESULTS:
: 3.141592653589793

But that's not fair.

#+begin_src julia 
num_within = 0; num_total = 1_000_000
for i in 1:num_total
    x = 2 .* rand(2) .- 1
    if norm(x) < 1
        num_within += 1
    end
end
# Area of a circle = œÄr^2 = œÄ * (1/2)^2 = œÄ/4
4 * num_within / num_total
#+end_src

#+RESULTS:
: 3.140156

#+begin_src julia :exports none :exports none :tangle no
using StatsPlots

ts = -œÄ:0.01:œÄ
p = plot(
    cos.(ts), sin.(ts);
    label="",
    size=(400, 400),
    xlim=(-1.1, 1.1),
    ylim=(-1.1, 1.1),
    ticks=:none,
    border=:none
)

anim = @animate for i=1:100
    x, y = 2 .* rand(2) .- 1
    c = x^2 + y^2 < 1 ? :green : :red
    scatter!(p, [x], [y], color=c, label="", markersize=2, markerstrokewidth=0.1)
    p
end every 1
gif(anim, outputdir("pi.gif"));
#+end_src

#+RESULTS:
: [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mSaved animation to /drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop/assets/outputs/more-julia/pi.gif

[[./assets/outputs/more-julia/pi.gif]]

* Scientific computing ecosystem
#+HTML: <div class="side-by-side">
- [[https://dataframes.juliadata.org/stable/][DataFrames.jl]], etc.
- [[https://docs.juliaplots.org/stable/][Plots.jl]], etc.
- [[https://juliastats.org/Distributions.jl/stable/][Distributions.jl]], etc.
- [[https://docs.sciml.ai/Optimization/stable/][Optimization.jl]] and all it contains
#+HTML: </div>

#+HTML: <div class="side-by-side">
- [[https://docs.sciml.ai/DiffEqDocs/stable/][DifferentialEquations.jl]]
- Deep learning, e.g. [[https://fluxml.ai/Flux.jl/stable/][Flux.jl]]
- Automatic Differentiation
- BenchmarkTools.jl
#+HTML: </div>

And more, of course

* Running example

An outbreak of influenza A (H1N1) in 1978 at a British boarding school

- 763 male students -> 512 of which became ill
- Reported that one infected boy started the epidemic
- Observations are number of boys in bed over 14 days

Data are freely available in the R package =outbreaks=, maintained as part of the [[http://www.repidemicsconsortium.org/][R Epidemics Consortium]]

* DataFrames.jl

#+begin_src julia :display text/plain
using DataFrames
#+end_src

#+RESULTS:

In Julia, the go-to for working with datasets is =DataFrames.jl=

#+HTML: <div class="small-text">

If you don't want to let go of the =tidyverse= and you don't mind a bunch of magic, you can use https://github.com/TidierOrg/Tidier.jl

#+HTML: </div>

#+REVEAL: split

If you're already familiar with equivalents in R or Python, the following is a great reference: https://dataframes.juliadata.org/stable/man/comparisons/

#+DOWNLOADED: file:///tmp/Spectacle.paVgAL/Screenshot_20230915_114925.png @ 2023-09-15 11:49:35
#+attr_org: :width 600px
[[file:.more-julia/attachments/2023-09-15_11-49-35_Screenshot_20230915_114925.png]]

#+REVEAL: split

There are many different ways to construct a =DataFrame=

#+begin_src julia :display text/plain
df = DataFrame(A=1:3, B=5:7, fixed=1)
#+end_src

#+RESULTS:
: [1m3√ó3 DataFrame[0m
: [1m Row [0m‚îÇ[1m A     [0m[1m B     [0m[1m fixed [0m
:      ‚îÇ[90m Int64 [0m[90m Int64 [0m[90m Int64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ     1      5      1
:    2 ‚îÇ     2      6      1
:    3 ‚îÇ     3      7      1

#+begin_src julia :display text/plain
DataFrame(Dict("A" => 1:3, "B" => 5:7, "fixed" => 1))
#+end_src

#+RESULTS:
: [1m3√ó3 DataFrame[0m
: [1m Row [0m‚îÇ[1m A     [0m[1m B     [0m[1m fixed [0m
:      ‚îÇ[90m Int64 [0m[90m Int64 [0m[90m Int64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ     1      5      1
:    2 ‚îÇ     2      6      1
:    3 ‚îÇ     3      7      1

Notice that columns are typed

#+REVEAL: split

Then we can interact with the =DataFrame= in a variety of ways

** Indexing

#+begin_src julia 
df.A
#+end_src

#+RESULTS:
: 3-element Vector{Int64}:
:  1
:  2
:  3

#+begin_src julia
df."A"  # useful when column-names aren't valid Julia symbols
#+end_src

#+RESULTS:
: 3-element Vector{Int64}:
:  1
:  2
:  3

#+begin_src julia
df[:, "A"]
#+end_src

#+RESULTS:
: 3-element Vector{Int64}:
:  1
:  2
:  3

#+REVEAL: split

#+begin_src julia :display text/plain
df[:, [:A, :B]]
#+end_src

#+RESULTS:
: [1m3√ó2 DataFrame[0m
: [1m Row [0m‚îÇ[1m A     [0m[1m B     [0m
:      ‚îÇ[90m Int64 [0m[90m Int64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ     1      5
:    2 ‚îÇ     2      6
:    3 ‚îÇ     3      7

#+begin_src julia :display text/plain
df[:, Not(:fixed)]
#+end_src

#+RESULTS:
: [1m3√ó2 DataFrame[0m
: [1m Row [0m‚îÇ[1m A     [0m[1m B     [0m
:      ‚îÇ[90m Int64 [0m[90m Int64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ     1      5
:    2 ‚îÇ     2      6
:    3 ‚îÇ     3      7

#+REVEAL: split

*TODO: Just add a list of methods*

#+begin_src julia
names(df)
#+end_src

#+RESULTS:
: 3-element Vector{String}:
:  "A"
:  "B"
:  "fixed"

** Actual data

Let's load the actual data

Our data is a CSV file

#+begin_src julia 
readdir("data")
#+end_src

#+RESULTS:
: 3-element Vector{String}:
:  "influenza_england_1978_school.csv"
:  "pest_data.csv"
:  "time-series.csv"

Functionality for different file formats is usually provided by separate packages:
- [[https://github.com/JuliaData/CSV.jl][CSV.jl]]
- [[https://github.com/JuliaData/Arrow.jl][Arrow.jl]] (Apache Arrow)
- [[https://github.com/JuliaData/RData.jl][RData.jl]] (R data files)
- [[https://felipenoris.github.io/XLSX.jl/stable/][XLSX.jl]] (Excel files)
- And more.

#+REVEAL: split

In our case, we're working with a CSV file, so we'll use =CSV.jl=:

#+begin_src julia :display text/plain
using CSV
datafile = CSV.File(joinpath("data", "influenza_england_1978_school.csv"));
#+end_src

#+RESULTS:

And then we can convert this =CSV.File= into a =DataFrame=

#+begin_src julia :display text/plain
data = DataFrame(datafile)
#+end_src

#+RESULTS:
#+begin_example
[1m14√ó4 DataFrame[0m
[1m Row [0m‚îÇ[1m Column1 [0m[1m date       [0m[1m in_bed [0m[1m convalescent [0m
     ‚îÇ[90m Int64   [0m[90m Date       [0m[90m Int64  [0m[90m Int64        [0m
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ       1  1978-01-22       3             0
   2 ‚îÇ       2  1978-01-23       8             0
   3 ‚îÇ       3  1978-01-24      26             0
   4 ‚îÇ       4  1978-01-25      76             0
   5 ‚îÇ       5  1978-01-26     225             9
   6 ‚îÇ       6  1978-01-27     298            17
   7 ‚îÇ       7  1978-01-28     258           105
   8 ‚îÇ       8  1978-01-29     233           162
   9 ‚îÇ       9  1978-01-30     189           176
  10 ‚îÇ      10  1978-01-31     128           166
  11 ‚îÇ      11  1978-02-01      68           150
  12 ‚îÇ      12  1978-02-02      29            85
  13 ‚îÇ      13  1978-02-03      14            47
  14 ‚îÇ      14  1978-02-04       4            20
#+end_example

#+REVEAL: split

#+begin_quote
Woah, how does this work? We just passed a =CSV.File= to =DataFrames.DataFrame=, and _it just works_?!
#+end_quote

Aye, that's right

This is thanks to [[https://tables.juliadata.org/stable/][Tables.jl]], a simple interface for tabular data

Such light-weight interface packages allow modules to seemlessly interact with each other without explicit dependencies

This is a very typical pattern in Julia

* Distributions.jl

#+begin_src julia
using Distributions
#+end_src

#+RESULTS:

In Julia, the go-to for working with distributions is [[https://juliastats.org/Distributions.jl/stable/][=Distributions.jl=]]

This package provides a large number of distributions

Used throughout the Julia community, e.g. =Turing= uses this

#+REVEAL: split

#+begin_src julia 
dist = Normal()
#+end_src

#+RESULTS:
: Normal{Float64}(Œº=0.0, œÉ=1.0)

#+begin_src julia :results scalar
mean(dist), var(dist)
#+end_src

#+RESULTS:
: (0.0, 1.0)

Remeber the =Random.rand= function from earlier? This now also accepts a =Distribution=

#+begin_src julia 
x = rand(dist)
#+end_src

#+RESULTS:
: -1.012052713069845

#+REVEAL: split

#+begin_src julia 
logpdf(dist, x)
#+end_src

#+RESULTS:
: -1.4310638802206896

#+begin_src julia
cdf(dist, 0.5)
#+end_src

#+RESULTS:
: 0.6914624612740131

#+begin_src julia 
quantile.(Normal(), [0.05, 0.5, 0.95])
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  -1.6448536269514724
:   0.0
:   1.6448536269514717

There is also maximum likelihood estimation (MLE)

#+begin_src julia
xs = rand(Normal(1, 2), 100)
fit(Normal, xs)
#+end_src

#+RESULTS:
: Normal{Float64}(Œº=1.2893234567407714, œÉ=1.7249112221240255)

#+REVEAL: split

But exactly what distributions are there?

Well, we can just check by inspecting the subtypes of =Distribution=

#+begin_src julia
# Filter away abstract types.
nonabstract_dist_subtypes = filter(!isabstracttype, subtypes(Distribution))
# Filter away types which are not found in Distributions.jl.
dist_types_from_distributions = filter(
    Base.Fix1(hasproperty, Distributions) ‚àò Symbol,
    nonabstract_dist_subtypes
)
#+end_src

#+RESULTS:
#+begin_example
84-element Vector{Any}:
 Arcsine
 Bernoulli
 BernoulliLogit
 Beta
 BetaBinomial
 BetaPrime
 Binomial
 Biweight
 Cauchy
 Chernoff
 Chi
 Chisq
 Cosine
 ‚ãÆ
 Soliton
 StudentizedRange
 SymTriangularDist
 TDist
 TriangularDist
 Triweight
 Truncated
 Uniform
 VonMises
 VonMisesFisher
 Weibull
 Wishart
#+end_example

#+REVEAL: split

Okay, there are a bit too many

Let's separate between different variate types

#+begin_src julia
filter(x -> x <: UnivariateDistribution, dist_types_from_distributions)
#+end_src

#+RESULTS:
#+begin_example
70-element Vector{Any}:
 Arcsine
 Bernoulli
 BernoulliLogit
 Beta
 BetaBinomial
 BetaPrime
 Binomial
 Biweight
 Cauchy
 Chernoff
 Chi
 Chisq
 Cosine
 ‚ãÆ
 SkewNormal
 SkewedExponentialPower
 Soliton
 StudentizedRange
 SymTriangularDist
 TDist
 TriangularDist
 Triweight
 Truncated
 Uniform
 VonMises
 Weibull
#+end_example

#+REVEAL: split

Too many

Let's convert it into a =Matrix= and force Julia to show all columns

#+begin_src julia
show(
    IOContext(stdout, :limit => false),
    "text/plain",
    reshape(filter(x -> x <: UnivariateDistribution, dist_types_from_distributions), 10, :)
)
#+end_src

#+RESULTS:
#+begin_example
10√ó7 Matrix{Any}:
 Arcsine         Chi                    Frechet                  KSDist       LogitNormal            PGeneralizedGaussian    Soliton
 Bernoulli       Chisq                  Gamma                    KSOneSided   NegativeBinomial       Pareto                  StudentizedRange
 BernoulliLogit  Cosine                 GeneralizedExtremeValue  Kolmogorov   NoncentralBeta         Poisson                 SymTriangularDist
 Beta            Dirac                  GeneralizedPareto        Kumaraswamy  NoncentralChisq        PoissonBinomial         TDist
 BetaBinomial    DiscreteNonParametric  Geometric                Laplace      NoncentralF            Rayleigh                TriangularDist
 BetaPrime       DiscreteUniform        Gumbel                   Levy         NoncentralT            Rician                  Triweight
 Binomial        Epanechnikov           Hypergeometric           Lindley      Normal                 Semicircle              Truncated
 Biweight        Erlang                 InverseGamma             LogNormal    NormalCanon            Skellam                 Uniform
 Cauchy          Exponential            InverseGaussian          LogUniform   NormalInverseGaussian  SkewNormal              VonMises
 Chernoff        FDist                  JohnsonSU                Logistic     OrderStatistic         SkewedExponentialPower  Weibull
#+end_example

#+REVEAL: split

Now for multivariate distributions

#+begin_src julia
filter(x -> x <: MultivariateDistribution, dist_types_from_distributions)
#+end_src

#+RESULTS:
: 6-element Vector{Any}:
:  Dirichlet
:  DirichletMultinomial
:  JointOrderStatistics
:  Multinomial
:  Product
:  VonMisesFisher

#+HTML: <div class="fragment (appear)>"
And matrix distributions

#+begin_src julia
filter(x -> x <: MatrixDistribution, dist_types_from_distributions)
#+end_src

#+RESULTS:
: 7-element Vector{Any}:
:  InverseWishart
:  LKJ
:  MatrixBeta
:  MatrixFDist
:  MatrixNormal
:  MatrixTDist
:  Wishart
#+HTML: </div>

* Plots.jl

#+begin_src julia 
using Plots
#+end_src

#+RESULTS:

The most commonly used plotting library is [[https://docs.juliaplots.org/stable/][Plots.jl]]

#+REVEAL: split

Has many backends, including:
- GR
- PyPlot
- Plotly
- Unicode
- PGFPlots
- And more

_But_ the code is the same for all backends

#+begin_src julia
# GR is used by default
Plots.backend()
#+end_src

#+RESULTS:
: Plots.GRBackend()

#+REVEAL: split

#+HTML: <div class="side-by-side">

#+HTML: <div>

#+begin_src julia
p1 = plot(1:10, rand(10), size=(450, 200))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/16d623348c3f18f48e1304d2e2300b5e289e1b86.svg]]

#+HTML: </div>

#+HTML: <div>

#+begin_src julia
p2 = scatter(1:10, rand(10), size=(450, 200))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/7cc0dffb8818815a0ac1bd1a2ed82b37365dceba.svg]]

#+HTML: </div>

#+HTML: </div>

#+begin_src julia
plot(p1, p2, layout=(1, 2), size=(800, 200))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/98e1cf87a13e33c358badda9dd87043e02cc227a.svg]]

#+REVEAL: split

A neat example from [[https://docs.juliaplots.org/stable/#simple-is-beautiful][the docs]]

#+begin_src julia 
# Define the Lorenz attractor
Base.@kwdef mutable struct Lorenz
    dt::Float64 = 0.02
    œÉ::Float64 = 10
    œÅ::Float64 = 28
    Œ≤::Float64 = 8/3
    x::Float64 = 1
    y::Float64 = 1
    z::Float64 = 1
end

function step!(l::Lorenz)
    dx = l.œÉ * (l.y - l.x)
    dy = l.x * (l.œÅ - l.z) - l.y
    dz = l.x * l.y - l.Œ≤ * l.z
    l.x += l.dt * dx
    l.y += l.dt * dy
    l.z += l.dt * dz
end

attractor = Lorenz()
#+end_src

#+RESULTS:
: Lorenz(0.02, 10.0, 28.0, 2.6666666666666665, 1.0, 1.0, 1.0)

#+REVEAL: split

#+begin_src julia :eval no
# Initialize a 3D plot with 1 empty series
plt = plot3d(
    1,
    xlim = (-30, 30),
    ylim = (-30, 30),
    zlim = (0, 60),
    title = "Lorenz Attractor",
    legend = false,
    marker = 2,
)

# Build an animated gif by pushing new points to the plot, saving every 10th frame
anim = @animate for i=1:1500
    step!(attractor)
    push!(plt, attractor.x, attractor.y, attractor.z)
end every 10
gif(anim, outputdir("lorenz.gif"));
#+end_src

#+RESULTS:
: [ Info: Saved animation to /drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop/assets/outputs/more-julia/lorenz.gif

#+REVEAL: split

[[./assets/outputs/more-julia/lorenz.gif]]

** Ecosystem

Plots.jl also has a very nice recipe-system

Allows you to define how to plot your own types

As a result, packages often define customized plotting recipes for their types

https://docs.juliaplots.org/latest/ecosystem/#Community-packages

** StatsPlots.jl

For us, [[https://github.com/JuliaPlots/StatsPlots.jl][StatsPlots.jl]] is particularly relevant

#+begin_src julia 
using StatsPlots
#+end_src

#+RESULTS:

It contains custom plotting functionality for dataframes and distibutions

#+REVEAL: split

#+begin_src julia 
plot(Normal())
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/348bd16b3b818fcfbedfaf14f50cb941ca1b7ca3.svg]]

#+REVEAL: split

It also contains the macro =@df= for working with dataframes

#+begin_src julia 
@df data scatter(:date, :in_bed, label=nothing, ylabel="Number of students in bed")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/1425b863a8661542a4b00f6bce46205730eb2531.svg]]

** TASK Recreate the above plot using standard Plots.jl functionality :noexport:

That is, don't use =@df data ...=, but call the =scatter= function directly

* DifferentialEquations.jl

#+begin_src julia 
using DifferentialEquations
#+end_src

#+RESULTS:

Everything related to differential equations is provided by [[https://docs.sciml.ai/DiffEqDocs/stable/][=DifferentialEquations.jl=]] and the [[https://sciml.ai/][SciML ecosystem]]

#+REVEAL: split

And I really do mean [[https://docs.sciml.ai/DiffEqDocs/stable/][/everything/]]

#+HTML: <div class="side-by-side">

#+DOWNLOADED: file:///tmp/Spectacle.jWiYMk/Screenshot_20230119_194737.png @ 2023-01-19 19:48:23
[[file:assets/attachments/2023-01-19_19-48-23_Screenshot_20230119_194737.png]]

#+DOWNLOADED: file:///tmp/Spectacle.jWiYMk/Screenshot_20230119_194838.png @ 2023-01-19 19:48:41
[[file:assets/attachments/2023-01-19_19-48-41_Screenshot_20230119_194838.png]]

#+HTML: </div>


** Differential equations

Suppose we have some function $f$ which describes how a state $x$ evolves wrt. $t$
\begin{equation*}
\frac{\mathrm{d} x}{\mathrm{d} t} = f(x, t)
\end{equation*}
which we then need to integrate to obtain the actual state at some time $t$
\begin{equation*}
x(t) = \int_{0}^{t} \frac{\mathrm{d} x}{\mathrm{d} t} \mathrm{d} t = \int_{0}^{t} f(x, t) \mathrm{d} t
\end{equation*}

In many interesting scenarios numerical methods are required to obtain $x(t)$

** Example: SIR model
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Example-SIR-model
:CUSTOM_ID: 2023-01-29-16-57-28-Example-SIR-model
:END:
One particular example of an (ordinary) differential equation that you might have seen recently is the *SIR model* used in epidemiology

#+DOWNLOADED: file:///home/tor/Downloads/sir_illu.png @ 2023-01-19 19:56:00
#+ATTR_ORG: :width 600
#+CAPTION: https://covid19.uclaml.org/model.html (2023-01-19)
[[file:assets/attachments/2023-01-19_19-56-00_sir_illu.png]]

#+REVEAL: split

The temporal dynamics of the sizes of each of the compartments are governed by the following system of ODEs:
\begin{equation*}
\begin{split}
  \frac{\mathrm{d} S}{\mathrm{d} t} &= - \beta S \frac{I}{N} \\
  \frac{\mathrm{d} I}{\mathrm{d} t} &= \beta S \frac{I}{N} - \gamma I \\
  \frac{\mathrm{d} R}{\mathrm{d} t} &= \gamma I
\end{split}
\end{equation*}
where
- $S(t)$ is the number of people susceptible to becoming infected,
- $I(t)$ is the number of people currently infected,
- $R(t)$ is the number of recovered people,
- $Œ≤$ is the constant rate of infectious contact between people,
- $\gamma$ the constant recovery rate of infected individuals

#+REVEAL: split

Converting this ODE into code is just

#+begin_src julia
const N = 763 # size of population

function SIR!(
    du,  # buffer for the updated differential equation
    u,   # current state
    p,   # parameters
    t    # current time
)
    S, I, R = u
    Œ≤, Œ≥ = p

    du[1] = dS = -Œ≤ * I * S / N
    du[2] = dI = Œ≤ * I * S / N - Œ≥ * I
    du[3] = dR = Œ≥ * I
end
#+end_src

#+RESULTS:
: SIR! (generic function with 1 method)

Not too bad!

#+REVEAL: split

Initial conditions are then
\begin{equation*}
\begin{split}
  S(0) &= N - 1 \\
  I(0) &= 1 \\
  R(0) &= 0
\end{split}
\end{equation*}
and we want to integrate from $t = 0$ to $t = 14$

#+begin_src julia
# Include 0 because that's the initial condition before any observations.
tspan = (0.0, 14.0)

# Initial conditions are:
#   S(0) = N - 1; I(0) = 1; R(0) = 0
u0 = [N - 1, 1, 0.0]
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:  762.0
:    1.0
:    0.0

#+REVEAL: split

Now we just need to define the overall problem and we can solve:

#+begin_src julia
# Just to check that everything works, we'll just use some "totally random" values for Œ≤ and Œ≥:
problem_sir = let Œ≤ = 2.0, Œ≥ = 0.6
    ODEProblem(SIR!, u0, tspan, (Œ≤, Œ≥))
end
#+end_src

#+RESULTS:
: [38;2;86;182;194mODEProblem[0m with uType [38;2;86;182;194mVector{Float64}[0m and tType [38;2;86;182;194mFloat64[0m. In-place: [38;2;86;182;194mtrue[0m
: timespan: (0.0, 14.0)
: u0: 3-element Vector{Float64}:
:  762.0
:    1.0
:    0.0

#+REVEAL: split

Aaaand

#+begin_src julia
sol = solve(problem_sir)
#+end_src

#+RESULTS:
#+begin_example
retcode: Success
Interpolation: specialized 4th order "free" interpolation, specialized 2nd order "free" stiffness-aware interpolation
t: 23-element Vector{Float64}:
  0.0
  0.0023558376404244326
  0.025914214044668756
  0.11176872871946908
  0.26714420676761075
  0.47653584778586056
  0.7436981238065388
  1.0701182881347182
  1.4556696154809898
  1.8994815718103506
  2.4015425820305163
  2.9657488203418048
  3.6046024613854746
  4.325611232479916
  5.234036476235002
  6.073132270491685
  7.323851265223563
  8.23100744184026
  9.66046960467715
 11.027717843180652
 12.506967592177675
 13.98890399536329
 14.0
u: 23-element Vector{Vector{Float64}}:
 [762.0, 1.0, 0.0]
 [761.9952867607622, 1.003297407481751, 0.001415831756055325]
 [761.9472927630898, 1.036873767352754, 0.015833469557440357]
 [761.7584189579304, 1.1690001128296739, 0.0725809292398516]
 [761.353498610305, 1.4522140137552049, 0.19428737593979384]
 [760.6490369821046, 1.9447820690728455, 0.4061809488225752]
 [759.3950815454128, 2.8210768113583082, 0.7838416432288186]
 [757.0795798160242, 4.437564277195732, 1.4828559067800167]
 [752.6094742865345, 7.552145919430467, 2.8383797940350495]
 [743.573784947305, 13.823077731564027, 5.603137321131049]
 [724.5575481927715, 26.909267078762316, 11.533184728466205]
 [683.6474029897502, 54.51612001957392, 24.836476990675976]
 [598.1841629858786, 109.41164143668018, 55.40419557744127]
 [450.08652743810205, 192.396449154863, 120.51702340703504]
 [259.11626253270623, 256.9925778114915, 246.89115965580237]
 [148.3573731526537, 240.10301213899098, 374.53961470835543]
 [76.52998017846475, 160.6373332952353, 525.8326865263001]
 [55.70519994004921, 108.7634182279299, 598.531381832021]
 [41.39587834423381, 55.09512088924873, 666.5090007665176]
 [35.87067243374374, 27.821838135708532, 699.3074894305479]
 [33.252184333490774, 13.087185981359177, 716.6606296851502]
 [32.08996839417716, 6.105264616193066, 724.8047669896299]
 [32.08428686823946, 6.070415830241046, 724.8452973015196]
#+end_example


#+REVEAL: split

We didn't specify a solver

DifferentialEquations.jl uses =AutoTsit5(Rosenbrock32())= by default 

Which is a composition between

- =Tsit5= (4th order Runge-Kutta), and
- =Rosenbrock32= (3rd order stiff solver)

with automatic switching between the two

#+REVEAL: split

=AutoTsit5(Rosenbrock32())= covers many use-cases well, but see

- https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/
- https://www.stochasticlifestyle.com/comparison-differential-equation-solver-suites-matlab-r-julia-python-c-fortran/

for more info on choosing a solver

#+REVEAL: split

This is the resulting solution

#+begin_src julia
plot(
    sol,
    linewidth=2, xaxis="Time in days", label=["Suspectible" "Infected" "Recovered"],
    alpha=0.5, size=(500, 300)
)
scatter!(1:14, data.in_bed, label="Data", color="black")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/780e8cc1c00812abcfba1fe711f0a8b7b168b7e7.svg]]

This doesn't really match the data though; let's do better

#+REVEAL: split

*Approach #1:* find optimal values of $\beta$ and $\gamma$ by minimizing some loss, e.g. sum-of-squares

\begin{equation*}
\ell(\beta, \gamma) = \sum_{i = 1}^{14} \bigg( F(u_0, t_i;\ \beta, \gamma) - y_i \bigg)^2
\end{equation*}

where $\big( y_i \big)_{i = 1}^{14}$ are the observations, $F$ is the integrated system

** Optimization.jl

In Julia, there are /tons/ of packages for performing all kinds of optimization

[[https://docs.sciml.ai/Optimization/stable/][Optimization.jl]] provides a convenient interface to many of them

#+begin_src julia 
using Optimization
#+end_src

#+RESULTS:
#+begin_example
[91m[1m‚îå [22m[39m[91m[1mError: [22m[39mError during package callback
[91m[1m‚îÇ [22m[39m  exception =
[91m[1m‚îÇ [22m[39m   [0m1-element ExceptionStack:
[91m[1m‚îÇ [22m[39m   On worker 3:
[91m[1m‚îÇ [22m[39m   ArgumentError: Package Optimization [7f7a1694-90dd-40f0-9382-eb1efda571ba] is required but does not seem to be installed:
[91m[1m‚îÇ [22m[39m    - Run `Pkg.instantiate()` to install all recorded dependencies.
[91m[1m‚îÇ [22m[39m   
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m     [1] [0m[1m_require[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1774[24m[39m
[91m[1m‚îÇ [22m[39m     [2] [0m[1m_require_prelocked[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1660[24m[39m
[91m[1m‚îÇ [22m[39m     [3] [0m[1m_require_prelocked[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1658[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [4] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mlock.jl:267[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [5] [0m[1mrequire[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1655[24m[39m
[91m[1m‚îÇ [22m[39m     [6] [0m[1m#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mDistributed.jl:83[24m[39m
[91m[1m‚îÇ [22m[39m     [7] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [8] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m
[91m[1m‚îÇ [22m[39m     [9] [0m[1m#114[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:301[24m[39m
[91m[1m‚îÇ [22m[39m    [10] [0m[1mrun_work_thunk[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:70[24m[39m
[91m[1m‚îÇ [22m[39m    [11] [0m[1mrun_work_thunk[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:79[24m[39m
[91m[1m‚îÇ [22m[39m    [12] [0m[1m#100[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mtask.jl:514[24m[39m
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m     [1] [0m[1msync_end[22m[0m[1m([22m[90mc[39m::[0mChannel[90m{Any}[39m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mtask.jl:445[24m[39m
[91m[1m‚îÇ [22m[39m     [2] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mtask.jl:477[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [3] [0m[1m_require_callback[22m[0m[1m([22m[90mmod[39m::[0mBase.PkgId[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [35mDistributed[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mDistributed.jl:77[24m[39m
[91m[1m‚îÇ [22m[39m     [4] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [5] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [6] [0m[1mrun_package_callbacks[22m[0m[1m([22m[90mmodkey[39m::[0mBase.PkgId[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1129[24m[39m
[91m[1m‚îÇ [22m[39m     [7] [0m[1m_require_prelocked[22m[0m[1m([22m[90muuidkey[39m::[0mBase.PkgId, [90menv[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1667[24m[39m
[91m[1m‚îÇ [22m[39m     [8] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1648[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [9] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mlock.jl:267[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [10] [0m[1mrequire[22m[0m[1m([22m[90minto[39m::[0mModule, [90mmod[39m::[0mSymbol[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1611[24m[39m
[91m[1m‚îÇ [22m[39m    [11] [0m[1meval[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mboot.jl:370[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [12] [0m[1minclude_string[22m[0m[1m([22m[90mmapexpr[39m::[0mtypeof(REPL.softscope), [90mmod[39m::[0mModule, [90mcode[39m::[0mString, [90mfilename[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1903[24m[39m
[91m[1m‚îÇ [22m[39m    [13] [0m[1msoftscope_include_string[22m[0m[1m([22m[90mm[39m::[0mModule, [90mcode[39m::[0mString, [90mfilename[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [36mSoftGlobalScope[39m [90m~/.julia/packages/SoftGlobalScope/u4UzH/src/[39m[90m[4mSoftGlobalScope.jl:65[24m[39m
[91m[1m‚îÇ [22m[39m    [14] [0m[1mexecute_request[22m[0m[1m([22m[90msocket[39m::[0mZMQ.Socket, [90mmsg[39m::[0mIJulia.Msg[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m~/.julia/packages/IJulia/Vo51o/src/[39m[90m[4mexecute_request.jl:67[24m[39m
[91m[1m‚îÇ [22m[39m    [15] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [16] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [17] [0m[1meventloop[22m[0m[1m([22m[90msocket[39m::[0mZMQ.Socket[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m~/.julia/packages/IJulia/Vo51o/src/[39m[90m[4meventloop.jl:8[24m[39m
[91m[1m‚îÇ [22m[39m    [18] [0m[1m(::IJulia.var"#15#18")[22m[0m[1m([22m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m./[39m[90m[4mtask.jl:514[24m[39m
[91m[1m‚îî [22m[39m[90m@ Base loading.jl:1134[39m
#+end_example

#+DOWNLOADED: file:///tmp/Spectacle.paVgAL/Screenshot_20230915_130639.png @ 2023-09-15 13:06:48
#+CAPTION: https://docs.sciml.ai/Optimization/stable/#Overview-of-the-Optimizers (2023-09-15)
#+attr_org: :width 600px
#+attr_html: :width 400px
[[file:.more-julia/attachments/2023-09-15_13-06-48_Screenshot_20230915_130639.png]]


#+REVEAL: split

#+HTML: <div class="small-text">

Recall we want to solve

\begin{equation*}
\min_{\beta, \gamma} \sum_{i = 1}^{14} \bigg( F(u_0, t_i;\ \beta, \gamma) - y_i \bigg)^2
\end{equation*}

where $\big( y_i \big)_{i = 1}^{14}$ are the observations, $F$ is the integrated system

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

First we define the loss

#+begin_src julia
# Define the loss function.
function loss_sir(problem_orig, p)
    # `remake` just, well, remakes the `problem` with parameters `p` replaced.
    problem = remake(problem_orig, p=p)
    # To ensure we get solutions _exactly_ at the timesteps of interest,
    # i.e. every day we have observations, we use `saveat=1` to tell `solve`
    # to save at every timestep (which is one day).
    sol = solve(problem, saveat=1)
    # Extract the 2nd state, the (I)infected, for the dates with observations.
    sol_for_observed = sol[2, 2:15]
    # Compute the sum-of-squares of the infected vs. data.
    return sum(abs2.(sol_for_observed - data.in_bed))
end
#+end_src

#+RESULTS:
: loss_sir (generic function with 1 method)

#+HTML: </div>

#+REVEAL: split

Then we can define our =OptimizationProblem=

#+begin_src julia 
opt_problem = OptimizationProblem(
    OptimizationFunction(
        (p,_) -> loss_sir(problem_sir, p), # function to minimize
        Optimization.AutoForwardDiff()     # use ForwardDiff for automatic differentiation
    ),
    [2.0, 0.5],                            # initial values
    lb = [0, 0],                           # lower bounds on variables
    ub = [Inf, Inf],                       # upper bounds on variables
) 
#+end_src

#+RESULTS:
: [38;2;86;182;194mOptimizationProblem[0m. In-place: [38;2;86;182;194mtrue[0m
: u0: 2-element Vector{Float64}:
:  2.0
:  0.5

#+REVEAL: split

And for general /deterministic/ problems, [[https://julianlsolvers.github.io/Optim.jl/stable/][Optim.jl]] is a good choice

#+begin_src julia
using OptimizationOptimJL
opt = solve(opt_problem, NelderMead())
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
[91m[1m‚îå [22m[39m[91m[1mError: [22m[39mError during package callback
[91m[1m‚îÇ [22m[39m  exception =
[91m[1m‚îÇ [22m[39m   [0m1-element ExceptionStack:
[91m[1m‚îÇ [22m[39m   On worker 3:
[91m[1m‚îÇ [22m[39m   ArgumentError: Package OptimizationOptimJL [36348300-93cb-4f02-beb5-3c3902f8871e] is required but does not seem to be installed:
[91m[1m‚îÇ [22m[39m    - Run `Pkg.instantiate()` to install all recorded dependencies.
[91m[1m‚îÇ [22m[39m   
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m     [1] [0m[1m_require[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1774[24m[39m
[91m[1m‚îÇ [22m[39m     [2] [0m[1m_require_prelocked[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1660[24m[39m
[91m[1m‚îÇ [22m[39m     [3] [0m[1m_require_prelocked[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1658[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [4] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mlock.jl:267[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [5] [0m[1mrequire[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1655[24m[39m
[91m[1m‚îÇ [22m[39m     [6] [0m[1m#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mDistributed.jl:83[24m[39m
[91m[1m‚îÇ [22m[39m     [7] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [8] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m
[91m[1m‚îÇ [22m[39m     [9] [0m[1m#114[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:301[24m[39m
[91m[1m‚îÇ [22m[39m    [10] [0m[1mrun_work_thunk[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:70[24m[39m
[91m[1m‚îÇ [22m[39m    [11] [0m[1mrun_work_thunk[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mprocess_messages.jl:79[24m[39m
[91m[1m‚îÇ [22m[39m    [12] [0m[1m#100[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mtask.jl:514[24m[39m
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m     [1] [0m[1msync_end[22m[0m[1m([22m[90mc[39m::[0mChannel[90m{Any}[39m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mtask.jl:445[24m[39m
[91m[1m‚îÇ [22m[39m     [2] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mtask.jl:477[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [3] [0m[1m_require_callback[22m[0m[1m([22m[90mmod[39m::[0mBase.PkgId[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [35mDistributed[39m [90m~/.julia/juliaup/julia-1.9.3+0.x64.linux.gnu/share/julia/stdlib/v1.9/Distributed/src/[39m[90m[4mDistributed.jl:77[24m[39m
[91m[1m‚îÇ [22m[39m     [4] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [5] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [6] [0m[1mrun_package_callbacks[22m[0m[1m([22m[90mmodkey[39m::[0mBase.PkgId[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1129[24m[39m
[91m[1m‚îÇ [22m[39m     [7] [0m[1m_require_prelocked[22m[0m[1m([22m[90muuidkey[39m::[0mBase.PkgId, [90menv[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1667[24m[39m
[91m[1m‚îÇ [22m[39m     [8] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mloading.jl:1648[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m     [9] [0m[1mmacro expansion[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mlock.jl:267[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [10] [0m[1mrequire[22m[0m[1m([22m[90minto[39m::[0mModule, [90mmod[39m::[0mSymbol[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1611[24m[39m
[91m[1m‚îÇ [22m[39m    [11] [0m[1meval[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4mboot.jl:370[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [12] [0m[1minclude_string[22m[0m[1m([22m[90mmapexpr[39m::[0mtypeof(REPL.softscope), [90mmod[39m::[0mModule, [90mcode[39m::[0mString, [90mfilename[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:1903[24m[39m
[91m[1m‚îÇ [22m[39m    [13] [0m[1msoftscope_include_string[22m[0m[1m([22m[90mm[39m::[0mModule, [90mcode[39m::[0mString, [90mfilename[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [36mSoftGlobalScope[39m [90m~/.julia/packages/SoftGlobalScope/u4UzH/src/[39m[90m[4mSoftGlobalScope.jl:65[24m[39m
[91m[1m‚îÇ [22m[39m    [14] [0m[1mexecute_request[22m[0m[1m([22m[90msocket[39m::[0mZMQ.Socket, [90mmsg[39m::[0mIJulia.Msg[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m~/.julia/packages/IJulia/Vo51o/src/[39m[90m[4mexecute_request.jl:67[24m[39m
[91m[1m‚îÇ [22m[39m    [15] [0m[1m#invokelatest#2[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:819[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [16] [0m[1minvokelatest[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [90m./[39m[90m[4messentials.jl:816[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [17] [0m[1meventloop[22m[0m[1m([22m[90msocket[39m::[0mZMQ.Socket[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m~/.julia/packages/IJulia/Vo51o/src/[39m[90m[4meventloop.jl:8[24m[39m
[91m[1m‚îÇ [22m[39m    [18] [0m[1m(::IJulia.var"#15#18")[22m[0m[1m([22m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m    @[39m [32mIJulia[39m [90m./[39m[90m[4mtask.jl:514[24m[39m
[91m[1m‚îî [22m[39m[90m@ Base loading.jl:1134[39m
#+end_example
: u: 2-element Vector{Float64}:
:  1.6692320164955483
:  0.44348639177622445
:END:

#+begin_src julia :results scalar
Œ≤, Œª = opt
Œ≤, Œª
#+end_src

#+RESULTS:

#+REVEAL: split

#+begin_src julia
# Solve the problem with the obtained parameters.
problem_sir = remake(problem_sir, p=(Œ≤, Œª))
sol = solve(problem_sir)

# Plot the solution.
plot(sol, linewidth=2, xaxis="Time in days", label=["Susceptible" "Infected" "Recovered"], alpha=0.5)
# And the data.
scatter!(1:14, data.in_bed, label="Data", color="black")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/c4a9d9cc8632820164ac0b1c77cded80e46b9a39.svg]]

That's better than our /totally/ "random" guess from earlier!

** Example: SEIR model
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Example-SEIR-model
:CUSTOM_ID: 2023-01-29-16-57-28-Example-SEIR-model
:END:

Adding another compartment to our SIR model: the _(E)xposed_ state

\begin{equation*}
\begin{split}
  \frac{\mathrm{d} S}{\mathrm{d} t} &= - \beta S \frac{I}{N} \\
  \frac{\mathrm{d} {\color{blue} E}}{\mathrm{d} t} &= \beta S \frac{I}{N} - {\color{orange} \sigma} {\color{blue} E} \\
  \frac{\mathrm{d} I}{\mathrm{d} t} &= {\color{orange} \sigma} {\color{blue} E} - \gamma I \\
  \frac{\mathrm{d} R}{\mathrm{d} t} &= \gamma I
\end{split}
\end{equation*}

where we've added a new parameter ${\color{orange} \sigma}$ describing the fraction of people who develop observable symptoms in this time

** TASK Solve the SEIR model using Julia
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Solve-the-SEIR-model-using-Julia
:CUSTOM_ID: 2023-01-29-16-57-28-Solve-the-SEIR-model-using-Julia
:END:

#+begin_src julia :eval no
function SEIR!(
    du,  # buffer for the updated differential equation
    u,   # current state
    p,   # parameters
    t    # current time
)
    N = 763  # population

    S, E, I, R = u  # have ourselves an additional state!
    Œ≤, Œ≥, œÉ = p     # and an additional parameter!

    # TODO: Implement yah fool!
    du[1] = nothing
    du[2] = nothing
    du[3] = nothing
    du[4] = nothing
end
#+end_src

*BONUS:* find minimizers of sum-of-squares

#+begin_src julia :exports (by-backend (reveal "none") (t "code"))
# Some space so you don't cheat.



















# Are you sure?
#+end_src

#+RESULTS:

** SOLUTION Solve the SEIR model using Julia
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Solve-the-SEIR-model-using-Julia
:CUSTOM_ID: 2023-01-29-16-57-28-Solve-the-SEIR-model-using-Julia
:END:

#+begin_src julia
function SEIR!(
    du,  # buffer for the updated differential equation
    u,   # current state
    p,   # parameters
    t    # current time
)
    N = 763  # population
    S, E, I, R = u  # have ourselves an additional state!
    Œ≤, Œ≥, œÉ = p     # and an additional parameter!

    # Might as well cache these computations.
    Œ≤SI = Œ≤ * S * I / N
    œÉE = œÉ * E
    Œ≥I = Œ≥ * I

    du[1] = -Œ≤SI
    du[2] = Œ≤SI - œÉE
    du[3] = œÉE - Œ≥I
    du[4] = Œ≥I
end
#+end_src

#+RESULTS:
: SEIR! (generic function with 1 method)

#+REVEAL: split

#+begin_src julia
problem_seir = let u0 = [N - 1, 0, 1, 0], Œ≤ = 2.0, Œ≥ = 0.6, œÉ = 0.8
    ODEProblem(SEIR!, u0, tspan, (Œ≤, Œ≥, œÉ))
end
#+end_src

#+RESULTS:
: [38;2;86;182;194mODEProblem[0m with uType [38;2;86;182;194mVector{Int64}[0m and tType [38;2;86;182;194mFloat64[0m. In-place: [38;2;86;182;194mtrue[0m
: timespan: (0.0, 14.0)
: u0: 4-element Vector{Int64}:
:  762
:    0
:    1
:    0

#+begin_src julia
sol_seir = solve(problem_seir, saveat=1)
#+end_src

#+RESULTS:
#+begin_example
retcode: Success
Interpolation: 1st order linear
t: 15-element Vector{Float64}:
  0.0
  1.0
  2.0
  3.0
  4.0
  5.0
  6.0
  7.0
  8.0
  9.0
 10.0
 11.0
 12.0
 13.0
 14.0
u: 15-element Vector{Vector{Float64}}:
 [762.0, 0.0, 1.0, 0.0]
 [760.1497035901518, 1.277915971753478, 1.015887135649055, 0.5564933024456415]
 [757.5476928906271, 2.425869618233348, 1.6850698824327135, 1.341367608706787]
 [753.081189706403, 4.277014534677882, 2.9468385687120784, 2.6949571902067637]
 [745.3234082630842, 7.455598293492681, 5.155811621098982, 5.065181822323939]
 [731.9851682751213, 12.855816151849933, 8.960337047554939, 9.198678525473571]
 [709.5042941973462, 21.77178343781762, 15.384985521594785, 16.338936843241182]
 [672.8733895183619, 35.77263271085456, 25.88133104438007, 28.472646726403138]
 [616.390571176038, 55.9717775696742, 42.09614416178475, 48.54150709250277]
 [536.453596476594, 81.2428045994271, 64.9673325777641, 80.33626634621449]
 [436.43708330634297, 106.04037246704702, 92.9550757379631, 127.56746848864664]
 [329.60092931771436, 121.08020372279418, 120.48402926084937, 191.83483769864185]
 [233.8471941518982, 119.43669383157659, 139.3233304893263, 270.3927815271987]
 [160.88805352426687, 102.7399386960996, 143.3826208089892, 355.98938697064415]
 [111.72261866282292, 79.02493776169311, 132.78384886713565, 439.46859470834806]
#+end_example

#+REVEAL: split

#+begin_src julia
plot(sol_seir, linewidth=2, xaxis="Time in days", label=["Susceptible" "Exposed" "Infected" "Recovered"], alpha=0.5)
scatter!(1:14, data.in_bed, label="Data")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/cf61c8af8f10097a63ca84e48ff0b4831f7d8a59.svg]]

Don't look so good. Let's try Optim.jl again.

#+REVEAL: split

#+begin_src julia
function loss_seir(problem, p)
    problem = remake(problem, p=p)
    sol = solve(problem, saveat=1)
    # NOTE: 3rd state is now the (I)nfectious compartment!!!
    sol_for_observed = sol[3, 2:15]
    return sum(abs2.(sol_for_observed - data.in_bed))
end
#+end_src

#+RESULTS:
: loss_seir (generic function with 1 method)

#+begin_src julia 
opt_problem = OptimizationProblem(
    OptimizationFunction(
        (p,_) -> loss_seir(problem_seir, p), # function to minimize
        Optimization.AutoForwardDiff()       # use ForwardDiff for automatic differentiation
    ),
    [2.0, 0.5, 0.9],                         # initial values
    lb = [0, 0, 0],                          # lower bounds on variables
    ub = [Inf, Inf, Inf],                    # upper bounds on variables
)
#+end_src

#+RESULTS:
: [38;2;86;182;194mOptimizationProblem[0m. In-place: [38;2;86;182;194mtrue[0m
: u0: 3-element Vector{Float64}:
:  2.0
:  0.5
:  0.9

#+begin_src julia
opt = solve(opt_problem, NelderMead())
#+end_src

#+RESULTS:
: u: 3-element Vector{Float64}:
:  4.853892250588215
:  0.46714672936112517
:  0.8150220601014526

#+REVEAL: split

#+begin_src julia
Œ≤, Œ≥, œÉ = opt
#+end_src

#+RESULTS:
: u: 3-element Vector{Float64}:
:  4.853892250588215
:  0.46714672936112517
:  0.8150220601014526

#+begin_src julia
sol_seir = solve(remake(problem_seir, p=(Œ≤, Œ≥, œÉ)), saveat=1)
plot(sol_seir, linewidth=2, xaxis="Time in days", label=["Susceptible" "Exposed" "Infected" "Recovered"], alpha=0.5)
scatter!(1:14, data.in_bed, label="Data", color="black")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/42df237b1d7d830e89b857e29552483eb45ebc0c.svg]]

#+REVEAL: split

#+begin_quote
But...but these are _point estimates_! What about distributions? WHAT ABOUT UNCERTAINTY?!
#+end_quote

No, no that's fair.

Let's do some Bayesian inference then.

BUT FIRST!

** Making our future selves less annoyed
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Making-our-future-selves-less-annoyed
:CUSTOM_ID: 2023-01-29-16-57-28-Making-our-future-selves-less-annoyed
:END:

It's annoying to have all these different loss-functions for /both/ =SIR!= and =SEIR!=

#+HTML: <div class="fragment (appear)">

#+begin_src julia
# Abstract type which we can use to dispatch on.
abstract type AbstractEpidemicProblem end

struct SIRProblem{P} <: AbstractEpidemicProblem
    problem::P
    N::Int
end

function SIRProblem(N::Int; u0 = [N - 1, 1, 0.], tspan = (0, 14), p = [2.0, 0.6])
    return SIRProblem(ODEProblem(SIR!, u0, tspan, p), N)
end
#+end_src

#+RESULTS:
: SIRProblem

Then we can just construct the problem as

#+begin_src julia
sir = SIRProblem(N);
#+end_src

#+RESULTS:

#+HTML: </div>

#+REVEAL: split

And to make it a bit easier to work with, we add some utility functions

#+begin_src julia
# General.
parameters(prob::AbstractEpidemicProblem) = prob.problem.p
initial_state(prob::AbstractEpidemicProblem) = prob.problem.u0
population(prob::AbstractEpidemicProblem) = prob.N

# Specializations.
susceptible(::SIRProblem, u::AbstractMatrix) = u[1, :]
infected(::SIRProblem, u::AbstractMatrix) = u[2, :]
recovered(::SIRProblem, u::AbstractMatrix) = u[3, :]
#+end_src

#+RESULTS:
: recovered (generic function with 1 method)

So that once we've solved the problem, we can easily extract the compartment we want, e.g.

#+begin_src julia
sol = solve(sir.problem, saveat=1)
infected(sir, sol)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
15-element Vector{Float64}:
   1.0
   4.026799533924022
  15.824575905720003
  56.779007685250534
 154.43105799061686
 248.98982384839158
 243.67838619968526
 181.93939659551984
 120.64627375763273
  75.92085282572398
  46.58644927641269
  28.214678599716414
  16.96318676577873
  10.158687874394722
   6.070415830241046
#+end_example
#+begin_example
15-element Vector{Float64}:
   1.0
   4.026799533924022
  15.824575905720003
  56.779007685250534
 154.43105799061686
 248.98982384839158
 243.67838619968526
 181.93939659551984
 120.64627375763273
  75.92085282572398
  46.58644927641269
  28.214678599716414
  16.96318676577873
  10.158687874394722
   6.070415830241046
#+end_example
:END:

** TASK Implement =SEIRProblem=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Implement-SEIRProblem
:CUSTOM_ID: 2023-01-29-16-57-28-Implement-SEIRProblem
:END:

#+begin_src julia :eval no
struct SEIRProblem <: AbstractEpidemicProblem
    # ...
end

function SEIRProblem end

susceptible
exposed
infected
recovered
#+end_src

#+begin_src julia :exports (by-backend (reveal "none") (t "code"))
# Some space so you don't cheat.



















# Are you sure?
#+end_src

#+RESULTS:

** SOLUTION Implement =SEIRProblem=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Implement-SEIRProblem
:CUSTOM_ID: 2023-01-29-16-57-28-Implement-SEIRProblem
:END:

#+begin_src julia
struct SEIRProblem{P} <: AbstractEpidemicProblem
    problem::P
    N::Int
end

function SEIRProblem(N::Int; u0 = [N - 1, 0, 1, 0.], tspan = (0, 14), p = [4.5, 0.45, 0.8])
    return SEIRProblem(ODEProblem(SEIR!, u0, tspan, p), N)
end

susceptible(::SEIRProblem, u::AbstractMatrix) = u[1, :]
exposed(::SEIRProblem, u::AbstractMatrix) = u[2, :]
infected(::SEIRProblem, u::AbstractMatrix) = u[3, :]
recovered(::SEIRProblem, u::AbstractMatrix) = u[4, :]
#+end_src

#+RESULTS:
: recovered (generic function with 2 methods)

#+REVEAL: split

Now, given a =problem= and a =sol=, we can query the =sol= for the =infected= state _without explicit handling of which =problem= we're working with_

#+begin_src julia
seir = SEIRProblem(N);
sol = solve(seir.problem, saveat=1)
infected(seir, sol)
#+end_src

#+RESULTS:
#+begin_example
15-element Vector{Float64}:
   1.0
   1.9941817088874336
   6.9585823072029
  23.926233517606498
  74.23638542794971
 176.98368495653585
 276.06126059898344
 293.92632518571605
 249.92836195453708
 189.07578975511504
 134.2373192679034
  91.82578430804273
  61.38108478932364
  40.42264366743211
  26.357816296754425
#+end_example

** Same =loss= for both!
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Same-loss-for-both
:CUSTOM_ID: 2023-01-29-16-57-28-Same-loss-for-both
:END:

#+begin_src julia
function loss(problem_wrapper::AbstractEpidemicProblem, p)
    # NOTE: Extract the `problem` from `problem_wrapper`.
    problem = remake(problem_wrapper.problem, p=p)
    sol = solve(problem, saveat=1)
    # NOTE: Now this is completely general!
    sol_for_observed = infected(problem_wrapper, sol)[2:end]
    return sum(abs2.(sol_for_observed - data.in_bed))
end
#+end_src

#+RESULTS:
: loss (generic function with 1 method)

Now we can call the _same =loss= for both_ =SIR= and =SEIR=

#+begin_src julia 
loss(SIRProblem(N), [2.0, 0.6])
#+end_src

#+RESULTS:
: 50257.839781348805

#+begin_src julia 
loss(SEIRProblem(N), [2.0, 0.6, 0.8])
#+end_src

#+RESULTS:
: 287325.105532706

* GPU programming
:PROPERTIES:
:header-args:julia: :session /ssh:beastly:/home/tor/.local/share/jupyter/runtime/kernel-593c7303-cb3d-494a-946c-14b11112578e.json :kernel julia-4-threads-1.9 :async yes :tangle no :exports both
:END:

#+begin_src julia :exports none
]activate --temp
#+end_src

#+RESULTS:
:   Activating new project at `/tmp/jl_N7SPiz`

#+begin_src julia :exports none
]add CUDA
#+end_src

#+RESULTS:
#+begin_example
[32m[1m   Resolving[22m[39m package versions...
[32m[1m   Installed[22m[39m CUDA_Runtime_Discovery ‚îÄ v0.2.2
[32m[1m   Installed[22m[39m JuliaNVTXCallbacks_jll ‚îÄ v0.2.1+0
[32m[1m   Installed[22m[39m BFloat16s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.4.2
[32m[1m   Installed[22m[39m CUDA_Driver_jll ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.6.0+3
[32m[1m   Installed[22m[39m NVTX_jll ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v3.1.0+2
[32m[1m   Installed[22m[39m TimerOutputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.5.23
[32m[1m   Installed[22m[39m NVTX ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.3.3
[32m[1m   Installed[22m[39m GPUCompiler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.24.4
[32m[1m   Installed[22m[39m CUDA_Runtime_jll ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.9.2+0
[32m[1m   Installed[22m[39m CUDA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v5.0.0
[32m[1m    Updating[22m[39m `/tmp/jl_N7SPiz/Project.toml`
  [90m[052768ef] [39m[92m+ CUDA v5.0.0[39m
[32m[1m    Updating[22m[39m `/tmp/jl_N7SPiz/Manifest.toml`
 Downloading artifact: CUDA_Driver
  [90m[621f4979] [39m[92m+ AbstractFFTs v1.5.0[39m
  [90m[79e6a3ab] [39m[92m+ Adapt v3.6.2[39m
  [90m[a9b6321e] [39m[92m+ Atomix v0.1.0[39m
  [90m[ab4f0b2a] [39m[92m+ BFloat16s v0.4.2[39m
  [90m[fa961155] [39m[92m+ CEnum v0.4.2[39m
  [90m[052768ef] [39m[92m+ CUDA v5.0.0[39m
  [90m[1af6417a] [39m[92m+ CUDA_Runtime_Discovery v0.2.2[39m
  [90m[3da002f7] [39m[92m+ ColorTypes v0.11.4[39m
  [90m[5ae59095] [39m[92m+ Colors v0.12.10[39m
  [90m[34da2185] [39m[92m+ Compat v4.9.0[39m
  [90m[a8cc5b0e] [39m[92m+ Crayons v4.1.1[39m
  [90m[9a962f9c] [39m[92m+ DataAPI v1.15.0[39m
  [90m[a93c6f00] [39m[92m+ DataFrames v1.6.1[39m
  [90m[864edb3b] [39m[92m+ DataStructures v0.18.15[39m
  [90m[e2d170a0] [39m[92m+ DataValueInterfaces v1.0.0[39m
  [90m[e2ba6199] [39m[92m+ ExprTools v0.1.10[39m
  [90m[53c48c17] [39m[92m+ FixedPointNumbers v0.8.4[39m
  [90m[0c68f7d7] [39m[92m+ GPUArrays v9.0.0[39m
  [90m[46192b85] [39m[92m+ GPUArraysCore v0.1.5[39m
  [90m[61eb1bfa] [39m[92m+ GPUCompiler v0.24.4[39m
  [90m[842dd82b] [39m[92m+ InlineStrings v1.4.0[39m
  [90m[41ab1584] [39m[92m+ InvertedIndices v1.3.0[39m
  [90m[82899510] [39m[92m+ IteratorInterfaceExtensions v1.0.0[39m
  [90m[692b3bcd] [39m[92m+ JLLWrappers v1.5.0[39m
  [90m[63c18a36] [39m[92m+ KernelAbstractions v0.9.8[39m
  [90m[929cbde3] [39m[92m+ LLVM v6.2.1[39m
  [90m[b964fa9f] [39m[92m+ LaTeXStrings v1.3.0[39m
  [90m[1914dd2f] [39m[92m+ MacroTools v0.5.11[39m
  [90m[e1d29d7a] [39m[92m+ Missings v1.1.0[39m
  [90m[5da4648a] [39m[92m+ NVTX v0.3.3[39m
  [90m[bac558e1] [39m[92m+ OrderedCollections v1.6.2[39m
  [90m[69de0a69] [39m[92m+ Parsers v2.7.2[39m
  [90m[2dfb63ee] [39m[92m+ PooledArrays v1.4.3[39m
  [90m[aea7be01] [39m[92m+ PrecompileTools v1.2.0[39m
  [90m[21216c6a] [39m[92m+ Preferences v1.4.1[39m
  [90m[08abe8d2] [39m[92m+ PrettyTables v2.2.7[39m
  [90m[74087812] [39m[92m+ Random123 v1.6.1[39m
  [90m[e6cf234a] [39m[92m+ RandomNumbers v1.5.3[39m
  [90m[189a3867] [39m[92m+ Reexport v1.2.2[39m
  [90m[ae029012] [39m[92m+ Requires v1.3.0[39m
  [90m[6c6a2e73] [39m[92m+ Scratch v1.2.0[39m
  [90m[91c51154] [39m[92m+ SentinelArrays v1.4.0[39m
  [90m[a2af1166] [39m[92m+ SortingAlgorithms v1.1.1[39m
  [90m[90137ffa] [39m[92m+ StaticArrays v1.6.3[39m
  [90m[1e83bf80] [39m[92m+ StaticArraysCore v1.4.2[39m
  [90m[892a3eda] [39m[92m+ StringManipulation v0.3.4[39m
  [90m[3783bdb8] [39m[92m+ TableTraits v1.0.1[39m
  [90m[bd369af6] [39m[92m+ Tables v1.11.0[39m
  [90m[a759f4b9] [39m[92m+ TimerOutputs v0.5.23[39m
  [90m[013be700] [39m[92m+ UnsafeAtomics v0.2.1[39m
  [90m[d80eeb9a] [39m[92m+ UnsafeAtomicsLLVM v0.1.3[39m
  [90m[4ee394cb] [39m[92m+ CUDA_Driver_jll v0.6.0+3[39m
[91m‚Üí[39m [90m[76a88914] [39m[92m+ CUDA_Runtime_jll v0.9.2+0[39m
  [90m[9c1d0b0a] [39m[92m+ JuliaNVTXCallbacks_jll v0.2.1+0[39m
  [90m[dad2f222] [39m[92m+ LLVMExtra_jll v0.0.25+0[39m
  [90m[e98f9f5b] [39m[92m+ NVTX_jll v3.1.0+2[39m
  [90m[0dad84c5] [39m[92m+ ArgTools v1.1.1[39m
  [90m[56f22d72] [39m[92m+ Artifacts[39m
  [90m[2a0f44e3] [39m[92m+ Base64[39m
  [90m[ade2ca70] [39m[92m+ Dates[39m
  [90m[f43a241f] [39m[92m+ Downloads v1.6.0[39m
  [90m[7b1f6079] [39m[92m+ FileWatching[39m
  [90m[9fa8497b] [39m[92m+ Future[39m
  [90m[b77e0a4c] [39m[92m+ InteractiveUtils[39m
  [90m[4af54fe1] [39m[92m+ LazyArtifacts[39m
  [90m[b27032c2] [39m[92m+ LibCURL v0.6.3[39m
  [90m[76f85450] [39m[92m+ LibGit2[39m
  [90m[8f399da3] [39m[92m+ Libdl[39m
  [90m[37e2e46d] [39m[92m+ LinearAlgebra[39m
  [90m[56ddb016] [39m[92m+ Logging[39m
  [90m[d6f4376e] [39m[92m+ Markdown[39m
  [90m[ca575930] [39m[92m+ NetworkOptions v1.2.0[39m
  [90m[44cfe95a] [39m[92m+ Pkg v1.9.2[39m
  [90m[de0858da] [39m[92m+ Printf[39m
  [90m[3fa0cd96] [39m[92m+ REPL[39m
  [90m[9a3f8284] [39m[92m+ Random[39m
  [90m[ea8e919c] [39m[92m+ SHA v0.7.0[39m
  [90m[9e88b42a] [39m[92m+ Serialization[39m
  [90m[6462fe0b] [39m[92m+ Sockets[39m
  [90m[2f01184e] [39m[92m+ SparseArrays[39m
  [90m[10745b16] [39m[92m+ Statistics v1.9.0[39m
  [90m[fa267f1f] [39m[92m+ TOML v1.0.3[39m
  [90m[a4e569a6] [39m[92m+ Tar v1.10.0[39m
  [90m[8dfed614] [39m[92m+ Test[39m
  [90m[cf7118a7] [39m[92m+ UUIDs[39m
  [90m[4ec0a83e] [39m[92m+ Unicode[39m
  [90m[e66e0078] [39m[92m+ CompilerSupportLibraries_jll v1.0.5+0[39m
  [90m[deac9b47] [39m[92m+ LibCURL_jll v7.84.0+0[39m
  [90m[29816b5a] [39m[92m+ LibSSH2_jll v1.10.2+0[39m
  [90m[c8ffd9c3] [39m[92m+ MbedTLS_jll v2.28.2+0[39m
  [90m[14a3606d] [39m[92m+ MozillaCACerts_jll v2022.10.11[39m
  [90m[4536629a] [39m[92m+ OpenBLAS_jll v0.3.21+4[39m
  [90m[bea87d4a] [39m[92m+ SuiteSparse_jll v5.10.1+6[39m
  [90m[83775a58] [39m[92m+ Zlib_jll v1.2.13+0[39m
  [90m[8e850b90] [39m[92m+ libblastrampoline_jll v5.8.0+0[39m
  [90m[8e850ede] [39m[92m+ nghttp2_jll v1.48.0+0[39m
  [90m[3f19e933] [39m[92m+ p7zip_jll v17.4.0+0[39m
[36m[1m        Info[22m[39m Packages marked with [91m‚Üí[39m are not downloaded, use `instantiate` to download
[32m[1mPrecompiling[22m[39m project...
[32m  ‚úì [39m[90mBFloat16s[39m
[32m  ‚úì [39m[90mNVTX_jll[39m
[32m  ‚úì [39m[90mJuliaNVTXCallbacks_jll[39m
[32m  ‚úì [39m[90mCUDA_Driver_jll[39m
[32m  ‚úì [39m[90mNVTX[39m
[32m  ‚úì [39m[90mCUDA_Runtime_Discovery[39m
[32m  ‚úì [39m[90mCUDA_Runtime_jll[39m
[32m  ‚úì [39m[90mTimerOutputs[39m
[32m  ‚úì [39m[90mGPUCompiler[39m
[32m  ‚úì [39mCUDA
  10 dependencies successfully precompiled in 180 seconds. 56 already precompiled.
#+end_example

#+begin_src julia 
using CUDA
#+end_src

#+RESULTS:

https://juliagpu.org/

#+REVEAL: split

Because some of you might not have a GPU, we'll use

#+begin_src julia 
CUDA.has_cuda()
#+end_src

#+RESULTS:
: true

to avoid executing the GPU code in that case

#+REVEAL: split

#+begin_src julia 
if CUDA.has_cuda()
    CUDA.versioninfo()
end
#+end_src

#+RESULTS:
#+begin_example
CUDA runtime 12.2, artifact installation
CUDA driver 12.2
NVIDIA driver 535.86.5

CUDA libraries: 
- CUBLAS: 12.2.5
- CURAND: 10.3.3
- CUFFT: 11.0.8
- CUSOLVER: 11.5.2
- CUSPARSE: 12.1.2
- CUPTI: 20.0.0
- NVML: 12.0.0+535.86.5

Julia packages: 
- CUDA: 5.0.0
- CUDA_Driver_jll: 0.6.0+3
- CUDA_Runtime_jll: 0.9.2+0

Toolchain:
- Julia: 1.9.3
- LLVM: 14.0.6
- PTX ISA support: 3.2, 4.0, 4.1, 4.2, 4.3, 5.0, 6.0, 6.1, 6.3, 6.4, 6.5, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5
- Device capability support: sm_37, sm_50, sm_52, sm_53, sm_60, sm_61, sm_62, sm_70, sm_72, sm_75, sm_80, sm_86

1 device:
  0: NVIDIA GeForce GTX 1080 Ti (sm_61, 10.047 GiB / 11.000 GiB available)
#+end_example

#+REVEAL: split

#+begin_src julia
# Array on CPU
xs = rand(2)
#+end_src

#+RESULTS:
: 2-element Vector{Float64}:
:  0.9209503500993459
:  0.8172019350381718

#+begin_src julia
if CUDA.has_cuda()
    # Array on GPU
    xs_cuda = cu(xs)
end
#+end_src

#+RESULTS:
: 2-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:
:  0.92095035
:  0.8172019

And that's it!

#+REVEAL: split

#+begin_src julia
if CUDA.has_cuda()
    2 * xs_cuda
end
#+end_src

#+RESULTS:
: 2-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:
:  1.8419007
:  1.6344038

#+begin_src julia
if CUDA.has_cuda()
    xs_cuda .+ xs_cuda
end
#+end_src

#+RESULTS:
: 2-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:
:  1.8419007
:  1.6344038

#+REVEAL: split

#+begin_src julia
if CUDA.has_cuda()
    X_cuda = xs_cuda * xs_cuda' + 1f-2 * I
    cholesky(X_cuda)
end
#+end_src

#+RESULTS:
: Cholesky{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}
: U factor:
: 2√ó2 UpperTriangular{Float32, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}:
:  0.926364  0.812427
:   ‚ãÖ        0.133349

#+REVEAL: split

#+HTML: <div class="WARNING">
*Important:* Turing.jl is _not_ completely GPU compatible
#+HTML: </div>

You can execute all the GPU code you want /inside/ the model

But you can't (/at the moment/) use GPU for the entire computation

Though some samplers are already GPU compatible

* Turing.jl
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Bayesian-inference
:CUSTOM_ID: 2023-01-29-16-57-28-Bayesian-inference
:END:

#+begin_src julia
using Turing
#+end_src

#+RESULTS:

and so we are finally here

#+RESULTS:

** A simple demo

#+begin_src julia :exports none
using StatsPlots, DifferentialEquations
#+end_src

#+RESULTS:

#+begin_src julia :async yes
# 1. Define the model
@model function simple_demo(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
# 2. Instantiate the model, giving it some data.
model = simple_demo(1.5, 2.0)
# 3. Sample.
chain = sample(model, NUTS(), 1000);
#+end_src

#+RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mFound initial step size
: [36m[1m‚îî [22m[39m  œµ = 1.6
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00[39m
:

#+REVEAL: split

#+begin_src julia 
chain
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó14√ó1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 1.06 seconds
Compute duration  = 1.06 seconds
parameters        = s, m
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m ‚ãØ
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m ‚ãØ

           s    2.5473    5.2060    0.6183   211.8820    82.0100    1.0014     ‚ãØ
           m    1.2801    1.2390    0.1610   181.4128    63.2533    1.0123     ‚ãØ
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

           s    0.5559    1.0290    1.5377    2.3967   11.1825
           m   -0.4322    0.6709    1.1794    1.6321    4.0980
#+end_example

#+REVEAL: split

#+begin_src julia 
plot(chain)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/1e1f607dc21364143f2f8b67328de490ce367807.svg]]

#+REVEAL: split


#+begin_src julia :display text/plain :eval no
# 1. Define the model
@model function simple_demo(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
# 2. Instantiate the model, giving it some data.
model = simple_demo(1.5, 2.0)
# 3. Sample.
chain = sample(model, NUTS(), 1000);
#+end_src

#+begin_quote
Okay, what is going on here?
#+end_quote

Let's break it down

#+REVEAL: split

To define a model in Turing.jl, we use the =@model= macro

#+begin_src julia 
@model function simple_demo(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
#+end_src

#+RESULTS:
: simple_demo (generic function with 2 methods)

which, as we can see, results in a few =simple_demo= methods

#+ATTR_REVEAL: :frag appear
- One method is for evaluation of the model
- The rest (one, here) are for constructing the =Model=

#+HTML: <div class="fragment (appear)">

#+begin_src julia 
model = simple_demo(1.5, 2.0)
#+end_src

#+RESULTS:
: Model(
:   args = (:x, :y)
:   defaults = ()
:   context = DynamicPPL.DefaultContext()
: )

#+HTML: </div>

#+REVEAL: split

In fact, we can call the =model=

#+begin_src julia 
model()
#+end_src

#+RESULTS:
: 2.0

It returns =2.0= because the last line was

#+begin_src julia :eval no
y ~ Normal(m, sqrt(s))
#+end_src

where =y= is conditioned to be =2.0=

#+REVEAL: split

We can add an explicit =return= statement if we want

#+begin_src julia 
@model function simple_demo(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))

    # This is just standard Julia, so we can put anything in here.
    return (; s, m, x, y, hello=42)
end
#+end_src

#+RESULTS:
: simple_demo (generic function with 2 methods)

#+begin_src julia :results scalar
model = simple_demo(1.5, 2.0)
model()
#+end_src

#+RESULTS:
: (s = 1.1025520712639092, m = -1.5289265819798645, x = 1.5, y = 2.0, hello = 42)

When we call the =model=, =s= and =m= are sampled from the prior

#+REVEAL: split

This can be very useful for debugging, e.g.

#+begin_src julia 
@model function demo_buggy()
    x ~ truncated(Normal(), -10, 0)
    y ~ Normal(0, x)
end
model_buggy = demo_buggy()
model_buggy()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
DomainError with -1.214255447361705:
Normal: the condition œÉ >= zero(œÉ) is not satisfied.

Stacktrace:
  [1] #371
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:37 [inlined]
  [2] check_args
    @ ~/.julia/packages/Distributions/Ufrz2/src/utils.jl:89 [inlined]
  [3] #Normal#370
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:37 [inlined]
  [4] Normal
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:36 [inlined]
  [5] #Normal#373
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:42 [inlined]
  [6] Normal(Œº::Int64, œÉ::Float64)
    @ Distributions ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:42
  [7] macro expansion
    @ ~/.julia/packages/DynamicPPL/YThRW/src/compiler.jl:555 [inlined]
  [8] demo_buggy(__model__::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, __varinfo__::DynamicPPL.ThreadSafeVarInfo{DynamicPPL.UntypedVarInfo{DynamicPPL.Metadata{Dict{AbstractPPL.VarName, Int64}, Vector{Distribution}, Vector{AbstractPPL.VarName}, Vector{Real}, Vector{Set{DynamicPPL.Selector}}}, Float64}, Vector{Base.RefValue{Float64}}}, __context__::DynamicPPL.SamplingContext{DynamicPPL.SampleFromPrior, DynamicPPL.DefaultContext, TaskLocalRNG})
    @ Main ./In[164]:3
  [9] _evaluate!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:963 [inlined]
 [10] evaluate_threadsafe!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:952 [inlined]
 [11] evaluate!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:887 [inlined]
 [12] evaluate!! (repeats 2 times)
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:900 [inlined]
 [13] evaluate!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:908 [inlined]
 [14] (::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext})()
    @ DynamicPPL ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:860
 [15] top-level scope
    @ In[164]:6
#+end_example
:END:

#+REVEAL: split

Let's insert some good old-fashioned print-statements

#+begin_src julia 
@model function demo_buggy()
    x ~ truncated(Normal(), -10, 0)
    println("x=$x")
    y ~ Normal(0, x)
    println("y=$y")
end
model_buggy = demo_buggy()
model_buggy()
#+end_src

#+RESULTS:
:RESULTS:
: x=-1.5669000963448219
# [goto error]
#+begin_example
DomainError with -1.5669000963448219:
Normal: the condition œÉ >= zero(œÉ) is not satisfied.

Stacktrace:
  [1] #371
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:37 [inlined]
  [2] check_args
    @ ~/.julia/packages/Distributions/Ufrz2/src/utils.jl:89 [inlined]
  [3] #Normal#370
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:37 [inlined]
  [4] Normal
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:36 [inlined]
  [5] #Normal#373
    @ ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:42 [inlined]
  [6] Normal(Œº::Int64, œÉ::Float64)
    @ Distributions ~/.julia/packages/Distributions/Ufrz2/src/univariate/continuous/normal.jl:42
  [7] demo_buggy(__model__::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, __varinfo__::DynamicPPL.ThreadSafeVarInfo{DynamicPPL.UntypedVarInfo{DynamicPPL.Metadata{Dict{AbstractPPL.VarName, Int64}, Vector{Distribution}, Vector{AbstractPPL.VarName}, Vector{Real}, Vector{Set{DynamicPPL.Selector}}}, Float64}, Vector{Base.RefValue{Float64}}}, __context__::DynamicPPL.SamplingContext{DynamicPPL.SampleFromPrior, DynamicPPL.DefaultContext, TaskLocalRNG})
    @ Main ./In[165]:4
  [8] _evaluate!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:963 [inlined]
  [9] evaluate_threadsafe!!(model::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, varinfo::DynamicPPL.UntypedVarInfo{DynamicPPL.Metadata{Dict{AbstractPPL.VarName, Int64}, Vector{Distribution}, Vector{AbstractPPL.VarName}, Vector{Real}, Vector{Set{DynamicPPL.Selector}}}, Float64}, context::DynamicPPL.SamplingContext{DynamicPPL.SampleFromPrior, DynamicPPL.DefaultContext, TaskLocalRNG})
    @ DynamicPPL ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:952
 [10] evaluate!!(model::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext}, varinfo::DynamicPPL.UntypedVarInfo{DynamicPPL.Metadata{Dict{AbstractPPL.VarName, Int64}, Vector{Distribution}, Vector{AbstractPPL.VarName}, Vector{Real}, Vector{Set{DynamicPPL.Selector}}}, Float64}, context::DynamicPPL.SamplingContext{DynamicPPL.SampleFromPrior, DynamicPPL.DefaultContext, TaskLocalRNG})
    @ DynamicPPL ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:887
 [11] evaluate!! (repeats 2 times)
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:900 [inlined]
 [12] evaluate!!
    @ ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:908 [inlined]
 [13] (::DynamicPPL.Model{typeof(demo_buggy), (), (), (), Tuple{}, Tuple{}, DynamicPPL.DefaultContext})()
    @ DynamicPPL ~/.julia/packages/DynamicPPL/YThRW/src/model.jl:860
 [14] top-level scope
    @ In[165]:8
#+end_example
:END:

#+REVEAL: split

=x= is negative ‚ü∂ let's fix that

#+begin_src julia 
@model function demo_buggy()
    x ~ truncated(Normal(), 0, 10)
    println("x=$x")
    y ~ Normal(0, x)
    println("y=$y")
end
model_buggy = demo_buggy()
model_buggy()
#+end_src

#+RESULTS:
: x=1.1710107037640873
: y=-0.55896646743747

It works!

#+REVEAL: split

But let's get back to our =simple_demo= example

#+begin_src julia :eval no
@model function simple_demo(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
#+end_src


#+HTML: <div class="fragment (appear)"
We've seen a =function= before, so that part isn't new

#+begin_src julia :eval no
@model function simple_demo(x)
    ...
end
#+end_src

Roughly, =@model= "transforms" the function =simple_demo= in a "certain way"
#+HTML: </div>

#+HTML: <div class="x-small-text">

#+HTML: <div class="fragment (appear)">

If you /really/ want to have a look, you can execute the following code block

#+begin_src julia :exports code :eval no
@macroexpand @model function demo()
    x ~ Normal()
    return nothing
end
#+end_src

#+RESULTS:
#+begin_example
quote
    function demo(__model__::DynamicPPL.Model, __varinfo__::DynamicPPL.AbstractVarInfo, __context__::AbstractPPL.AbstractContext; )
        #= In[29]:1 =#
        begin
            #= In[29]:1 =#
            #= In[29]:2 =#
            begin
                var"##dist#437" = Normal()
                var"##vn#434" = (DynamicPPL.resolve_varnames)((AbstractPPL.VarName){:x}(), var"##dist#437")
                var"##isassumption#435" = begin
                        if (DynamicPPL.contextual_isassumption)(__context__, var"##vn#434")
                            if !((DynamicPPL.inargnames)(var"##vn#434", __model__)) || (DynamicPPL.inmissings)(var"##vn#434", __model__)
                                true
                            else
                                x === missing
                            end
                        else
                            false
                        end
                    end
                if (DynamicPPL.contextual_isfixed)(__context__, var"##vn#434")
                    x = (DynamicPPL.getfixed_nested)(__context__, var"##vn#434")
                elseif var"##isassumption#435"
                    begin
                        (var"##value#438", __varinfo__) = (DynamicPPL.tilde_assume!!)(__context__, (DynamicPPL.unwrap_right_vn)((DynamicPPL.check_tilde_rhs)(var"##dist#437"), var"##vn#434")..., __varinfo__)
                        x = var"##value#438"
                        var"##value#438"
                    end
                else
                    if !((DynamicPPL.inargnames)(var"##vn#434", __model__))
                        x = (DynamicPPL.getconditioned_nested)(__context__, var"##vn#434")
                    end
                    (var"##value#436", __varinfo__) = (DynamicPPL.tilde_observe!!)(__context__, (DynamicPPL.check_tilde_rhs)(var"##dist#437"), x, var"##vn#434", __varinfo__)
                    var"##value#436"
                end
            end
            #= In[29]:3 =#
            begin
                #= /home/tor/.julia/packages/DynamicPPL/YThRW/src/compiler.jl:555 =#
                var"##retval#439" = nothing
                #= /home/tor/.julia/packages/DynamicPPL/YThRW/src/compiler.jl:556 =#
                return (var"##retval#439", __varinfo__)
            end
        end
    end
    begin
        $(Expr(:meta, :doc))
        function demo(; )
            #= In[29]:1 =#
            return (DynamicPPL.Model)(demo, NamedTuple{()}(()); )
        end
    end
end
#+end_example

to see the actual code being generated

#+HTML: </div>

#+HTML: </div>

#+REVEAL: split

Then we have the "tilde-statements"

#+begin_src julia :eval no
s ~ InverseGamma(2, 3)
m ~ Normal(0, sqrt(s))

x ~ Normal(m, sqrt(s))
y ~ Normal(m, sqrt(s))
#+end_src

#+HTML: <div class="fragment (appear)">
_Important:_ only lines of the form =LEFT ~ RIGHT= are touched by =@model=
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
‚üπ Everything that is _not_ of the form =LEFT ~ RIGHT= is _not_ touched by =@model=

#+begin_quote
If it's valid Julia code, it's valid inside a =@model= block
#+end_quote

#+HTML: </div>

#+REVEAL: split

But in our simple demo model, =s= and =m= are treated differently than =x= and =y=

=s= and =m= are considered as random variables to be inferred

=x= and =y= are considered as data / conditioned

#+HTML: <div class="fragment (appear)">

Basically, =L ~ R= is considered a /conditioned/ variable if either
1. =L= is present in the arguments of the function defining the model, or
2. =L= is /conditioned/ using =model | (L9 = ..., )= or similar.
3. =L= is a /literal/, e.g. =1.5 ~ Normal()=.

_Otherwise_, =L= is considered a random variable

#+HTML: </div>

#+REVEAL: split

The following are all equivalent

#+begin_src julia :results none
# (1): using the arguments of the function
@model function simple_demo_v1(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
model_v1 = simple_demo_v1(1.5, 2.0)
#+end_src

#+begin_src julia :results none
# (2): using the `|` operator / `condition`
@model function simple_demo_v2()
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
model_v2 = simple_demo_v2() | (x = 1.5, y = 2.0)
#+end_src

#+begin_src julia :results none
# (3): when `L` is a literal
@model function simple_demo_v3()
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    1.5 ~ Normal(m, sqrt(s))
    2.0 ~ Normal(m, sqrt(s))
end
model_v3 = simple_demo_v3()
#+end_src

#+REVEAL: split

#+begin_src julia :async yes
with_logger(NullLogger()) do  # just surpressing the log output for presentation
    chain_v1 = sample(model_v1, NUTS(), 1000; progress=false)
    chain_v2 = sample(model_v2, NUTS(), 1000; progress=false)
    chain_v3 = sample(model_v3, NUTS(), 1000; progress=false)
end
plot(chainscat(chain_v1, chain_v2, chain_v3))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/03bc977a68859f71cedc48d9a2d1f1c823036872.svg]]

#+REVEAL: split

One thing that Turing.jl cannot handle is the following

#+begin_src julia 
@model function simple_demo_v1_failure(x, y)
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    # Used to be: y ~ Normal(m, sqrt(s))
    z = y
    z ~ Normal(m, sqrt(s))
end

model_v1_failure = simple_demo_v1_failure(1.5, 2.0)
model_v1_failure() # `y` is treated as a random variable!!!
#+end_src

#+RESULTS:
: -1.262744522413113

Turing.jl performs no analysis of the code ‚üπ don't know that =y= is constant

#+REVEAL: split

=decondition= can be used to "undo" the conditioning of a variable

#+HTML: <div class="fragment (appear)"
For _argument-based conditioning_, we need to replace it with =missing=

#+begin_src julia 
model_v1_decondition = simple_demo_v1(1.5, missing)
model_v1_decondition()  # `y` is now a random variable
#+end_src

#+RESULTS:
: -0.2820674051533346

#+HTML: </div>

#+HTML: <div class="fragment (appear)"
For _|-based conditioning_, we can just call =decondition=

#+begin_src julia
model_v2_decondition = DynamicPPL.decondition(model_v2, @varname(y))
model_v2_decondition()  # `y` is now a random variable!
#+end_src

#+RESULTS:
: -1.0537785826772716
#+HTML: </div>

#+HTML: <div class="fragment (appear)"
For _literal-based conditioning_, =y= is hard-coded, so deconditioning is not possible
#+HTML: </div>

#+REVEAL: split

Overall, |-based conditioning is preferred, i.e.

#+begin_src julia :eval no
@model function simple_demo_v2()
    s ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s))

    x ~ Normal(m, sqrt(s))
    y ~ Normal(m, sqrt(s))
end
model_v2 = simple_demo_v2() | (x = 1.5, y = 2.0)
#+end_src

But you will also encounter the other two approaches in the wild

** Other actions on a =Model=

#+REVEAL: split

*Computing probabilities*

#+HTML: <div class="fragment (appear)">
#+begin_src julia 
logprior(model, (s = 1, m = 1))
#+end_src

#+RESULTS:
: -2.221713955868453
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
#+begin_src julia
loglikelihood(model, (s = 1, m = 1))
#+end_src

#+RESULTS:
: -2.4628770664093453
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
#+begin_src julia
logjoint(model, (s = 1, m = 1))
#+end_src

#+RESULTS:
: -4.6845910222777984
#+HTML: </div>

#+REVEAL: split

*Conditioning and fixing*

#+HTML: <div class="fragment (appear)">
#+begin_src julia :results scalar
# Condition a variable to be a value
model_with_condition = Turing.condition(model, s=1.0)  # equivalent to `|` operator
model_with_condition()
#+end_src

#+RESULTS:
: (s = 1.0, m = -0.7072604928423466, x = 1.5, y = 2.0, hello = 42)
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
#+begin_src julia :results scalar
# Fix a variable to a value
model_with_fixed = Turing.fix(model, s=1.0)
model_with_fixed()
#+end_src

#+RESULTS:
: (s = 1.0, m = -0.2580013604654765, x = 1.5, y = 2.0, hello = 42)
#+HTML: </div>

#+HTML: <div class="fragment (appear)">
Difference between conditioning and fixing

#+begin_src julia :results scalar
logjoint(model_with_condition, (m=1,)), logjoint(model_with_fixed, (m=1,))
#+end_src

#+RESULTS:
: (-4.6845910222777984, -3.881815599614018)

A =fixed= variable is _not_ included in the log-probability
#+HTML: </div>

#+REVEAL: split

And can query the model about these things

#+begin_src julia :results scalar
DynamicPPL.observations(model_with_condition)
#+end_src

#+RESULTS:
: (s = 1.0,)

#+begin_src julia :results scalar
DynamicPPL.fixed(model_with_fixed)
#+end_src

#+RESULTS:
: (s = 1.0,)

[[https://turinglang.org/library/DynamicPPL/stable/api/][And much more...]]

** Back to our working example: S(E)IR model

#+REVEAL: split

We'll use the following model
\begin{equation*}
\begin{split}
  \beta &\sim \mathcal{N}_{ + }(2, 1) \\
  \gamma &\sim \mathcal{N}_{ + }(0.4, 0.5) \\
  \phi^{-1} &\sim \mathrm{Exponential}(1/5) \\
   y_i &\sim \mathrm{NegativeBinomial2}\big(F(u_0, t_i;\ \beta, \gamma), \phi \big)
\end{split}
\end{equation*}
where 
- $\big( y_i \big)_{i = 1}^{14}$ are the observations, 
- $F$ is the integrated system, and
- $\phi$ is the over-dispersion parameter.

#+REVEAL: split

#+begin_src julia
plot(
    plot(truncated(Normal(2, 1); lower=0), label=nothing, title="Œ≤"),
    plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title="Œ≥"),
    plot(Exponential(1/5), label=nothing, title="œï‚Åª¬π"),
    layout=(3, 1)
)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/80c76ad5d3151ec0f3e044a075b2a5b88956d14b.svg]]

#+REVEAL: split

=NegativeBinomial(r, p)= represents the number of trials to achieve $r$ successes, where each trial has a probability $p$ of success

=NegativeBinomial2(Œº, œï)= is parameterized by mean $Œº$ and /dispersion/ $\phi$

#+begin_src julia
# `NegativeBinomial` already exists, so let's just make an alternative constructor instead.
function NegativeBinomial2(Œº, œï)
    p = 1/(1 + Œº/œï)
    r = œï
    return NegativeBinomial(r, p)
end
#+end_src

#+RESULTS:
: NegativeBinomial2 (generic function with 1 method)

#+begin_src julia
# Let's just make sure we didn't do something stupid.
Œº = 2; œï = 3;
dist = NegativeBinomial2(Œº, œï)
# Source: https://mc-stan.org/docs/2_20/functions-reference/nbalt.html
mean(dist) ‚âà Œº && var(dist) ‚âà Œº + Œº^2 / œï
#+end_src

#+RESULTS:
: true

#+REVEAL: split

And here's the full model

#+begin_src julia
@model function sir_model(
    num_days;                                  # Number of days to model
    tspan = (0.0, float(num_days)),            # Timespan to model
    u0 = [N - 1, 1, 0.0],                      # Initial state
    p0 = [2.0, 0.6],                           # Placeholder parameters
    problem = ODEProblem(SIR!, u0, tspan, p0)  # Create problem once so we can `remake`.
)
    Œ≤ ~ truncated(Normal(2, 1); lower=0)
    Œ≥ ~ truncated(Normal(0.4, 0.5); lower=0)
    œï‚Åª¬π ~ Exponential(1/5)
    œï = inv(œï‚Åª¬π)

    problem_new = remake(problem, p=[Œ≤, Œ≥])  # Replace parameters `p`.
    sol = solve(problem_new, saveat=1)       # Solve!

    sol_for_observed = sol[2, 2:num_days + 1]  # Timesteps we have observations for.
    in_bed = Vector{Int}(undef, num_days)
    for i = 1:length(sol_for_observed)
        # Add a small constant to `sol_for_observed` to make things more stable.
        in_bed[i] ~ NegativeBinomial2(sol_for_observed[i] + 1e-5, œï)
    end

    # Some quantities we might be interested in.
    return (R0 = Œ≤ / Œ≥, recovery_time = 1 / Œ≥, infected = sol_for_observed)
end
#+end_src

#+RESULTS:
: sir_model (generic function with 2 methods)

It's break-down time

#+REVEAL: split

#+begin_src julia :eval no :tangle no
function sir_model(
    num_days;                                  # Number of days to model
    tspan = (0.0, float(num_days)),            # Timespan to model
    u0 = [N - 1, 1, 0.0],                      # Initial state
    p0 = [2.0, 0.6],                           # Placeholder parameters
    problem = ODEProblem(SIR!, u0, tspan, p0)  # Create problem once so we can `remake`.
)
    ...
end
#+end_src

#+REVEAL: split

#+begin_src julia :eval no :tangle no
Œ≤ ~ truncated(Normal(2, 1); lower=0)
Œ≥ ~ truncated(Normal(0.4, 0.5); lower=0)
œï‚Åª¬π ~ Exponential(1/5)
œï = inv(œï‚Åª¬π)
#+end_src

defines our prior

=truncated= is just a way of restricting the domain of the distribution you pass it

#+REVEAL: split

#+begin_src julia :eval no :tangle no
problem_new = remake(problem, p=[Œ≤, Œ≥])  # Replace parameters `p`.
sol = solve(problem_new, saveat=1)       # Solve!
#+end_src

We then remake the problem, now with the parameters =[Œ≤, Œ≥]= sampled above

=saveat = 1= gets us the solution at the timesteps =[0, 1, 2, ..., 14]=

#+REVEAL: split

Then we extract the timesteps we have observations for

#+begin_src julia :eval no :tangle no
sol_for_observed = sol[2, 2:num_days + 1]  # Timesteps we have observations for.
#+end_src

and define what's going to be a likelihood (once we add observations)

#+begin_src julia :eval no :tangle no
in_bed = Vector{Int}(undef, num_days)
for i = 1:length(sol_for_observed)
    # Add a small constant to `sol_for_observed` to make things more stable.
    in_bed[i] ~ NegativeBinomial2(sol_for_observed[i] + 1e-5, œï)
end
#+end_src

#+REVEAL: split

Finally we return some values that might be of interest

#+begin_src julia :eval no :tangle no
# Some quantities we might be interested in.
return (R0 = Œ≤ / Œ≥, recovery_time = 1 / Œ≥, infected = sol_for_observed)
#+end_src

This is useful for a post-sampling diagnostics, debugging, etc.

#+REVEAL: split

#+begin_src julia
model = sir_model(length(data.in_bed))
#+end_src

#+RESULTS:
: Model(
:   args = (:num_days,)
:   defaults = (:tspan, :u0, :p0, :problem)
:   context = DynamicPPL.DefaultContext()
: )

The model is just another function, so we can call it to check that it works

#+HTML: <div class="fragment (appear)">

#+begin_src julia
model().infected
#+end_src

#+RESULTS:
#+begin_example
14-element Vector{Float64}:
   2.045278282267525
   4.1719314481204
   8.463592114876898
  16.982881538280996
  33.35144429728391
  62.89009851410882
 110.43944141129398
 173.67998956357812
 236.81249111242104
 278.12376889737783
 287.77818356134276
 271.63941458117574
 241.2767842275726
 206.08954395632932
#+end_example

Hey, it does!

#+HTML: </div>

** Is the prior reasonable?
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Is-the-prior-reasonable
:CUSTOM_ID: 2023-01-29-16-57-28-Is-the-prior-reasonable
:END:

Before we do any inference, we should check if the prior is reasonable

From domain knowledge we know that (for influenza at least)
#+ATTR_REVEAL: :frag (appear)
- $R_0$ is typically between 1 and 2
- =recovery_time= ($1 / \gamma$) is usually ~1 week

#+HTML: <div class="fragment (appear)">

We want to make sure that your prior belief reflects this knowledge while still being flexible enough to accommodate the observations

#+HTML: </div>

#+REVEAL: split

To check this we'll just simulate some draws from our prior model, i.e. the model /without/ conditioning on =in_bed=

There are two ways to sample form the prior

#+HTML: <div class="fragment (appear)">

#+begin_src julia
# 1. By just calling the `model`, which returns a `NamedTuple` containing the quantities of interest
print(model())
#+end_src

#+RESULTS:
: (R0 = 5.578052108554251, recovery_time = 1.6184106251985781, infected = [16.430455140203254, 182.9254072058487, 390.7169678308964, 277.09955590850717, 160.73921416675392, 89.63989662512411, 49.40650374221978, 27.106414184874176, 14.840416681752787, 8.116354793408362, 4.436485354821677, 2.42457515773754, 1.3250052214147743, 0.7239404815304972])

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

Or by just calling =sample= using =Prior=

#+begin_src julia :async yes
# Sample from prior.
chain_prior = sample(model, Prior(), 10_000);
#+end_src

#+RESULTS:
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01[39m
:

#+HTML: </div>

#+REVEAL: split

Let's have a look at the prior predictive

#+begin_src julia :async yes
p = plot(legend=false, size=(600, 300))
plot_trajectories!(p, group(chain_prior, :in_bed); n = 1000)
hline!([N], color="red")
#+end_src

#+RESULTS:
:RESULTS:
[[file:assets/outputs/more-julia/f110b08ba2b09629fd9d3c498a45a8ab21e0915a.svg]]
:END:

#+ATTR_REVEAL: :frag (appear)
For certain values we get number of infected /larger/ than the actual population

#+ATTR_REVEAL: :frag (appear)
But this is includes the randomness from =NegativeBinomial2= likelihood

#+ATTR_REVEAL: :frag (appear)
Maybe more useful to inspect the (I)nfected state from the ODE solution?

#+REVEAL: split

We can also look at the =generated_quantities=, i.e. the values from the =return= statement in our model

#+HTML: <div class="fragment (appear)">
Our =return= looked like this

#+begin_src julia :eval no :tangle no
# Some quantities we might be interested in.
return (R0 = Œ≤ / Œ≥, recovery_time = 1 / Œ≥, infected = sol_for_observed)
#+end_src

#+HTML: </div>

#+HTML: <div class="fragment (appear)">
and so =generated_quantities= (conditioned on =chain_prior=) gives us

#+begin_src julia
quantities_prior = generated_quantities(model, chain_prior)
print(quantities_prior[1])
#+end_src

#+RESULTS:
: (R0 = 16.064158353916437, recovery_time = 4.5961550015651325, infected = [25.54664433192158, 341.2329870861155, 582.291266785026, 497.4517243568478, 402.4686620041788, 324.04672948494715, 260.73310729465913, 209.76289783753236, 168.75108612079157, 135.75620551517966, 109.21213227857037, 87.85804244192713, 70.67909288672027, 56.8592954645382])

#+HTML: </div>

#+REVEAL: split

We can convert it into a =Chains= using a utility function of mine

#+begin_src julia
# Convert to `Chains`.
chain_quantities_prior = to_chains(quantities_prior);

# Plot.
p = plot(legend=false, size=(600, 300))
plot_trajectories!(p, group(chain_quantities_prior, :infected); n = 1000)
hline!([N], color="red")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/a1b75cd5d378febc7029c1ed63db2831e09ab9ee.svg]]

#+HTML: <div class="x-small-text">

*NOTE:* =to_chains= is not part of "official" Turing.jl because the =return= can contain /whatever/ you want, and so it's not always possible to convert into a =Chains=

#+HTML: </div>

#+REVEAL: split

And the quantiles for the trajectories

#+begin_src julia
p = plot(legend=false, size=(600, 300))
plot_trajectory_quantiles!(p, group(chain_quantities_prior, :infected))
hline!(p, [N], color="red")
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/3f7598c6f0df5f376d9f89161504465787bacf25.svg]]

#+REVEAL: split


#+begin_src julia :display text/plain
DataFrame(quantile(chain_quantities_prior[:, [:R0, :recovery_time], :]))
#+end_src

#+RESULTS:
: [1m2√ó6 DataFrame[0m
: [1m Row [0m‚îÇ[1m parameters    [0m[1m 2.5%     [0m[1m 25.0%   [0m[1m 50.0%   [0m[1m 75.0%   [0m[1m 97.5%   [0m
:      ‚îÇ[90m Symbol        [0m[90m Float64  [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ R0             0.522984  2.02904  3.63259  7.0329   56.6748
:    2 ‚îÇ recovery_time  0.708293  1.19377  1.83346  3.41632  28.2667

Compare to our prior knowledge of $R_0 \in [1, 2]$ and $(1/\gamma) \approx 1$ for influenza

Do we really need probability mass on $R_0 \ge 10$?

** TASK Can we improve the current prior?
:PROPERTIES:
:ID:       2023-01-29-16-57-28-What-s-wrong-with-the-current-prior
:CUSTOM_ID: 2023-01-29-16-57-28-What-s-wrong-with-the-current-prior
:END:

#+HTML: <div class="side-by-side">

#+HTML: <div style="margin: auto;">

The SIR model

\begin{equation*}
\begin{split}
  \frac{\mathrm{d} S}{\mathrm{d} t} &= - \beta S \frac{I}{N} \\
  \frac{\mathrm{d} I}{\mathrm{d} t} &= \beta S \frac{I}{N} - \gamma I \\
  \frac{\mathrm{d} R}{\mathrm{d} t} &= \gamma I
\end{split}
\end{equation*}

#+HTML: </div>

#+HTML: <div>

And here's the current priors

#+HTML: <div class="x-small-text">

#+begin_src julia 
plot(
    plot(truncated(Normal(2, 1); lower=0), label=nothing, title="Œ≤"),
    plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title="Œ≥"),
    plot(Exponential(1/5), label=nothing, title="œï‚Åª¬π"),
    layout=(3, 1)
)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/80c76ad5d3151ec0f3e044a075b2a5b88956d14b.svg]]

#+HTML: </div>

#+HTML: </div>

#+HTML: </div>

** SOLUTION Recovery time shouldn't be several years
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Recovery-time-shouldn-t-be-several-years
:CUSTOM_ID: 2023-01-29-16-57-28-Recovery-time-shouldn-t-be-several-years
:END:

We mentioned that =recovery_time=, which is expressed as $1 / \gamma$, is ~1 week

We're clearly putting high probability on regions near 0, i.e. /long/ recovery times

#+begin_src julia
plot(truncated(Normal(0.4, 0.5); lower=0), label=nothing, title="Œ≥", size=(500, 300))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/ed3058dc552f72dbe5151feb938d103b75251f63.svg]]

_Should probably be putting less probability mass near 0_

** SOLUTION What if ${\color{red} \beta} > N$?
:PROPERTIES:
:ID:       2023-01-29-16-57-28-What-if-color-red-beta-N
:CUSTOM_ID: 2023-01-29-16-57-28-What-if-color-red-beta-N
:END:
Then for $t = 0$ we have
\begin{equation*}
\frac{\mathrm{d} S}{\mathrm{d} t} \bigg|_{t = 0} = - {\color{red} \beta} S \frac{I}{N} > - N (N - 1) \frac{1}{N} = - (N - 1)
\end{equation*}

i.e. we /immediately/ infect everyone on the very first time-step

Also doesn't seem very realistic

#+REVEAL: split

/But/ under our current prior does this matter?

#+begin_src julia
# ‚Ñô(Œ≤ > N) = 1 - ‚Ñô(Œ≤ ‚â§ N)
1 - cdf(truncated(Normal(2, 1); lower=0), N)
#+end_src

#+RESULTS:
: 0.0

Better yet

#+begin_src julia
quantile(truncated(Normal(2, 1); lower=0), 0.95)
#+end_src

#+RESULTS:
: 3.6559843567138275

i.e. 95% of the probability mass falls below ~3.65

‚üπ _Current prior for $\beta$ seems fine (‚úì)_

#+REVEAL: split

Before we change the prior, let's also make it a bit easier to change the prior using =@submodel=

#+HTML: <div class="fragment (appear)">

=@submodel= allows you call models within models, e.g.

#+begin_src julia
@model function ModelA()
    x_hidden_from_B ~ Normal()
    x = x_hidden_from_B + 100
    return x
end

@model function ModelB()
    @submodel x = ModelA()
    y ~ Normal(x, 1)

    return (; x, y)
end
#+end_src

#+RESULTS:
: ModelB (generic function with 2 methods)

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

#+begin_src julia
# So if we call `B` we only see `x` and `y`
println(ModelB()())
#+end_src

#+RESULTS:
: (x = 101.38020683691398, y = 103.1132024568557)

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

#+begin_src julia
# While if we sample from `B` we get the latent variables
println(rand(ModelB()))
#+end_src

#+RESULTS:
: (x_hidden_from_B = 0.9613929680828116, y = 100.5481850154222)

#+HTML: </div>

#+REVEAL: split

To avoid clashes of variable-names, we can specify a =prefix=

#+begin_src julia
@model ModelA() = (x ~ Normal(); return x + 100)

@model function ModelB()
    # Given it a prefix to use for the variables in `A`.
    @submodel prefix=:inner x_inner = ModelA()
    x ~ Normal(x_inner, 1)

    return (; x_inner, x)
end
#+end_src

#+RESULTS:
: ModelB (generic function with 2 methods)

#+begin_src julia
print(rand(ModelB()))
#+end_src

#+RESULTS:
: (var"inner.x" = 0.16844167629567983, x = 99.58017059461453)

#+REVEAL: split

=@submodel= is useful as it allows you to:
1. Easy to swap out certain parts of your model.
2. Can re-use models across projects and packages.

When working on larger projects, this really shines

#+REVEAL: split

Equipped with =@submodel= we can replace

#+begin_src julia :eval no :tangle no
Œ≤ ~ truncated(Normal(2, 1); lower=0)
Œ≥ ~ truncated(Normal(0.4, 0.5); lower=0)
#+end_src

with

#+begin_src julia :eval no :tangle no
@submodel p = prior(problem_wrapper)
#+end_src

#+HTML: <div class="fragment (appear)">

where =prior= can be something like

#+begin_src julia
@model function prior_original(problem_wrapper::SIRProblem)
    Œ≤ ~ truncated(Normal(2, 1); lower=0)
    Œ≥ ~ truncated(Normal(0.4, 0.5); lower=0)

    return [Œ≤, Œ≥]
end

@model function prior_improved(problem_wrapper::SIRProblem)
    # NOTE: Should probably also lower mean for `Œ≤` since
    # more probability mass on small `Œ≥` ‚üπ `R0 =  Œ≤ / Œ≥` grows.
    Œ≤ ~ truncated(Normal(1, 1); lower=0)
    # NOTE: New prior for `Œ≥`.
    Œ≥ ~ Beta(2, 5)

    return [Œ≤, Œ≥]
end
#+end_src

#+RESULTS:
: prior_improved (generic function with 2 methods)

#+HTML: </div>

#+REVEAL: split

#+begin_src julia
@model function epidemic_model(
    problem_wrapper::AbstractEpidemicProblem,
    prior  # NOTE: now we just pass the prior as an argument
)
    # NOTE: And use `@submodel` to embed the `prior` in our model.
    @submodel p = prior(problem_wrapper)

    œï‚Åª¬π ~ Exponential(1/5)
    œï = inv(œï‚Åª¬π)

    problem_new = remake(problem_wrapper.problem, p=p)  # Replace parameters `p`.
    sol = solve(problem_new, saveat=1)                  # Solve!

    # Extract the `infected`.
    sol_for_observed = infected(problem_wrapper, sol)[2:end]

    # NOTE: `product_distribution` is faster for larger dimensional problems,
    # and it does not require explicit allocation of the vector.
    in_bed ~ product_distribution(NegativeBinomial2.(sol_for_observed .+ 1e-5, œï))

    Œ≤, Œ≥ = p[1:2]
    return (R0 = Œ≤ / Œ≥, recovery_time = 1 / Œ≥, infected = sol_for_observed)
end
#+end_src

#+RESULTS:
: epidemic_model (generic function with 2 methods)

#+REVEAL: split

#+HTML: <div class="x-small-text">

Another neat trick is to return early if integration fail

#+HTML: </div>

#+begin_src julia
@model function epidemic_model(
    problem_wrapper::AbstractEpidemicProblem,
    prior  # now we just pass the prior as an argument
)
    # And use `@submodel` to embed the `prior` in our model.
    @submodel p = prior(problem_wrapper)

    œï‚Åª¬π ~ Exponential(1/5)
    œï = inv(œï‚Åª¬π)

    problem_new = remake(problem_wrapper.problem, p=p)  # Replace parameters `p`.
    sol = solve(problem_new, saveat=1)                  # Solve!

    # NOTE: Return early if integration failed.
    if !issuccess(sol)
        Turing.@addlogprob! -Inf  # NOTE: Causes automatic rejection.
        return nothing
    end

    # Extract the `infected`.
    sol_for_observed = infected(problem_wrapper, sol)[2:end]

    # `product_distribution` is faster for larger dimensional problems,
    # and it does not require explicit allocation of the vector.
    in_bed ~ product_distribution(NegativeBinomial2.(sol_for_observed .+ 1e-5, œï))

    Œ≤, Œ≥ = p[1:2]
    return (R0 = Œ≤ / Œ≥, recovery_time = 1 / Œ≥, infected = sol_for_observed)
end
#+end_src

#+RESULTS:
: epidemic_model (generic function with 2 methods)

#+REVEAL: split

Equipped with this we can now easily construct /two/ models using different priors

#+begin_src julia
sir = SIRProblem(N);
model_original = epidemic_model(sir, prior_original);
model_improved = epidemic_model(sir, prior_improved);
#+end_src

#+RESULTS:

but using the same underlying =epidemic_model=

#+begin_src julia
chain_prior_original = sample(model_original, Prior(), 10_000; progress=false);
chain_prior_improved = sample(model_improved, Prior(), 10_000; progress=false);
#+end_src

#+RESULTS:

Let's compare the resulting priors over some of the quantities of interest

#+REVEAL: split

Let's compare the =generated_quantities=, e.g. $R_0$

#+HTML: <div class="small-text">

#+begin_src julia
chain_quantities_original = to_chains(
    generated_quantities(
        model_original,
        chain_prior_original
    );
);

chain_quantities_improved = to_chains(
    generated_quantities(
        model_improved,
        chain_prior_improved
    );
);
#+end_src

#+RESULTS:

#+begin_src julia
p = plot(; legend=false, size=(500, 200))
plot_trajectories!(p, group(chain_quantities_original, :infected); n = 100, trajectory_color="red")
plot_trajectories!(p, group(chain_quantities_improved, :infected); n = 100, trajectory_color="blue")
hline!([N], color="red", linestyle=:dash)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/2e1579a71c4072534cabe41a233cd283543874e6.svg]]

#+HTML: </div>

#+REVEAL: split

#+HTML: <div class="small-text">

#+begin_src julia
plt1 = plot(legend=false)
plot_trajectory_quantiles!(plt1, group(chain_quantities_original, :infected))
hline!(plt1, [N], color="red", linestyle=:dash)

plt2 = plot(legend=false)
plot_trajectory_quantiles!(plt2, group(chain_quantities_improved, :infected))
hline!(plt2, [N], color="red", linestyle=:dash)

plot(plt1, plt2, layout=(2, 1))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/cffea7a80541e6f61fd182de85cb18bc8520b0b4.svg]]

#+HTML: </div>

This makes sense: if half of the population is immediately infected ‚üπ number of infected tapers wrt. time as they recover

#+REVEAL: split

For =model_improved= we then have

#+begin_src julia :display text/plain
DataFrame(quantile(chain_quantities_improved[:, [:R0, :recovery_time], :]))
#+end_src

#+RESULTS:
: [1m2√ó6 DataFrame[0m
: [1m Row [0m‚îÇ[1m parameters    [0m[1m 2.5%     [0m[1m 25.0%   [0m[1m 50.0%   [0m[1m 75.0%   [0m[1m 97.5%   [0m
:      ‚îÇ[90m Symbol        [0m[90m Float64  [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ R0             0.286716  2.23462  4.33312  8.11769  33.3006
:    2 ‚îÇ recovery_time  1.53444   2.53735  3.72106  6.17165  22.3583

Compare to =model_original=

#+begin_src julia :display text/plain
DataFrame(quantile(chain_quantities_original[:, [:R0, :recovery_time], :]))
#+end_src

#+RESULTS:
: [1m2√ó6 DataFrame[0m
: [1m Row [0m‚îÇ[1m parameters    [0m[1m 2.5%     [0m[1m 25.0%   [0m[1m 50.0%   [0m[1m 75.0%   [0m[1m 97.5%   [0m
:      ‚îÇ[90m Symbol        [0m[90m Float64  [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m[90m Float64 [0m
: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
:    1 ‚îÇ R0             0.473824  2.10679  3.68512  7.09941  63.941
:    2 ‚îÇ recovery_time  0.714109  1.21813  1.86754  3.44443  28.9721

** TASK Make =epidemic_model= work for =SEIRProblem=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Make-epidemic-model-work-for-SEIRProblem
:CUSTOM_ID: 2023-01-29-16-57-28-Make-epidemic-model-work-for-SEIRProblem
:END:
1. [ ] Implement a prior which also includes $\sigma$ and execute
   =epidemic_model= with it
2. [ ] Can we make a better prior for $\sigma$? Do we even need one?

#+begin_src julia :eval no
@model function prior_original(problem_wrapper::SEIRProblem)
    # TODO: Implement
end
#+end_src

#+begin_src julia :exports (by-backend (reveal "none") (t "code"))
# Some space so you don't cheat.



















# Are you sure?
#+end_src

#+RESULTS:


** SOLUTION
:PROPERTIES:
:ID:       2023-01-29-16-57-28-
:CUSTOM_ID: 2023-01-29-16-57-28-
:END:

#+begin_src julia
@model function prior_original(problem_wrapper::SEIRProblem)
    Œ≤ ~ truncated(Normal(2, 1); lower=0)
    Œ≥ ~ truncated(Normal(0.4, 0.5); lower=0)
    œÉ ~ truncated(Normal(0.8, 0.5); lower=0)

    return [Œ≤, Œ≥, œÉ]
end
#+end_src

#+RESULTS:
: prior_original (generic function with 4 methods)

#+begin_src julia
model_seir = epidemic_model(SEIRProblem(N), prior_original)
print(model_seir())
#+end_src

#+RESULTS:
: (R0 = 10.841276436804648, recovery_time = 4.848273422496571, infected = [1.8556649722515102, 5.109504870724178, 14.128014745551562, 38.02055081470466, 95.42621500541911, 205.1678971459235, 340.4657927412176, 423.48245642091246, 425.60404263438573, 380.6571766736939, 322.5152690195781, 266.93526450913197, 218.78163169041363, 178.58496449305477])

** WARNING Consult with domain experts
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Consult-with-domain-experts
:CUSTOM_ID: 2023-01-29-16-57-28-Consult-with-domain-experts
:END:
This guy should _not_ be the one setting your priors!

#+ATTR_HTML: :height 400px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-18_14-49-24_471337_3317365246956_1262712540_o.jpg]]

Get an actual scientist to do that...

** Condition
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Condition
:CUSTOM_ID: 2023-01-29-16-57-28-Condition
:END:
Now let's actually involve the data

#+HTML: <div class="fragment (appear)">

We can condition a =Model= as so

#+begin_src julia
# Condition on the observations.
model = epidemic_model(SIRProblem(N), prior_improved)
model_conditioned = model | (in_bed = data.in_bed,)
#+end_src

#+RESULTS:
: Model(
:   args = (:problem_wrapper, :prior)
:   defaults = ()
:   context = ConditionContext((in_bed = [3, 8, 26, 76, 225, 298, 258, 233, 189, 128, 68, 29, 14, 4],), DynamicPPL.DefaultContext())
: )

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

You know what time it is: /inference time/!

#+HTML: </div>


** Metropolis-Hastings (MH)
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Metropolis-Hastings--MH
:CUSTOM_ID: 2023-01-29-16-57-28-Metropolis-Hastings--MH
:END:

#+begin_src julia
chain_mh = sample(model_conditioned, MH(), MCMCThreads(), 10_000, 4; discard_initial=5_000);
#+end_src

#+RESULTS:

Rhat is /okay-ish/ but not great, and ESS is pretty low innit?

#+REVEAL: split

#+begin_src julia
plot(chain_mh; size=(800, 500))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/7763ba1e7b6bb223fde4d453cab14cbcf723b75a.svg]]

Eeehh doesn't look the greatest

#+REVEAL: split

Difficult to trust these results, but let's check if it at least did /something/ useful

#+begin_src julia
# We're using the unconditioned model!
predictions_mh = predict(model, chain_mh)
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (10000√ó14√ó4 Array{Float64, 3}):

Iterations        = 1:1:10000
Number of chains  = 4
Samples per chain = 10000
parameters        = in_bed[1], in_bed[2], in_bed[3], in_bed[4], in_bed[5], in_bed[6], in_bed[7], in_bed[8], in_bed[9], in_bed[10], in_bed[11], in_bed[12], in_bed[13], in_bed[14]
internals         = 

Summary Statistics
 [1m parameters [0m [1m     mean [0m [1m     std [0m [1m    mcse [0m [1m   ess_bulk [0m [1m   ess_tail [0m [1m    rha[0m ‚ãØ
 [90m     Symbol [0m [90m  Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m    Float64 [0m [90m    Float64 [0m [90m Float6[0m ‚ãØ

   in_bed[1]     3.3249    2.1920    0.0118   33756.7191   38619.0772    1.000 ‚ãØ
   in_bed[2]    10.9586    5.4223    0.0969    3388.1068    5478.6177    1.001 ‚ãØ
   in_bed[3]    34.3216   15.3619    0.4614    1183.2380    2101.3284    1.002 ‚ãØ
   in_bed[4]    93.6330   41.0836    1.4312     847.9521    1582.5817    1.004 ‚ãØ
   in_bed[5]   187.9322   77.5176    2.2562    1184.3400    2207.8895    1.005 ‚ãØ
   in_bed[6]   248.2565   94.9655    1.6925    2960.3179    3339.7323    1.005 ‚ãØ
   in_bed[7]   235.6735   90.0406    1.1257    6390.9925    4352.1889    1.004 ‚ãØ
   in_bed[8]   183.8796   70.2155    1.0787    4418.1236    4169.8339    1.003 ‚ãØ
   in_bed[9]   131.3458   52.2405    1.1180    2381.4977    3047.1447    1.003 ‚ãØ
  in_bed[10]    89.0473   37.2303    0.9557    1786.5982    1939.8059    1.003 ‚ãØ
  in_bed[11]    58.8175   25.2954    0.7115    1401.5932    1790.4031    1.002 ‚ãØ
  in_bed[12]    38.3867   17.5306    0.5328    1186.2437    1603.0100    1.003 ‚ãØ
  in_bed[13]    24.8612   12.1535    0.4086     966.0334    1510.0551    1.003 ‚ãØ
  in_bed[14]    16.0139    8.3750    0.2876     926.7078    1442.5682    1.003 ‚ãØ
[36m                                                               2 columns omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m    25.0% [0m [1m    50.0% [0m [1m    75.0% [0m [1m    97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m  Float64 [0m

   in_bed[1]    0.0000     2.0000     3.0000     5.0000     8.0000
   in_bed[2]    3.0000     7.0000    10.0000    14.0000    24.0000
   in_bed[3]   11.0000    24.0000    32.0000    42.0000    70.0000
   in_bed[4]   32.0000    66.0000    88.0000   114.0000   190.0000
   in_bed[5]   68.0000   136.0000   177.0000   228.0000   369.0000
   in_bed[6]   95.0000   184.0000   237.0000   299.0000   470.0000
   in_bed[7]   90.0000   174.0000   225.0000   284.0000   444.0000
   in_bed[8]   71.0000   136.0000   176.0000   222.0000   344.0000
   in_bed[9]   50.0000    96.0000   125.0000   159.0000   252.0000
  in_bed[10]   32.0000    64.0000    84.0000   108.0000   176.0000
  in_bed[11]   21.0000    42.0000    55.0000    72.0000   118.0000
  in_bed[12]   12.9750    26.0000    36.0000    47.0000    80.0000
  in_bed[13]    7.0000    17.0000    23.0000    31.0000    54.0000
  in_bed[14]    4.0000    10.0000    15.0000    20.0000    36.0000
#+end_example

#+REVEAL: split

#+begin_src julia
plot_trajectories!(plot(legend=false, size=(600, 300)), predictions_mh; data=data)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/53d5bcefafe0e9c29e4ee0f560bc2648d8b43118.svg]]

#+begin_src julia
plot_trajectory_quantiles!(plot(legend=false, size=(600, 300)), predictions_mh; data=data)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/0d84524cc352ba3471bf66156dda0a8cfd1e66b9.svg]]

Okay, it's not /completely/ useless, but my trust-issues are still present.

Metropolis-Hastings have disappointed me one too many times before.

** So instead, let's go =NUTS=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-So-instead-let-s-go-NUTS
:CUSTOM_ID: 2023-01-29-16-57-28-So-instead-let-s-go-NUTS
:END:
That's right, we're reaching for the *No U-Turn sampler (NUTS)*

*** 
:PROPERTIES:
:reveal_background_iframe: file:///home/tor/Projects/public/mcmc-demo/app.html?closeControls=true&algorithm=HamiltonianMH&target=standard&seed=1&autoplay=true&histBins=100
:ID:       2023-01-29-16-57-28-
:CUSTOM_ID: 2023-01-29-16-57-28-
:END:

#+ATTR_REVEAL: :frag (appear)
[[https://chi-feng.github.io/mcmc-demo/app.html][https://chi-feng.github.io/mcmc-demo/app.html]]

** 
:PROPERTIES:
:ID:       2023-01-29-16-57-28-
:CUSTOM_ID: 2023-01-29-16-57-28-
:END:

#+begin_quote
Wooaah there! =NUTS= requires gradient information!

How are you going to get that through that =solve=?
#+end_quote

Good question, voice in my head

#+ATTR_REVEAL: :frag (appear)
I'm obviously not going to it myself

** Automatic differentiation (AD) in Julia
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Automatic-differentiation--AD--in-Julia
:CUSTOM_ID: 2023-01-29-16-57-28-Automatic-differentiation--AD--in-Julia
:END:
- [[https://github.com/JuliaDiff/ForwardDiff.jl][ForwardDiff.jl]]: forward-mode AD /(default in Turing.jl)/
- [[https://github.com/JuliaDiff/ReverseDiff.jl][ReverseDiff.jl]]: tape-based reverse-mode AD
- [[https://github.com/FluxML/Zygote.jl][Zygote.jl]]: source-to-source reverse-mode AD
- And more...

#+HTML: <div class="fragment (appear)">

Up-and-coming

- [[https://github.com/EnzymeAD/Enzyme.jl][Enzyme.jl]]: Julia bindings for [[https://github.com/EnzymeAD/Enzyme.jl][Enzyme]] which ADs LLVM (low-level)
- [[https://github.com/JuliaDiff/Diffractor.jl][Diffractor.jl]]: experimental mixed-mode AD meant to replace Zygote.jl

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

Of importance
- [[https://github.com/JuliaDiff/ChainRulesCore.jl][ChainRulesCore.jl]]: light-weight package for defining rules, compatible with many of the above

#+HTML: </div>

#+REVEAL: split

*Important*

#+begin_quote
When you write code, you don't have to make a choice which one you want to use!
#+end_quote

All the (stable) ones, will (mostly) work

/But/ how you write code will affect performance characteristics

Takes a bit of know-how + a bit of digging to go properly "vroom!"

** Differentiating through =solve=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Differentiating-through-solve
:CUSTOM_ID: 2023-01-29-16-57-28-Differentiating-through-solve
:END:
With that being said, differentiating through numerical =solve= is not necessarily trivial to do efficiently

There are numerous ways of approaching this problem

#+ATTR_HTML: :width 400px
#+ATTR_ORG: :width 400
[[file:assets/attachments/2023-01-22_12-30-07_Screenshot_20230122_122936.png]]

[[https://arxiv.org/abs/1812.01892][https://arxiv.org/abs/1812.01892]] is /great/ resource

#+HTML: <div class="fragment (appear)">

But this is why we have [[https://github.com/SciML/SciMLSensitivity.jl][=SciMLSensitivity.jl=]]

[[https://docs.sciml.ai/SciMLSensitivity/stable/manual/differential_equation_sensitivities/#Choosing-a-Sensitivity-Algorithm][SciMLSensitivity.jl docs]] also provides a great overview of different approaches

#+HTML: </div>

#+REVEAL: split

#+begin_src julia
using SciMLSensitivity
#+end_src

#+RESULTS:

It offers

1. /Discrete sensitivity analysis/ or the /"Direct" method/: just use
   =ForwardDiff.Dual= in the =solve=.
2. /Continuous local sensitivity analysis (CSA)/: extends the original
   system such that the =solve= gives you both the solution and the the
   gradient simultaenously.
3. /Adjoint methods/: construct a backwards system whose solution gives
   us the gradient.

Just do =solve(problem, solver, sensealg = ...)=

** Back to being =NUTS=
   :PROPERTIES:
   :CUSTOM_ID: back-to-being-nuts
   :ID:       2023-01-29-16-57-28-Back-to-being-NUTS
   :END:

#+begin_src julia
chain = sample(model_conditioned, NUTS(0.8), MCMCThreads(), 1000, 4);
#+end_src

#+RESULTS:
#+begin_example
‚îå Info: Found initial step size
‚îî   œµ = 0.8
‚îå Info: Found initial step size
‚îî   œµ = 0.4
‚îå Info: Found initial step size
‚îî   œµ = 0.025
‚îå Info: Found initial step size
‚îî   œµ = 0.05
‚îå Warning: The current proposal will be rejected due to numerical error(s).
‚îÇ   isfinite.((Œ∏, r, ‚ÑìœÄ, ‚ÑìŒ∫)) = (true, false, false, false)
‚îî @ AdvancedHMC ~/.julia/packages/AdvancedHMC/4fByY/src/hamiltonian.jl:49
#+end_example

#+REVEAL: split

#+begin_src julia
chain
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó15√ó4 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 4
Samples per chain = 1000
Wall duration     = 8.48 seconds
Compute duration  = 33.22 seconds
parameters        = Œ≤, Œ≥, œï‚Åª¬π
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
  parameters      mean       std   naive_se      mcse         ess      rhat    ‚ãØ
      Symbol   Float64   Float64    Float64   Float64     Float64   Float64    ‚ãØ

           Œ≤    1.7305    0.0532     0.0008    0.0012   2305.3519    1.0006    ‚ãØ
           Œ≥    0.5305    0.0430     0.0007    0.0009   2432.0514    0.9998    ‚ãØ
         œï‚Åª¬π    0.1349    0.0727     0.0011    0.0015   2211.5812    0.9994    ‚ãØ
                                                                1 column omitted

Quantiles
  parameters      2.5%     25.0%     50.0%     75.0%     97.5% 
      Symbol   Float64   Float64   Float64   Float64   Float64 

           Œ≤    1.6279    1.6970    1.7281    1.7618    1.8401
           Œ≥    0.4464    0.5024    0.5294    0.5580    0.6172
         œï‚Åª¬π    0.0394    0.0843    0.1180    0.1699    0.3165
#+end_example

Muuuch better! Both ESS and Rhat is looking good

#+REVEAL: split

#+begin_src julia
plot(chain; size=(800, 500))
#+end_src

#+RESULTS:
[[file:assets/outputs/ba6a57881c744560992e6aeb0ff47cfb9aaf9238.png]]

#+REVEAL: split

#+begin_src julia
# Predict using the results from NUTS.
predictions = predict(model, chain)
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó14√ó4 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 4
Samples per chain = 1000
parameters        = in_bed[1], in_bed[2], in_bed[3], in_bed[4], in_bed[5], in_bed[6], in_bed[7], in_bed[8], in_bed[9], in_bed[10], in_bed[11], in_bed[12], in_bed[13], in_bed[14]
internals         = 

Summary Statistics
  parameters       mean       std   naive_se      mcse         ess      rhat 
      Symbol    Float64   Float64    Float64   Float64     Float64   Float64 

   in_bed[1]     3.2840    2.1793     0.0345    0.0327   4055.3023    0.9998
   in_bed[2]    10.7950    5.4560     0.0863    0.0749   3714.2037    1.0005
   in_bed[3]    34.0883   15.7327     0.2488    0.2596   3642.2139    1.0001
   in_bed[4]    93.0002   41.3318     0.6535    0.7048   3577.5458    1.0012
   in_bed[5]   187.5652   79.0050     1.2492    1.2543   3478.9204    1.0010
   in_bed[6]   248.9330   97.2779     1.5381    1.6339   4056.1039    1.0008
   in_bed[7]   234.6240   89.1151     1.4090    1.2074   4022.8396    0.9996
   in_bed[8]   185.4033   71.8807     1.1365    1.0479   3860.3337    0.9997
   in_bed[9]   130.9750   50.4204     0.7972    0.8315   3694.8750    0.9999
  in_bed[10]    88.2115   35.8989     0.5676    0.6532   3401.2244    0.9999
  in_bed[11]    59.4943   25.4118     0.4018    0.4155   3460.7875    0.9997
  in_bed[12]    38.6793   16.7184     0.2643    0.2929   3697.7714    1.0005
  in_bed[13]    24.8678   11.4870     0.1816    0.2081   3578.3080    1.0001
  in_bed[14]    15.9450    8.2237     0.1300    0.1376   3389.6307    0.9996

Quantiles
  parameters      2.5%      25.0%      50.0%      75.0%      97.5% 
      Symbol   Float64    Float64    Float64    Float64    Float64 

   in_bed[1]    0.0000     2.0000     3.0000     5.0000     8.0000
   in_bed[2]    2.9750     7.0000    10.0000    14.0000    24.0000
   in_bed[3]   11.0000    24.0000    32.0000    42.0000    73.0000
   in_bed[4]   33.0000    65.0000    87.0000   113.0000   190.0000
   in_bed[5]   69.0000   134.0000   177.0000   226.0000   376.0000
   in_bed[6]   95.0000   184.0000   237.0000   299.0000   473.0250
   in_bed[7]   88.0000   175.0000   224.0000   283.0000   440.0250
   in_bed[8]   70.0000   137.0000   176.0000   225.0000   351.0000
   in_bed[9]   49.0000    96.0000   126.0000   159.0000   245.0000
  in_bed[10]   31.9750    64.0000    84.0000   107.0000   170.0000
  in_bed[11]   19.0000    42.0000    57.0000    73.0000   118.0250
  in_bed[12]   13.0000    27.0000    36.0000    48.0000    77.0000
  in_bed[13]    7.0000    17.0000    23.0000    31.0000    51.0000
  in_bed[14]    4.0000    10.0000    15.0000    20.0000    36.0000
#+end_example

#+REVEAL: split

#+begin_src julia
plot_trajectories!(plot(legend=false, size=(600, 300)), predictions; n = 1000, data=data)
#+end_src

#+RESULTS:
[[file:assets/outputs/870b8fafd890396444043fd96c7d303fb7722627.png]]

#+REVEAL: split

#+begin_src julia
plot_trajectory_quantiles!(plot(legend=false, size=(600, 300)), predictions; data=data)
#+end_src

#+RESULTS:
[[file:assets/outputs/145ba1245ad3196f9bb3001254df5b3cf451e778.png]]

** Simulation-based calibration (SBC) [[https://arxiv.org/abs/1804.06788][Talts et. al. (2018)]]
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Simulation-based-calibration--SBC--https-arxiv-dot-org-abs-1804-dot-06788-Talts-et-dot-al-dot--2018
:CUSTOM_ID: 2023-01-29-16-57-28-Simulation-based-calibration--SBC--https-arxiv-dot-org-abs-1804-dot-06788-Talts-et-dot-al-dot--2018
:END:
1. Sample from prior $\theta_1, \dots, \theta_n \sim p(\theta)$.
2. Sample datasets $\mathcal{D}_i \sim p(\cdot \mid \theta_i)$ for $i = 1, \dots, n$.
3. Obtain (approximate) $p(\theta \mid \mathcal{D}_i)$ for $i = 1, \dots, n$.

For large enough (n), the "combination" of the posteriors should recover the prior!

"Combination" here usually means computing some statistic and comparing against what it should be

#+ATTR_HTML: :width 800px
#+ATTR_ORG: :width 400
[[file:assets/attachments/2023-01-22_12-09-24_Screenshot_20230122_120848.png]]

#+REVEAL: split

That's very expensive ‚Üí in practice we just do this once or twice

#+begin_src julia :results scalar
# Sample from the conditioned model so we don't get the `in_bed` variables too
using Random  # Just making sure the numbers of somewhat interesting
rng = MersenneTwister(43);
test_values = rand(rng, NamedTuple, model_conditioned)
#+end_src

#+RESULTS:
: (Œ≤ = 1.2254566808077714, Œ≥ = 0.27594266205681933, œï‚Åª¬π = 0.13984179162984164)

Now we condition on those values and run once to generate data

#+begin_src julia
model_test = model | test_values
#+end_src

#+RESULTS:
: Model(
:   args = (:problem_wrapper, :prior)
:   defaults = ()
:   context = ConditionContext((Œ≤ = 1.2254566808077714, Œ≥ = 0.27594266205681933, œï‚Åª¬π = 0.13984179162984164), DynamicPPL.DefaultContext())
: )

#+begin_src julia
in_best_test = rand(rng, model_test).in_bed;
#+end_src

#+RESULTS:

#+REVEAL: split

Next, inference!

#+begin_src julia
model_test_conditioned = model | (in_bed = in_best_test,)
#+end_src

#+RESULTS:
: Model(
:   args = (:problem_wrapper, :prior)
:   defaults = ()
:   context = ConditionContext((in_bed = [1, 9, 11, 45, 159, 136, 270, 123, 463, 376, 231, 148, 99, 162],), DynamicPPL.DefaultContext())
: )

#+begin_src julia
# Let's just do a single chain here.
chain_test = sample(model_test_conditioned, NUTS(0.8), 1000);
#+end_src

#+RESULTS:
: ‚îå Info: Found initial step size
: ‚îî   œµ = 0.0125
: 
Sampling:   4%|‚ñà‚ñä                                       |  ETA: 0:00:05
Sampling:  12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                    |  ETA: 0:00:02
Sampling:  25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              |  ETA: 0:00:01
Sampling:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         |  ETA: 0:00:01
Sampling:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   |  ETA: 0:00:01
Sampling:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              |  ETA: 0:00:00
Sampling:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        |  ETA: 0:00:00
Sampling:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   |  ETA: 0:00:00
Sampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01

#+REVEAL: split

Did we recover the parameters?

#+HTML: <div class="small-text">

#+begin_src julia
ps = []
for sym in [:Œ≤, :Œ≥, :œï‚Åª¬π]
    p = density(chain_test[:, [sym], :])
    vline!([test_values[sym]])
    push!(ps, p)
end
plot(ps..., layout=(3, 1), size=(600, 400))
#+end_src

#+RESULTS:
[[file:assets/outputs/be1c12fbb76e6f039cc149b75842d8ee461b8f89.png]]

#+HTML: </div>

Yay!

** Samplers in Turing.jl
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Samplers-in-Turing-dot-jl
:CUSTOM_ID: 2023-01-29-16-57-28-Samplers-in-Turing-dot-jl
:END:
- Metropolis-Hastings, MALA, emcee ([[https://github.com/TuringLang/AdvancedMH.jl][AdvancedMH.jl]])
- Hamiltonian Monte Carlo, NUTS ([[https://github.com/TuringLang/AdvancedMH.jl][AdvancedHMC.jl]])
- SMC ([[https://github.com/TuringLang/AdvancedPS.jl][AdvancedPS.jl]])
- Elliptical Slice Sampling ([[https://github.com/TuringLang/EllipticalSliceSampling.jl][EllipticalSliceSampling.jl]])
- Nested sampling ([[https://github.com/TuringLang/NestedSamplers.jl][NestedSamplers.jl]])
- (Experimental) Tempered sampling ([[https://github.com/Julia-Tempering/Pigeons.jl][Pigeons.jl]] and [[https://github.com/TuringLang/MCMCTempering.jl][MCMCTempering.jl]])

#+REVEAL: split

You can also combine some of these in Turing.jl

#+HTML: <div class="small-text">

#+begin_src julia
using LinearAlgebra: I

@model function linear_regression(X)
    num_params = size(X, 1)
    Œ≤ ~ MvNormal(ones(num_params))
    œÉ¬≤ ~ InverseGamma(2, 3)
    y ~ MvNormal(vec(Œ≤' * X), œÉ¬≤ * I)
end

# Generate some dummy data.
X = randn(2, 1_000); lin_reg = linear_regression(X); true_vals = rand(lin_reg)

# Condition.
lin_reg_conditioned = lin_reg | (y = true_vals.y,);
#+end_src

#+RESULTS:

We can then do =Gibbs= but sampling $Œ≤$ using =ESS= and $\sigma^2$ using =HMC=

#+begin_src julia
chain_ess_hmc = sample(lin_reg_conditioned, Gibbs(ESS(:Œ≤), HMC(1e-3, 16, :œÉ¬≤)), 1_000);
#+end_src

#+RESULTS:
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00[39m
:

#+HTML: </div>

#+REVEAL: split

#+HTML: <div class="small-text">

#+begin_src julia
chain_ess_hmc
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó4√ó1 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 0.46 seconds
Compute duration  = 0.46 seconds
parameters        = Œ≤[1], Œ≤[2], œÉ¬≤
internals         = lp

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m ‚ãØ
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m ‚ãØ

        Œ≤[1]   -0.4997    0.0441    0.0028   337.5415   327.4560    1.0017     ‚ãØ
        Œ≤[2]    0.3895    0.0404    0.0022   289.2465   247.3620    1.0020     ‚ãØ
          œÉ¬≤    1.2700    0.0583    0.0089    42.1068    84.2563    1.0555     ‚ãØ
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

        Œ≤[1]   -0.5659   -0.5244   -0.5027   -0.4778   -0.4312
        Œ≤[2]    0.3211    0.3662    0.3897    0.4136    0.4686
          œÉ¬≤    1.1480    1.2329    1.2714    1.3108    1.3711
#+end_example

Could potentially lead to improvements

*NOTE:* Usually /very/ difficult to choose sampler parameters in this case

#+HTML: </div>

#+REVEAL: split

Means one can also mix discrete and continuous

#+HTML: <div class="small-text">

#+begin_src julia 
@model function mixture(n)
    cluster ~ filldist(Categorical([0.25, 0.75]), n)
    Œº ~ MvNormal([-10.0, 10.0], I)
    x ~ product_distribution(Normal.(Œº[cluster], 1))
end

model_mixture = mixture(10)
fake_values_mixture = rand(model_mixture)
model_mixture_conditioned = model_mixture | (x = fake_values_mixture.x, )
chain_discrete = sample(
    model_mixture_conditioned, Gibbs(PG(10, :cluster), HMC(1e-3, 16, :Œº)), MCMCThreads(), 1_000, 4
)
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó13√ó4 Array{Float64, 3}):

Iterations        = 1:1:1000
Number of chains  = 4
Samples per chain = 1000
Wall duration     = 8.99 seconds
Compute duration  = 34.94 seconds
parameters        = cluster[1], cluster[2], cluster[3], cluster[4], cluster[5], cluster[6], cluster[7], cluster[8], cluster[9], cluster[10], Œº[1], Œº[2]
internals         = lp

Summary Statistics
 [1m  parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m  ess_bulk [0m [1m  ess_tail [0m [1m    rhat [0m ‚ãØ
 [90m      Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m   Float64 [0m [90m   Float64 [0m [90m Float64 [0m ‚ãØ

   cluster[1]    1.9997    0.0158    0.0002   4016.0965         NaN    1.0000  ‚ãØ
   cluster[2]    2.0000    0.0000       NaN         NaN         NaN       NaN  ‚ãØ
   cluster[3]    1.9995    0.0224    0.0005   2004.0160         NaN    1.0010  ‚ãØ
   cluster[4]    1.9995    0.0224    0.0004   4002.3197         NaN    0.9999  ‚ãØ
   cluster[5]    2.0000    0.0000       NaN         NaN         NaN       NaN  ‚ãØ
   cluster[6]    1.9992    0.0274    0.0006   2406.5231         NaN    1.0005  ‚ãØ
   cluster[7]    1.9965    0.0591    0.0032    340.3033         NaN    1.0061  ‚ãØ
   cluster[8]    1.9995    0.0224    0.0005   1691.3376         NaN    1.0010  ‚ãØ
   cluster[9]    2.0000    0.0000       NaN         NaN         NaN       NaN  ‚ãØ
  cluster[10]    1.0008    0.0274    0.0006   2222.0124   2222.0124    1.0005  ‚ãØ
         Œº[1]   -8.6166    0.5168    0.1786      8.7221     15.2414    3.2763  ‚ãØ
         Œº[2]    9.4711    0.5231    0.1767      9.3008     14.8740    2.4261  ‚ãØ
[36m                                                                1 column omitted[0m

Quantiles
 [1m  parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m      Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

   cluster[1]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[2]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[3]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[4]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[5]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[6]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[7]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[8]    2.0000    2.0000    2.0000    2.0000    2.0000
   cluster[9]    2.0000    2.0000    2.0000    2.0000    2.0000
  cluster[10]    1.0000    1.0000    1.0000    1.0000    1.0000
         Œº[1]   -9.7048   -8.8341   -8.5010   -8.2766   -7.7699
         Œº[2]    8.3393    9.0501    9.5868    9.9171   10.1812
#+end_example

#+HTML: </div>

#+REVEAL: split

#+HTML: <div class="x-small-text">

#+begin_src julia 
ps = []
for (i, realizations) in enumerate(eachcol(Array(group(chain_discrete, :cluster))))
    p = density(
        realizations,
        legend=false,
        ticks=false,
        border=:none
    )
    vline!(p, [fake_values_mixture.cluster[i]])
    push!(ps, p)
end
plot(ps..., layout=(length(ps) √∑ 2, 2), size=(600, 40 * length(ps)))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/d49b052ee893e7410f4c67e9ca34a5e5faee8850.svg]]

#+HTML: </div>

Again, this is difficult to get to work properly on non-trivial examples

_But_ it is possible

** Other utilities for Turing.jl
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Other-utilities-for-Turing-dot-jl
:CUSTOM_ID: 2023-01-29-16-57-28-Other-utilities-for-Turing-dot-jl
:END:
- [[https://github.com/TuringLang/TuringGLM.jl][TuringGLM.jl]]: GLMs using the formula-syntax from R but using Turing.jl under the hood
- [[https://github.com/TuringLang/TuringBenchmarking.jl][TuringBenchmarking.jl]]: useful for benchmarking Turing.jl models
- [[https://github.com/TuringLang/TuringCallbacks.jl][TuringCallbacks.jl]]: on-the-fly visualizations using =tensorboard=

*** TuringGLM.jl

#+begin_src julia 
using TuringGLM
#+end_src

#+RESULTS:

#+begin_src julia :exports none
using TuringGLM, DataDeps, DataFrames, CSV, StatsPlots
#+end_src

#+RESULTS:

#+REVEAL: split

We'll use the KidIQ dataset for a quick example

#+begin_src julia
register(DataDep(
    "kidiq",
    "Survey of adult American women and their respective children from 2007",
    "https://raw.githubusercontent.com/TuringLang/TuringGLM.jl/bbc9129fc2d1ff7a1026fe2189b6580303d5c9f5/data/kidiq.csv",
))
#+end_src

#+RESULTS:
: DataDep("kidiq", "https://raw.githubusercontent.com/TuringLang/TuringGLM.jl/bbc9129fc2d1ff7a1026fe2189b6580303d5c9f5/data/kidiq.csv", nothing, DataDeps.fetch_default, identity, "Survey of adult American women and their respective children from 2007")

#+begin_src julia :display text/plain
fname = joinpath(datadep"kidiq", "kidiq.csv")
kidiq = DataFrame(CSV.File(fname))
#+end_src

#+RESULTS:
#+begin_example
434√ó4 DataFrame
 Row ‚îÇ kid_score  mom_hs  mom_iq    mom_age 
     ‚îÇ Int64      Int64   Float64   Int64   
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ        65       1  121.118        27
   2 ‚îÇ        98       1   89.3619       25
   3 ‚îÇ        85       1  115.443        27
   4 ‚îÇ        83       1   99.4496       25
   5 ‚îÇ       115       1   92.7457       27
   6 ‚îÇ        98       0  107.902        18
   7 ‚îÇ        69       1  138.893        20
   8 ‚îÇ       106       1  125.145        23
   9 ‚îÇ       102       1   81.6195       24
  10 ‚îÇ        95       1   95.0731       19
  11 ‚îÇ        91       1   88.577        23
  ‚ãÆ  ‚îÇ     ‚ãÆ        ‚ãÆ        ‚ãÆ         ‚ãÆ
 425 ‚îÇ        42       1   78.2446       27
 426 ‚îÇ       102       1  127.676        29
 427 ‚îÇ       104       1  124.515        23
 428 ‚îÇ        59       0   80.464        21
 429 ‚îÇ        93       0   74.8607       25
 430 ‚îÇ        94       0   84.8774       21
 431 ‚îÇ        76       1   92.9904       23
 432 ‚îÇ        50       0   94.8597       24
 433 ‚îÇ        88       1   96.8566       21
 434 ‚îÇ        70       1   91.2533       25
                            413 rows omitted
#+end_example

#+REVEAL: split

Now we can create the formula

#+begin_src julia :display text/plain
fm = @formula(kid_score ~ mom_hs * mom_iq)
#+end_src

#+RESULTS:
: FormulaTerm
: Response:
:   kid_score(unknown)
: Predictors:
:   mom_hs(unknown)
:   mom_iq(unknown)
:   mom_hs(unknown) & mom_iq(unknown)

which can then easily be converted into a Turing.jl-model

#+begin_src julia :display text/plain
model = turing_model(fm, kidiq);
#+end_src

#+RESULTS:

And then we can use our standard Turing.jl workflow:

#+begin_src julia :display text/plain :async yes
chns = sample(model, NUTS(), 1000)
#+end_src

#+RESULTS:
:RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mFound initial step size
: [36m[1m‚îî [22m[39m  œµ = 0.00078125
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01[39m
: 
#+begin_example
Chains MCMC chain (1000√ó17√ó1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 1.72 seconds
Compute duration  = 1.72 seconds
parameters        = Œ±, Œ≤[1], Œ≤[2], Œ≤[3], œÉ
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 [1m parameters [0m [1m    mean [0m [1m     std [0m [1m    mcse [0m [1m ess_bulk [0m [1m ess_tail [0m [1m    rhat [0m [1m e[0m ‚ãØ
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m  Float64 [0m [90m  Float64 [0m [90m Float64 [0m [90m  [0m ‚ãØ

           Œ±   31.3373    6.0901    0.3698   280.1918   384.7312    1.0005     ‚ãØ
        Œ≤[1]    0.6108    2.1583    0.2464   296.4324    83.2314    1.0025     ‚ãØ
        Œ≤[2]    0.5123    0.0682    0.0040   310.4550   330.9380    1.0010     ‚ãØ
        Œ≤[3]    0.0474    0.0316    0.0026   312.0172   134.9725    0.9998     ‚ãØ
           œÉ   18.2138    0.6364    0.0264   583.5792   564.1153    1.0013     ‚ãØ
[36m                                                                1 column omitted[0m

Quantiles
 [1m parameters [0m [1m    2.5% [0m [1m   25.0% [0m [1m   50.0% [0m [1m   75.0% [0m [1m   97.5% [0m
 [90m     Symbol [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m [90m Float64 [0m

           Œ±   19.2411   27.3696   31.5349   35.2764   43.1019
        Œ≤[1]   -1.9778   -0.4569    0.2894    1.0749    5.5943
        Œ≤[2]    0.3839    0.4694    0.5107    0.5555    0.6518
        Œ≤[3]   -0.0127    0.0294    0.0493    0.0670    0.1008
           œÉ   17.0081   17.7909   18.1895   18.6149   19.5446
#+end_example
:END:



*** TuringCallbacks.jl

#+begin_src julia 
using TuringCallbacks
#+end_src

#+RESULTS:

#+begin_src julia 
model = simple_demo(1.5, 2.0);
#+end_src

#+RESULTS:

#+begin_src julia :async yes
logdir = mktempdir()
#+end_src

#+RESULTS:
: "/tmp/jl_QMfUjM"

#+begin_src julia :async yes
callback = TensorBoardCallback(joinpath(logdir, "logs"); include_hyperparams=true)
chain = sample(model, NUTS(0.8), 1000; callback=callback);
#+end_src

#+RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mFound initial step size
: [36m[1m‚îî [22m[39m  œµ = 1.6
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01[39m
:

#+REVEAL: split

If you have =tensorboard= installed, you can then run

#+begin_src sh :eval no
python3 -m tensorboard.main --logdir /tmp/jl_QMfUjM
#+end_src

#+DOWNLOADED: file:///home/tor/Downloads/tensorboard_demo_histograms_screen.png @ 2023-01-25 20:50:11
#+ATTR_HTML: :width 800px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-25_20-50-11_tensorboard_demo_histograms_screen.png]]

#+REVEAL: split

Can inspect hyperparameters, e.g. target acceptance rate for =NUTS=

#+DOWNLOADED: file:///tmp/Spectacle.EtZoaa/Screenshot_20230919_213557.png @ 2023-09-19 21:36:15
#+attr_org: :width 600px
[[file:.more-julia/attachments/2023-09-19_21-36-15_Screenshot_20230919_213557.png]]


** Downsides of using Turing.jl
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Downsides-of-using-Turing-dot-jl
:CUSTOM_ID: 2023-01-29-16-57-28-Downsides-of-using-Turing-dot-jl
:END:

#+ATTR_REVEAL: :frag (appear)
- ${\color{red} \times}$ No depedency-extraction of the model
  - ‚üπ can't do things like automatic marginalization
  - /But/ it's not impossible; just a matter of development effort
  - ${\color{green} \checkmark}$ And we have JuliaBUGS now!
- ${\color{red} \times}$ NUTS performance is at the mercy of AD in Julia
- ${\color{green} \checkmark}$ You _can_ put anything in a model
- ${\color{red} \times}$ Whether you _should_ put anything in a model is a another matter


* Setting up a project environment

** Set up

First we need to set up our project.

#+begin_src julia
pwd()
#+end_src

#+RESULTS:
: "/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop"

This will generate a folder that looks something like

** What we're doing

1. Create project.
   - Look at the structure of the project.
2. Add dependencies.
   - Talk about Project.toml and Manifest.toml
   - Dependencies we want:
     - DrWatson.jl
       - [ ] Do we set up the project using their structure?
       - https://juliadynamics.github.io/DrWatson.jl/dev/project/#Default-Project-Setup-1
       - [ ] Oooor maybe not talk about DrWatson.jl at all.
     - Revise.jl
     - Turing.jl
     - DifferentialEquations.jl
     - StatsPlots.jl
     - DataDeps.jl
3. 

* Case study

It's time to do a case study!

But on which dataset?

*You're own!*

#+REVEAL: split

But if you don't have one, here are some alternatives:
1. Lotka-Volterra model for snowhoe hares and Canadian lynxes
   - A classic example of predator-prey dynamics
2. Cockroaches in residential buildings throughout New York
   - Become your landlord's favorite tenant by minimizing cockroach complaints in residential buildings while keeping costs low
3. Synthetic time-series model
   - A syncthetic time-series with periodic behavior
4. S(?)IR modeling of influenza
   - You already have the data; go knock yourself out!
5. Pick one from RDatasets.jl

Go to the next slides for more details

** 1. Lotka-Volterra Predator-Prey model

#+HTML: <div class="small-text">

#+HTML: <div class="side-by-side">

#+HTML: <div>
The species of interest in this case study are:
- Snowshoe hares, an hervivorous cousin of rabbits
- Canadian lynxes, a feline predator whose diet consists largely of snowshoe hares
#+HTML: </div>

#+HTML: <div>
Use Lotka-Volterra equations to model the population dynamics
\begin{equation*}
\begin{aligned}
\frac{dH}{dt} &= \alpha H - \beta H L \\
\frac{dL}{dt} &= \delta H L - \gamma L
\end{aligned}
\end{equation*}

#+HTML: </div>

#+HTML: </div>

Use Turing.jl to infer the parameters
- $\alpha$: growth rate of the prey population
- $\beta$: rate of shrinkage of the prey population
- $\delta$: rate of growth of the predator population
- $\gamma$: rate of shrinkage of the predator population

[[https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html][Source (but don't look!)]]

#+RESULTS:

#+HTML: </div>

#+REVEAL: split

#+HTML: <div class="small-text">

#+begin_src julia :exports none
using DataFrames, CSV, DataDeps
#+end_src

#+begin_src julia :display text/plain :exports code
register(DataDep(
    "hares-and-lynxes",
    "Numerical data for the number of pelts collected by the Hudson‚Äôs Bay Company in the years 1900-1920.",
    "https://raw.githubusercontent.com/stan-dev/example-models/master/knitr/lotka-volterra/hudson-bay-lynx-hare.csv",
))
#+end_src

#+RESULTS:
: DataDep("hares-and-lynxes", "https://raw.githubusercontent.com/stan-dev/example-models/master/knitr/lotka-volterra/hudson-bay-lynx-hare.csv", nothing, DataDeps.fetch_default, identity, "Numerical data for the number of pelts collected by the Hudson‚Äôs Bay Company in the years 1900-1920.")


And then we can load it

#+begin_src julia :display text/plain
df = DataFrame(
    CSV.File(
        joinpath(datadep"hares-and-lynxes", "hudson-bay-lynx-hare.csv"),
        skipto=4,
        header=3
    )
)
#+end_src

#+RESULTS:
#+begin_example
[1m21√ó3 DataFrame[0m
[1m Row [0m‚îÇ[1m Year  [0m[1m  Lynx   [0m[1m  Hare   [0m
     ‚îÇ[90m Int64 [0m[90m Float64 [0m[90m Float64 [0m
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ  1900      4.0     30.0
   2 ‚îÇ  1901      6.1     47.2
   3 ‚îÇ  1902      9.8     70.2
   4 ‚îÇ  1903     35.2     77.4
   5 ‚îÇ  1904     59.4     36.3
   6 ‚îÇ  1905     41.7     20.6
   7 ‚îÇ  1906     19.0     18.1
   8 ‚îÇ  1907     13.0     21.4
   9 ‚îÇ  1908      8.3     22.0
  10 ‚îÇ  1909      9.1     25.4
  11 ‚îÇ  1910      7.4     27.1
  12 ‚îÇ  1911      8.0     40.3
  13 ‚îÇ  1912     12.3     57.0
  14 ‚îÇ  1913     19.5     76.6
  15 ‚îÇ  1914     45.7     52.3
  16 ‚îÇ  1915     51.1     19.5
  17 ‚îÇ  1916     29.7     11.2
  18 ‚îÇ  1917     15.8      7.6
  19 ‚îÇ  1918      9.7     14.6
  20 ‚îÇ  1919     10.1     16.2
  21 ‚îÇ  1920      8.6     24.7
#+end_example

#+HTML: </div>

** 2. Cockroaches in New York

#+HTML: <div class="x-small-text">

#+begin_quote
Imagine that you are a statistician or data scientist working as an independent contractor. One of your clients is a company that owns many residential buildings throughout New York City. The property manager explains that they are concerned about the number of cockroach complaints that they receive from their buildings. Previously the company has offered monthly visits from a pest inspector as a solution to this problem. While this is the default solution of many property managers in NYC, the tenants are rarely home when the inspector visits, and so the manager reasons that this is a relatively expensive solution that is currently not very effective.

One alternative to this problem is to deploy long term bait stations. In this alternative, child and pet safe bait stations are installed throughout the apartment building. Cockroaches obtain quick acting poison from these stations and distribute it throughout the colony. The manufacturer of these bait stations provides some indication of the space-to-bait efficacy, but the manager suspects that this guidance was not calculated with NYC roaches in mind. NYC roaches, the manager rationalizes, have more hustle than traditional roaches; and NYC buildings are built differently than other common residential buildings in the US. This is particularly important as the unit cost for each bait station per year is quite high.
#+end_quote

[[https://github.com/jgabry/stancon2018helsinki_intro][Source #1]] and [[https://github.com/jgabry/stancon2018helsinki_intro][Source #2]]  _(but don't look!)_

#+HTML: </div>

#+REVEAL: split

#+HTML: <div class="x-small-text">

The manager wishes to employ your services to help them to find the optimal number of roach bait stations they should place in each of their buildings in order to minimize the number of cockroach complaints while also keeping expenditure on pest control affordable.

A subset of the company's buildings have been randomly selected for an experiment:
- At the beginning of each month, a pest inspector randomly places a number of bait stations throughout the building, without knowledge of the current cockroach levels in the building
- At the end of the month, the manager records the total number of cockroach complaints in that building.
- The manager would like to determine the optimal number of traps (=traps=) that balances the lost revenue (=R=) such that complaints (=complaints=) generate with the all-in cost of maintaining the traps (=TC=).

Formally, we are interested in finding
\begin{equation*}
\arg \max_{\mathrm{traps} \in \mathbb{N}} \mathbb{E}_{\mathrm{complaints}} \big[ R \big( \mathrm{complaints}(\mathrm{traps}) \big) - \mathrm{TC}(\mathrm{traps}) \big]
\end{equation*}

The property manager would also, if possible, like to learn how these results generalize to buildings they haven't treated so they can understand the potential costs of pest control at buildings they are acquiring as well as for the rest of their building portfolio.

As the property manager has complete control over the number of traps set, the random variable contributing to this expectation is the number of complaints given the number of traps. We will model the number of complaints as a function of the number of traps.

#+HTML: </div>

#+REVEAL: split

#+begin_src julia :display text/plain
DataFrame(CSV.File(joinpath("data", "pest_data.csv")))
#+end_src

#+RESULTS:
#+begin_example
[1m120√ó14 DataFrame[0m
[1m Row [0m‚îÇ[1m mus       [0m[1m building_id [0m[1m wk_ind [0m[1m date       [0m[1m traps   [0m[1m floors  [0m[1m sq_footag[0m ‚ãØ
     ‚îÇ[90m Float64   [0m[90m Int64       [0m[90m Int64  [0m[90m Date       [0m[90m Float64 [0m[90m Float64 [0m[90m Float64  [0m ‚ãØ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ 0.369134            37       1  2017-01-15      8.0      8.0            ‚ãØ
   2 ‚îÇ 0.359355            37       2  2017-02-14      8.0      8.0
   3 ‚îÇ 0.281783            37       3  2017-03-16      9.0      8.0
   4 ‚îÇ 0.129254            37       4  2017-04-15     10.0      8.0
   5 ‚îÇ 0.452041            37       5  2017-05-15     11.0      8.0            ‚ãØ
   6 ‚îÇ 0.44213             37       6  2017-06-14     11.0      8.0
   7 ‚îÇ 0.990865            37       7  2017-07-14     10.0      8.0
   8 ‚îÇ 0.785977            37       8  2017-08-13     10.0      8.0
   9 ‚îÇ 0.691797            37       9  2017-09-12      9.0      8.0            ‚ãØ
  10 ‚îÇ 0.480696            37      10  2017-10-12      9.0      8.0
  11 ‚îÇ 0.562431            37      11  2017-11-11      8.0      8.0
  ‚ãÆ  ‚îÇ     ‚ãÆ           ‚ãÆ         ‚ãÆ         ‚ãÆ          ‚ãÆ        ‚ãÆ             ‚ãÆ ‚ã±
 111 ‚îÇ 0.542095            98       3  2017-03-16      7.0     13.0
 112 ‚îÇ 0.866334            98       4  2017-04-15      6.0     13.0            ‚ãØ
 113 ‚îÇ 1.40571             98       5  2017-05-15      6.0     13.0
 114 ‚îÇ 1.65598             98       6  2017-06-14      5.0     13.0
 115 ‚îÇ 2.2483              98       7  2017-07-14      4.0     13.0
 116 ‚îÇ 2.30359             98       8  2017-08-13      3.0     13.0            ‚ãØ
 117 ‚îÇ 2.253               98       9  2017-09-12      2.0     13.0
 118 ‚îÇ 2.0419              98      10  2017-10-12      2.0     13.0
 119 ‚îÇ 1.90705             98      11  2017-11-11      2.0     13.0
 120 ‚îÇ 2.10317             98      12  2017-12-11      1.0     13.0            ‚ãØ
[36m                                                   8 columns and 99 rows omitted[0m
#+end_example

** 3. Synthetic time-series
:PROPERTIES:
:header-args:julia: :session timeseries :kernel julia-4-threads-1.9 :async yes :tangle no :exports none
:END:

Or you can have a go at this synthetic time-series example

#+HTML: <div class="side-by-side small-text">

#+HTML: <div>

#+begin_src julia :exports both :display text/plain
DataFrame(CSV.File(
    joinpath("data", "time-series.csv")
))
#+end_src

#+RESULTS:
#+begin_example
[1m67√ó2 DataFrame[0m
[1m Row [0m‚îÇ[1m t         [0m[1m y         [0m
     ‚îÇ[90m Float64   [0m[90m Float64   [0m
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ 0.0        -19.3009
   2 ‚îÇ 0.0151515  -18.2195
   3 ‚îÇ 0.030303   -17.931
   4 ‚îÇ 0.0454545  -18.5562
   5 ‚îÇ 0.0606061  -19.2006
   6 ‚îÇ 0.0757576  -18.7376
   7 ‚îÇ 0.0909091  -16.4586
   8 ‚îÇ 0.106061   -15.0723
   9 ‚îÇ 0.121212   -12.6583
  10 ‚îÇ 0.136364   -11.1347
  11 ‚îÇ 0.151515   -10.9626
  ‚ãÆ  ‚îÇ     ‚ãÆ          ‚ãÆ
  58 ‚îÇ 0.863636    -6.70737
  59 ‚îÇ 0.878788    -6.59501
  60 ‚îÇ 0.893939    -7.91087
  61 ‚îÇ 0.909091    -8.78053
  62 ‚îÇ 0.924242    -9.81755
  63 ‚îÇ 0.939394    -9.06206
  64 ‚îÇ 0.954545    -7.48517
  65 ‚îÇ 0.969697    -4.72118
  66 ‚îÇ 0.984848    -1.85908
  67 ‚îÇ 1.0          0.0
[36m             46 rows omitted[0m
#+end_example

#+HTML: </div>

#+HTML: <div class="center">

[[./assets/attachments/synthetic-timeseries-data.png]]

#+HTML: </div>

#+HTML: </div>

*** Data generation                                                :noexport:

#+begin_src julia 
]activate --temp
#+end_src

#+RESULTS:
: [32m[1m  Activating[22m[39m new project at `/tmp/jl_SaDhi8`

#+begin_src julia :results silent
]add Turing FillArrays LinearAlgebra StatsPlots Random Statistics DataFrames CSV
#+end_src

#+begin_src julia
using Turing, FillArrays, StatsPlots, LinearAlgebra, Random, Statistics, DataFrames, CSV
#+end_src

#+begin_src julia
Random.seed!(12345)

true_sin_freq = 2
true_sin_amp = 5
true_cos_freq = 7
true_cos_amp = 2.5
tmax = 10
Œ≤_true = 2
Œ±_true = -1
tt = 0:0.05:tmax
f‚ÇÅ(t) = Œ±_true + Œ≤_true * t
f‚ÇÇ(t) = true_sin_amp * sinpi(2 * t * true_sin_freq / tmax)
f‚ÇÉ(t) = true_cos_amp * cospi(2 * t * true_cos_freq / tmax)
f(t) = f‚ÇÅ(t) + f‚ÇÇ(t) + f‚ÇÉ(t)

plot(f, tt; label="f(t)", title="Observed time series", legend=:topleft, linewidth=3)
plot!(
    [f‚ÇÅ, f‚ÇÇ, f‚ÇÉ],
    tt;
    label=["f‚ÇÅ(t)" "f‚ÇÇ(t)" "f‚ÇÉ(t)"],
    style=[:dot :dash :dashdot],
    linewidth=1,
)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0b26b4ffdbb5a6d6692d6439bbcca36ca293e4a5.svg]]


#+begin_src julia :exports output
œÉ_true = 0.35
t = collect(tt[begin:3:end])
t_min, t_max = extrema(t)
x = (t .- t_min) ./ (t_max - t_min)
yf = f.(t) .+ œÉ_true .* randn(size(t))

p = scatter(x, yf; title="Standardised data", legend=false)
savefig("assets/attachments/synthetic-timeseries-data.png")
p
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/901b0ff0c5838163d8c7b76abe4158c02d07125b.svg]]

#+begin_src julia :display text/plain :eval no
CSV.write(joinpath("data", "time-series.csv"), DataFrame(t = x, y = yf))
#+end_src

#+RESULTS:
: "data/time-series.csv"

** 4. Influenza at British boarding school (same as before)
An outbreak of influenza A (H1N1) in 1978 at a British boarding school

- 763 male students -> 512 of which became ill
- Reported that one infected boy started the epidemic
- Observations are number of boys in bed over 14 days

Data are freely available in the R package =outbreaks=, maintained as part of the [[http://www.repidemicsconsortium.org/][R Epidemics Consortium]]

#+REVEAL: split

#+begin_src julia :display text/plain
DataFrame(CSV.File(joinpath("data", "influenza_england_1978_school.csv")))
#+end_src

#+RESULTS:
#+begin_example
[1m14√ó4 DataFrame[0m
[1m Row [0m‚îÇ[1m Column1 [0m[1m date       [0m[1m in_bed [0m[1m convalescent [0m
     ‚îÇ[90m Int64   [0m[90m Date       [0m[90m Int64  [0m[90m Int64        [0m
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1 ‚îÇ       1  1978-01-22       3             0
   2 ‚îÇ       2  1978-01-23       8             0
   3 ‚îÇ       3  1978-01-24      26             0
   4 ‚îÇ       4  1978-01-25      76             0
   5 ‚îÇ       5  1978-01-26     225             9
   6 ‚îÇ       6  1978-01-27     298            17
   7 ‚îÇ       7  1978-01-28     258           105
   8 ‚îÇ       8  1978-01-29     233           162
   9 ‚îÇ       9  1978-01-30     189           176
  10 ‚îÇ      10  1978-01-31     128           166
  11 ‚îÇ      11  1978-02-01      68           150
  12 ‚îÇ      12  1978-02-02      29            85
  13 ‚îÇ      13  1978-02-03      14            47
  14 ‚îÇ      14  1978-02-04       4            20
#+end_example

** 5. Anything from =RDatasets.jl=

Or you can just do =]add RDatasets= and knock yourself out

https://github.com/JuliaStats/RDatasets.jl

** TODO EpimapMini                                                 :noexport:

** Covid19: ImperialReport13                                       :noexport:

* [cite:@kxs052]                                                   :noexport:
:PROPERTIES:
:header-args:julia: :session mrc-biostats-2023-particle-filter :tangle particle-filter.jl :exports both :kernel julia-4-threads-1.9 :async yes :file (f-join "assets" "outputs" "more-julia" (sha1 (plist-get (cadr (org-element-at-point)) :value)))
:END:

#+begin_src julia
using DifferentialEquations, Turing, StatsPlots, LinearAlgebra
#+end_src

#+RESULTS:

#+begin_src julia 
struct SEIR{T1,T2}
    k::T1
    Œ≥::T2
    N::Int
end

function (seir::SEIR)(du, u, p, t)
    S, E, I, R = u
    k, Œ≥, N = seir.k, seir.Œ≥, seir.N
    Œ≤ = only(p)

    du[1] = -Œ≤ * S * I / N
    du[2] = Œ≤ * S * I / N - k * E
    du[3] = k * E - Œ≥ * I
    du[4] = Œ≥ * I

    return nothing
end
#+end_src

#+RESULTS:

#+begin_src julia
tspan = (0.0, 100.0)
u0 = [999.0, 1, 0, 0]
probf = SEIR(0.25, 0.05, 1000)
prob = ODEProblem(probf, u0, tspan, [0.2])
solve(prob)
#+end_src

#+RESULTS:
#+begin_example
retcode: Success
Interpolation: specialized 4th order "free" interpolation, specialized 2nd order "free" stiffness-aware interpolation
t: 28-element Vector{Float64}:
   0.0
   0.0056540236999814706
   0.062194260699796174
   0.30072981111184066
   0.6950381565675945
   1.2203000465133529
   1.9420478964976093
   2.875425767640001
   4.059411303485391
   5.5012350028501915
   7.231365280264414
   9.310611835029093
  11.822720603708422
   ‚ãÆ
  29.994131638154776
  36.38399041740069
  43.15031946908468
  49.925654813444986
  56.64173164949659
  63.21608779006091
  69.68044151998856
  76.04965890277947
  82.24922997649685
  88.32704521258971
  94.43532129748762
 100.0
u: 28-element Vector{Vector{Float64}}:
 [999.0, 1.0, 0.0, 0.0]
 [998.9999992020507, 0.9985882901773383, 0.0014123080849147874, 1.9968700047033795e-7]
 [998.999903990443, 0.9846672028102782, 0.015404780329859823, 2.402641680625783e-5]
 [998.9978071088109, 0.9297127930516831, 0.0719313259662255, 0.0005487721711357369]
 [998.988715035506, 0.8511476794063842, 0.15731320394797277, 0.002824081139604212]
 [998.9668112144358, 0.767041034463036, 0.25784211124172, 0.008305639859413096]
 [998.9208316832985, 0.6827118072407354, 0.3766438333267149, 0.01981267613405121]
 [998.8381486559025, 0.6147899451473634, 0.5065547781759926, 0.04050662077415447]
 [998.7012919960837, 0.5764444949375392, 0.6475005783296947, 0.07476293064911178]
 [998.4923402920977, 0.5785427877223749, 0.8020426609011208, 0.12707425927887211]
 [998.1839760718743, 0.6275609878677972, 0.9841692988996603, 0.20429364135823094]
 [997.7273588313809, 0.7325590501006006, 1.2214003176662998, 0.318681800852206]
 [997.0331285904066, 0.9130060315711355, 1.5611701374154396, 0.49269524060683106]
 ‚ãÆ
 [982.0702623929466, 4.978328695298856, 8.678429708473596, 4.272979203280957]
 [967.3040268930682, 8.929117975760578, 15.706379061376614, 8.060476069794523]
 [939.2612602725887, 16.244165918604498, 29.079324826448026, 15.415248982358625]
 [889.935318260028, 28.490110433785002, 52.673150775667786, 28.90142053051913]
 [809.536141204184, 46.627383515369715, 91.26328180674686, 52.57319347369934]
 [693.548729931949, 68.30245900142862, 146.9156269837328, 91.23318408288952]
 [549.4058252982588, 86.32392859844263, 214.79100213149258, 149.47924397180583]
 [400.5060115349084, 91.46932009526371, 279.51869582345205, 228.50597254637566]
 [275.14644582873996, 81.21206493893693, 321.279498493012, 322.36199073931095]
 [184.50529783539324, 62.256830342268195, 330.969490819117, 422.2683810032214]
 [124.27616729855168, 42.68631251399805, 311.97675224228794, 521.0607679451622]
 [89.37978460338655, 28.53709293175161, 278.6199759741896, 603.4631464906721]
#+end_example

#+begin_src julia
using Random: Random

struct EulerMaruyama{F, G}
    Œº::F
    œÉ::G
end

EulerMaruyama() = EulerMaruyama((Œ∏, x) -> 0, (Œ∏, x) -> 1)

(em::EulerMaruyama)(Œ∏, x, Œ¥, m=1) = em(Random.default_rng(), Œ∏, x, Œ¥, m)
function (em::EulerMaruyama)(rng::Random.AbstractRNG, Œ∏, x, Œ¥, m=1)
    # TODO: Do we need to adjust the size in our `randn` call?
    for _ = 1:m
        Œº = em.Œº(Œ∏, x)
        œÉ = em.œÉ(Œ∏, x)
        x = @. x + Œ¥ * Œº + sqrt(Œ¥) * œÉ * randn(rng)
    end

    return x
end
#+end_src

#+RESULTS:

#+begin_src julia
# Simple OU process.
ou = EulerMaruyama((Œ∏, x) -> -Œ∏[1] * x, (Œ∏, x) -> Œ∏[2])

Œ∏ = 1.0; œÉ = sqrt(2); Œ¥ = 0.05;
t = 12
xs = let
    x = 10.0
    xs = [x]
    for _ = 1:ceil(Int, t / Œ¥)
        x = ou([Œ∏, œÉ], x, Œ¥)
        push!(xs, x)
    end
    xs
end

plot(0:Œ¥:(length(xs) - 1) * Œ¥, xs, legend=false)
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/7c3945985ca929a14b309bb0a74f6a7a934b07c7.svg]]


#+begin_src julia 
# Algorithm 1: Particle Filter Algorithm
"""
    particle_filter(y, x‚ÇÄ, ode; n, N)

# Arguments
- `y`: observations
- `x‚ÇÄ`: initial states
- `ode`: ODE model

# Keyword Arguments
- `n`: number of observations (default: length(y))
- `N`: number of particles (default: length(x‚ÇÄ))
- `M`: number of discretization steps between each observation time (default: 1)
"""
function particle_filter(
    x‚ÇÄ, V‚ÇÄ, y, Œ∏, ts, prob, f, em;
    n = length(y),
    N = 10,
    m = 1,
    hinv=exp
)
    # TODO: Change it all to work on log-scale as much as possible.
    # Buffer for the particles.
    V = Matrix{typeof(V‚ÇÄ)}(undef, N, n)
    # Initialize the particles.
    for j = 1:N
        V[j, 1] = V‚ÇÄ
    end
    # Buffer for the states.
    x = Matrix{typeof(x‚ÇÄ)}(undef, N, n)
    for j = 1:N
        # Initialize the states.
        x[j, 1] = x‚ÇÄ
    end

    # Other buffers.
    Œ± = zeros(N, n)
    W = zeros(N, n)
    L = one(eltype(x‚ÇÄ))

    # Step-size for SDE solve.
    Œ¥ = 1 / m
    for i = 1:n - 1
        # Remake the problem to the next observation time.
        prob_t = remake(prob, tspan=(ts[i], ts[i + 1]))
        # For each particle.
        for j = 1:N
            # Sample x[i + 1] given x[i].
            x_j = em(Œ∏, x[j, i], Œ¥, m)
            x[j, i + 1] = x_j

            # Solve ODE between the two observation times.
            Œ≤ = hinv(x_j)
            prob_t_j = remake(prob_t, p=[Œ≤,])
            # TODO: Disable storing of the intermediate steps.
            # TODO: Check at that we have the correct `saveat`.
            V_t = solve(prob_t_j)
            V[j, i + 1] = V_t[end]

            # Compute the likelihood of the observation at time i + 1.
            # TODO: Should this be a Turing.jl model?
            Œ±[j, i + 1] = f(y[i + 1], V[j, 1:i + 1])
        end

        W[:, i + 1] = normalize(Œ±[:, i + 1], 1); L = L * mean(Œ±);
        # TODO: Resample
        # resample(V[1:i + 1, :], x[1:i + 1, :])
    end

    return (; V, W, x, L)
end
#+end_src

#+RESULTS:
: particle_filter

#+begin_src julia
f(y, V) = pdf(Normal(V[end][3], 1), y)
hinv = exp
N = 10

m = 4
Œ¥ = 1 / m

tspan = (0, 5)
Œît = 0.1
ts = tspan[1]:Œît:tspan[2]
n = length(ts)

Œ∏ = [0.1, 1.0]
x‚ÇÄ = rand(Normal())

xs_true = Float64[x‚ÇÄ]
for i = 1:n
    # We take `m` steps of size `Œ¥` to approximate a step of size `Œît`.
    x = ou(Œ∏, xs_true[i], Œ¥, m)
    for _ = 1:m - 1
        x = ou(Œ∏, xs_true[i], Œ¥, m)
    end
    push!(xs_true, x)
end
xs_true
#+end_src

#+RESULTS:
#+begin_example
52-element Vector{Float64}:
 -0.24878183911750845
 -0.6612017363745032
 -0.5771129755661678
 -1.3998600910341077
 -3.451824275216758
 -1.9984112308388422
 -1.9924864608629838
 -3.5250896691556277
 -2.9739944443243034
 -2.9800035362896766
 -4.17320936285544
 -3.3632341699940276
 -1.6339647999108249
  ‚ãÆ
 -0.12313561294713371
  1.5450391910822283
  0.5587443891018262
  1.7891589771333165
  1.872952639316824
  1.5540947466863484
 -0.2167465035797701
 -1.526033137464444
 -2.3638187290855757
 -1.2625822265622242
 -0.7982249206748514
 -1.2116103413002468
#+end_example

#+begin_src julia
Œ≤s = hinv.(xs_true)
#+end_src

#+RESULTS:
#+begin_example
52-element Vector{Float64}:
 0.7797500657927471
 0.5162305885040517
 0.5615171424285115
 0.24663146748144474
 0.031687776392698305
 0.1355504706573401
 0.13635595982888485
 0.029449166568809727
 0.051098790857907486
 0.050792654247042046
 0.015402747708387066
 0.03462310067973559
 0.19515429050669508
 ‚ãÆ
 0.8841437530903199
 4.688155357303803
 1.7484757162671933
 5.984417317534419
 6.507482308931339
 4.730802011969568
 0.8051340420355165
 0.21739634049976952
 0.09406034551872539
 0.28292251241208627
 0.4501272669874618
 0.2977174664702004client_loop: send disconnect: Broken pipe
#+end_example

#+begin_src julia
V‚ÇÄ = [999.0, 1, 0, 0]
probf = SEIR(0.25, 0.05, 1000)
prob = ODEProblem(probf, V‚ÇÄ, tspan, [0.2])
#+end_src

#+RESULTS:
: [38;2;86;182;194mODEProblem[0m with uType [38;2;86;182;194mVector{Float64}[0m and tType [38;2;86;182;194mInt64[0m. In-place: [38;2;86;182;194mtrue[0m
: timespan: (0, 5)
: u0: 4-element Vector{Float64}:
:  999.0
:    1.0
:    0.0
:    0.0

#+begin_src julia
let i = 1, prob = prob
    Œ≤ = Œ≤s[i]
    prob = remake(prob, p=[Œ≤,], tspan=(ts[i], ts[i + 1]))
    V_t = solve(prob)[end]
end
#+end_src

#+RESULTS:
: 4-element Vector{Float64}:
:  998.999035805983
:    0.976266101698541
:    0.024636203279721925
:    6.188903883306985e-5

#+begin_src julia
V_true = zeros(length(V‚ÇÄ), n)
V_true[:, 1] = V‚ÇÄ
for i = 1:n - 1
    Œ≤ = Œ≤s[i]
    prob = remake(prob, u0=V_true[:, i], p=[Œ≤,], tspan=(ts[i], ts[i + 1]))
    V_t = solve(prob)
    V_true[:, i + 1] = V_t[end]
end
#+end_src

#+RESULTS:

#+begin_src julia
infected_true = V_true[3, :]
plot(ts, infected_true, label="true", size=(400, 200))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/47fd6cb8c10828598540fa1f4c0111622d264e6d.svg]]


#+begin_src julia
V_true
#+end_src

#+RESULTS:
: 4√ó51 Matrix{Float64}:
:  999.0  998.999      998.997        ‚Ä¶  982.474     982.437    982.317
:    1.0    0.976266     0.954032         13.4865     13.19      12.9825
:    0.0    0.0246362    0.0485779         3.83996     4.1534     4.459
:    0.0    6.1889e-5    0.000245206       0.199733    0.21972    0.241254

#+begin_src julia
ys = map(eachcol(V_true)) do V
    V[3] + rand(Normal())
end
#+end_src

#+RESULTS:
#+begin_example
51-element Vector{Float64}:
 -0.5576703894082115
  0.31494731473497434
 -0.782010760585272
 -1.1253763909484469
  0.3928993294327789
 -0.8227802480874041
  2.842180090129152
  1.609855724089655
  0.1217016398280302
 -0.31360887101271573
 -0.7839811314785547
  1.042050553773855
  0.09414142122994448
  ‚ãÆ
  0.05421057426064957
  1.8792572903396607
  1.0816613933578965
  2.417860738671401
  1.796002164551382
  3.444541128186396
  1.8289648762543378
  3.4364109210785503
  3.904061960770232
  2.225333928943403
  3.4349557674958855
  5.037173311656346
#+end_example

#+begin_src julia
x‚ÇÄ
#+end_src

#+RESULTS:
: -0.24878183911750845

#+begin_src julia
res = particle_filter(x‚ÇÄ, V‚ÇÄ, ys, Œ∏, ts, prob, f, ou)
#+end_src

#+RESULTS:
: '(V = ((999.0  1.0  0.0  0.0) (981.6549825068294  13.636653304174525  4.467096587319281  0.24126760167636907) ‚Ä¶ (981.4516426950192  13.837503257224819  4.4695823185470775  0.24127172920838716) (979.0817567031715  16.1783921724427  4.498531338416847  0.24131978596839576); (999.0  1.0  0.0  0.0) (982.2631520721105  13.035932437032557  4.4596602382065775  0.241255252649868) ‚Ä¶ (982.2861196382858  13.01324622364836  4.459379351894491  0.24125478617088797) (982.0891142368577  13.207838431565234  4.461788544437223  0.24125878713941296); ‚Ä¶ ; (999.0  1.0  0.0  0.0) (981.7439049217614  13.548819821185612  4.4660094605939955  0.2412657964583884) ‚Ä¶ (663.334004658758  328.2287237478621  8.18992670303448  0.2473448903449323) (825.1828219702596  168.25388439497434  6.318987396914114  0.24430623785147454); (999.0  1.0  0.0  0.0) (982.2879321980549  13.01145586790656  4.459357184681115  0.24125474935682695) ‚Ä¶ (982.0983594909576  13.198706419818599  4.461675489831078  0.24125859939224795) (982.3116508758052  12.988027748370422  4.4590671082110065  0.24125426761286162))  W = (0.0 0.09988757372155688 ‚Ä¶ 0.11260922674838236 0.10429844379909534; 0.0 0.10301704630685216 ‚Ä¶ 0.11379833207901854 0.102185543421086; ‚Ä¶ ; 0.0 0.1003394173483243 ‚Ä¶ 2.367964404902901e-6 0.053026954224620594; 0.0 0.10314651947720654 ‚Ä¶ 0.11353066890134646 0.10202528124349138)  x = (-0.24878183911750845 0.6138855191582259 ‚Ä¶ 0.8449512024687492 2.0692792441000702; -0.24878183911750845 -0.8899954378772685 ‚Ä¶ -1.0317669857230851 -0.19608925850572068; ‚Ä¶ ; -0.24878183911750845 0.4931976536046899 ‚Ä¶ 6.566510698925604 5.871380391390189; -0.24878183911750845 -1.043860246823622 ‚Ä¶ -0.22302817403959607 -1.2172756503512303)  L = 1.013581747539015e-136)

#+begin_src julia
res.V[:, end]
#+end_src

#+RESULTS:
#+begin_example
10-element Vector{Vector{Float64}}:
 [979.0817567031715, 16.1783921724427, 4.498531338416847, 0.24131978596839576]
 [982.0891142368577, 13.207838431565234, 4.461788544437223, 0.24125878713941296]
 [979.8625656172379, 15.407132551714664, 4.488997868500401, 0.24130396254650277]
 [980.436410636633, 14.840308410290579, 4.481988625921814, 0.2412923271540778]
 [982.0356905978668, 13.26060771242806, 4.462441817696447, 0.24125987200809731]
 [982.1798037070085, 13.118259816220359, 4.460679531359107, 0.24125694541145867]
 [967.9235445503858, 27.20059731799279, 4.634313247988205, 0.24154488363263862]
 [958.0934636878087, 36.91153279602659, 4.75326183935249, 0.2417416768116818]
 [825.1828219702596, 168.25388439497434, 6.318987396914114, 0.24430623785147454]
 [982.3116508758052, 12.988027748370422, 4.4590671082110065, 0.24125426761286162]
#+end_example

#+begin_src julia 
res.V
#+end_src

#+RESULTS:
#+begin_example
10√ó51 Matrix{Vector{Float64}}:
 [999.0, 1.0, 0.0, 0.0]  ‚Ä¶  [979.082, 16.1784, 4.49853, 0.24132]
 [999.0, 1.0, 0.0, 0.0]     [982.089, 13.2078, 4.46179, 0.241259]
 [999.0, 1.0, 0.0, 0.0]     [979.863, 15.4071, 4.489, 0.241304]
 [999.0, 1.0, 0.0, 0.0]     [980.436, 14.8403, 4.48199, 0.241292]
 [999.0, 1.0, 0.0, 0.0]     [982.036, 13.2606, 4.46244, 0.24126]
 [999.0, 1.0, 0.0, 0.0]  ‚Ä¶  [982.18, 13.1183, 4.46068, 0.241257]
 [999.0, 1.0, 0.0, 0.0]     [967.924, 27.2006, 4.63431, 0.241545]
 [999.0, 1.0, 0.0, 0.0]     [958.093, 36.9115, 4.75326, 0.241742]
 [999.0, 1.0, 0.0, 0.0]     [825.183, 168.254, 6.31899, 0.244306]
 [999.0, 1.0, 0.0, 0.0]     [982.312, 12.988, 4.45907, 0.241254]
#+end_example

#+begin_src julia 
map(Base.Fix2(getindex, 3), res.V[1, :])
#+end_src

#+RESULTS:
#+begin_example
51-element Vector{Float64}:
 0.0
 4.467096587319281
 4.463862526615373
 4.459656853523802
 4.466795106880251
 4.465373456614291
 4.4709067521561074
 4.483831870092793
 4.48709930090452
 4.488202856233156
 4.475931845249381
 4.49828765348811
 4.471014395310173
 ‚ãÆ
 4.457669068409179
 4.457627261638725
 4.457618617597363
 4.4576794290840995
 4.458148242977677
 4.457862024612464
 4.458002377816298
 4.458960451540986
 4.462557706195554
 4.474477160405936
 4.4695823185470775
 4.498531338416847WARNING: redefinition of constant PATH. This may fail, cause incorrect answers, or produce other errors.
WARNING: redefinition of constant LIBPATH. This may fail, cause incorrect answers, or produce other errors.
WARNING: redefinition of constant PATH_list. This may fail, cause incorrect answers, or produce other errors.
WARNING: redefinition of constant LIBPATH_list. This may fail, cause incorrect answers, or produce other errors.
[91m[1m‚îå [22m[39m[91m[1mError: [22m[39mError watching manifest
[91m[1m‚îÇ [22m[39m  exception =
[91m[1m‚îÇ [22m[39m   cannot set type for global best_wrapper. It already has a value or is already set to a different type.
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m    [1] top-level scope
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90m~/.julia/packages/JLLWrappers/pG9bm/src/[39m[90m[4mtoplevel_generators.jl:119[24m[39m
[91m[1m‚îÇ [22m[39m   Revise evaluation error at /home/tor/.julia/packages/JLLWrappers/pG9bm/src/toplevel_generators.jl:119
[91m[1m‚îÇ [22m[39m   
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m    [1] [0m[1mmethods_by_execution![22m[0m[1m([22m[90mrecurse[39m::[0mAny, [90mmethodinfo[39m::[0mRevise.CodeTrackingMethodInfo, [90mdocexprs[39m::[0mDict[90m{Module, Vector{Expr}}[39m, [90mmod[39m::[0mModule, [90mex[39m::[0mExpr; [90mmode[39m::[0mSymbol, [90mdisablebp[39m::[0mBool, [90malways_rethrow[39m::[0mBool, [90mkwargs[39m::[0mBase.Pairs[90m{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}[39m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [35mRevise[39m [90m~/.julia/packages/Revise/7HQ7u/src/[39m[90m[4mlowered.jl:227[24m[39m
[91m[1m‚îî [22m[39m[90m@ Revise ~/.julia/packages/Revise/7HQ7u/src/pkgs.jl:477[39m[91m[1m‚îå [22m[39m[91m[1mError: [22m[39mError watching manifest
[91m[1m‚îÇ [22m[39m  exception =
[91m[1m‚îÇ [22m[39m   [91mTOML Parser error:[39m
[91m[1m‚îÇ [22m[39m   [0m[1m/drive-2/Projects/public/Turing-Workshop/2023-MRC-BSU-and-UKHSA/TorsWorkshop/Manifest.toml:854:77[22m[91m error: [39mstring literal ended unexpectedly
[91m[1m‚îÇ [22m[39m     deps = ["AbstractTrees", "Colors", "FileIO", "FixedPointNumbers", "IndirectA
[91m[1m‚îÇ [22m[39m                                                                                [92m^[39m 
[91m[1m‚îÇ [22m[39m   Stacktrace:
[91m[1m‚îÇ [22m[39m    [1] [0m[1mparse[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90m./[39m[90m[4mtoml_parser.jl:445[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [2] [0m[1mget_updated_dict[22m[0m[1m([22m[90mp[39m::[0mBase.TOML.Parser, [90mf[39m::[0mBase.CachedTOMLDict[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:247[24m[39m
[91m[1m‚îÇ [22m[39m    [3] [0m[1m(::Base.var"#938#939"{String, Base.TOMLCache})[22m[0m[1m([22m[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90mBase[39m [90m./[39m[90m[4mloading.jl:288[24m[39m
[91m[1m‚îÇ [22m[39m    [4] [0m[1mlock[22m[0m[1m([22m[90mf[39m::[0mBase.var"#938#939"[90m{String, Base.TOMLCache}[39m, [90ml[39m::[0mReentrantLock[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90mBase[39m [90m./[39m[90m[4mlock.jl:229[24m[39m
[91m[1m‚îÇ [22m[39m    [5] [0m[1mparsed_toml[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90m./[39m[90m[4mloading.jl:275[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [6] [0m[1mparsed_toml[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [90m./[39m[90m[4mloading.jl:273[24m[39m[90m [inlined][39m
[91m[1m‚îÇ [22m[39m    [7] [0m[1mmanifest_paths![22m[0m[1m([22m[90mpkgpaths[39m::[0mDict[90m{Base.PkgId, String}[39m, [90mmanifest_file[39m::[0mString[0m[1m)[22m
[91m[1m‚îÇ [22m[39m   [90m   @[39m [35mRevise[39m [90m~/.julia/packages/Revise/7HQ7u/src/[39m[90m[4mpkgs.jl:390[24m[39m
[91m[1m‚îî [22m[39m[90m@ Revise ~/.julia/packages/Revise/7HQ7u/src/pkgs.jl:477[39m
#+end_example

#+begin_src julia
state_idx = 3

p = plot(size=(400, 200))
for particle_idx = 1:N
    scatter!(
        p,
        ts,
        map(Base.Fix2(getindex, state_idx), res.V[particle_idx, :]),
        label="",
        markerstrokewidth=0.1,
        markersize=2,
    )
end
p
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/f87dcb0a320c0a8b9559fd1d70d587bb40de4cdc.svg]]

* Julia: The Good, the Bad, and the Ugly
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Julia-The-Good-the-Bad-and-the-Ugly
:CUSTOM_ID: 2023-01-29-16-57-28-Julia-The-Good-the-Bad-and-the-Ugly
:END:

An honest take from a little 27-year old Norwegian boy

*** The Good
:PROPERTIES:
:ID:       2023-01-29-16-57-28-The-Good
:CUSTOM_ID: 2023-01-29-16-57-28-The-Good
:END:
- Speed
- Composability (thank you multiple dispatch)
- No need to tie yourself to an underlying computational framework
- Interactive
- Transparency
- Very easy to call into other languages

*** Speed
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Speed
:CUSTOM_ID: 2023-01-29-16-57-28-Speed
:END:

I think you got this already...

*** Composability
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Composability
:CUSTOM_ID: 2023-01-29-16-57-28-Composability
:END:

We've seen some of that

Defining =infected(problem_wrapper, u)= allowed us to abstract away how to extract the compartment of interest

*** Transparency
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Transparency
:CUSTOM_ID: 2023-01-29-16-57-28-Transparency
:END:

For starters, almost all the code you'll end up using is pure Julia

Hence, you can always look at the code

You can find the implementation by using =@which=

#+begin_src julia 
# Without arguments
@which sum
#+end_src

#+RESULTS:
: Base

#+begin_src julia :display text/plain
# With arguments
@which sum([1.0])
#+end_src

#+RESULTS:
: sum(a::AbstractArray; dims, kw...) in Base at reducedim.jl:994

#+REVEAL: split

And yeah, you can even look into the macros

#+HTML: <div class="small-text">

#+begin_src julia 
@macroexpand @model f() = x ~ Normal()
#+end_src

#+RESULTS:
#+begin_example
quote
    function f(__model__::DynamicPPL.Model, __varinfo__::DynamicPPL.AbstractVarInfo, __context__::AbstractPPL.AbstractContext; )
        #= In[113]:1 =#
        begin
            var"##dist#1413" = Normal()
            var"##vn#1410" = (DynamicPPL.resolve_varnames)((AbstractPPL.VarName){:x}(), var"##dist#1413")
            var"##isassumption#1411" = begin
                    if (DynamicPPL.contextual_isassumption)(__context__, var"##vn#1410")
                        if !((DynamicPPL.inargnames)(var"##vn#1410", __model__)) || (DynamicPPL.inmissings)(var"##vn#1410", __model__)
                            true
                        else
                            x === missing
                        end
                    else
                        false
                    end
                end
            begin
                #= /home/tor/.julia/packages/DynamicPPL/WBmMU/src/compiler.jl:539 =#
                var"##retval#1415" = if var"##isassumption#1411"
                        begin
                            (var"##value#1414", __varinfo__) = (DynamicPPL.tilde_assume!!)(__context__, (DynamicPPL.unwrap_right_vn)((DynamicPPL.check_tilde_rhs)(var"##dist#1413"), var"##vn#1410")..., __varinfo__)
                            x = var"##value#1414"
                            var"##value#1414"
                        end
                    else
                        if !((DynamicPPL.inargnames)(var"##vn#1410", __model__))
                            x = (DynamicPPL.getvalue_nested)(__context__, var"##vn#1410")
                        end
                        (var"##value#1412", __varinfo__) = (DynamicPPL.tilde_observe!!)(__context__, (DynamicPPL.check_tilde_rhs)(var"##dist#1413"), x, var"##vn#1410", __varinfo__)
                        var"##value#1412"
                    end
                #= /home/tor/.julia/packages/DynamicPPL/WBmMU/src/compiler.jl:540 =#
                return (var"##retval#1415", __varinfo__)
            end
        end
    end
    begin
        $(Expr(:meta, :doc))
        function f(; )
            #= In[113]:1 =#
            return (DynamicPPL.Model)(f, NamedTuple(), NamedTuple())
        end
    end
end
#+end_example

#+HTML: </div>

#+REVEAL: split

I told you didn't want to see that.

Can make it /a bit/ cleaner by removing linenums:

#+HTML: <div class="x-small-text">

#+begin_src julia 
@macroexpand(@model f() = x ~ Normal()) |> Base.remove_linenums!
#+end_src

#+RESULTS:
#+begin_example
quote
    function f(__model__::DynamicPPL.Model, __varinfo__::DynamicPPL.AbstractVarInfo, __context__::AbstractPPL.AbstractContext; )
        begin
            var"##dist#1419" = Normal()
            var"##vn#1416" = (DynamicPPL.resolve_varnames)((AbstractPPL.VarName){:x}(), var"##dist#1419")
            var"##isassumption#1417" = begin
                    if (DynamicPPL.contextual_isassumption)(__context__, var"##vn#1416")
                        if !((DynamicPPL.inargnames)(var"##vn#1416", __model__)) || (DynamicPPL.inmissings)(var"##vn#1416", __model__)
                            true
                        else
                            x === missing
                        end
                    else
                        false
                    end
                end
            begin
                var"##retval#1421" = if var"##isassumption#1417"
                        begin
                            (var"##value#1420", __varinfo__) = (DynamicPPL.tilde_assume!!)(__context__, (DynamicPPL.unwrap_right_vn)((DynamicPPL.check_tilde_rhs)(var"##dist#1419"), var"##vn#1416")..., __varinfo__)
                            x = var"##value#1420"
                            var"##value#1420"
                        end
                    else
                        if !((DynamicPPL.inargnames)(var"##vn#1416", __model__))
                            x = (DynamicPPL.getvalue_nested)(__context__, var"##vn#1416")
                        end
                        (var"##value#1418", __varinfo__) = (DynamicPPL.tilde_observe!!)(__context__, (DynamicPPL.check_tilde_rhs)(var"##dist#1419"), x, var"##vn#1416", __varinfo__)
                        var"##value#1418"
                    end
                return (var"##retval#1421", __varinfo__)
            end
        end
    end
    begin
        $(Expr(:meta, :doc))
        function f(; )
            return (DynamicPPL.Model)(f, NamedTuple(), NamedTuple())
        end
    end
end
#+end_example

#+HTML: </div>

#+REVEAL: split

#+begin_src julia
f(x) = 2x
#+end_src

#+RESULTS:
: f (generic function with 1 method)

You can inspect the type-inferred and lowered code

#+begin_src julia
@code_typed f(1)
#+end_src

#+RESULTS:
: CodeInfo(
: 1 ‚îÄ %1 = Base.mul_int(2, x)::Int64
: ‚îî‚îÄ‚îÄ      return %1
: ) => Int64

#+REVEAL: split

You can inspect the LLVM code

#+begin_src julia
@code_llvm f(1)
#+end_src

#+RESULTS:
: ;  @ In[115]:1 within `f`
: define i64 @julia_f_52767(i64 signext %0) #0 {
: top:
: ; ‚îå @ int.jl:88 within `*`
:    %1 = shl i64 %0, 1
: ; ‚îî
:   ret i64 %1
: }

#+REVEAL: split

And even the resulting machine code

#+begin_src julia
@code_native f(1)
#+end_src

#+RESULTS:
#+begin_example
	.text
	.file	"f"
	.globl	julia_f_52804                   # -- Begin function julia_f_52804
	.p2align	4, 0x90
	.type	julia_f_52804,@function
julia_f_52804:                          # @julia_f_52804
; ‚îå @ In[115]:1 within `f`
	.cfi_startproc
# %bb.0:                                # %top
; ‚îÇ‚îå @ int.jl:88 within `*`
	leaq	(%rdi,%rdi), %rax
; ‚îÇ‚îî
	retq
.Lfunc_end0:
	.size	julia_f_52804, .Lfunc_end0-julia_f_52804
	.cfi_endproc
; ‚îî
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
#+end_example

It really just depends on which level of "I hate my life" you're currently at

*** Calling into other languages
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Calling-into-other-languages
:CUSTOM_ID: 2023-01-29-16-57-28-Calling-into-other-languages
:END:
- [[https://docs.julialang.org/en/v1/manual/calling-c-and-fortran-code/][C and Fortran comes built-in stdlib]]
- [[https://juliainterop.github.io/RCall.jl/stable/][RCall.jl]]: call into =R=
- [[https://github.com/JuliaPy/PyCall.jl][PyCall.jl]]: call into =python=
- Etc.

When working with =Array=, etc. memory is usually shared ‚üπ fairly low overhead

*** C and Fortran
:PROPERTIES:
:ID:       2023-01-29-16-57-28-C-and-Fortran
:CUSTOM_ID: 2023-01-29-16-57-28-C-and-Fortran
:END:
#+begin_src julia 
# Define the Julia function
function mycompare(a, b)::Cint
    println("mycompare($a, $b)")  # NOTE: Let's look at the comparisons made.
    return (a < b) ? -1 : ((a > b) ? +1 : 0)
end

# Get the corresponding C function pointer.
mycompare_c = @cfunction(mycompare, Cint, (Ref{Cdouble}, Ref{Cdouble}))

# Array to sort.
arr = [1.3, -2.7, 4.4, 3.1];

# Call in-place quicksort.
ccall(:qsort, Cvoid, (Ptr{Cdouble}, Csize_t, Csize_t, Ptr{Cvoid}),
      arr, length(arr), sizeof(eltype(arr)), mycompare_c)
#+end_src

#+RESULTS:
: mycompare(1.3, -2.7)
: mycompare(4.4, 3.1)
: mycompare(-2.7, 3.1)
: mycompare(1.3, 3.1)

#+begin_src julia 
# All sorted!
arr
#+end_src

#+RESULTS:
: 4-element Vector{Float64}:
:  -2.7
:   1.3
:   3.1
:   4.4

[[https://docs.julialang.org/en/v1/manual/calling-c-and-fortran-code/#Creating-C-Compatible-Julia-Function-Pointers][Example is from Julia docs]]

*** RCall.jl                                                       :noexport:
:PROPERTIES:
:ID:       2023-01-29-16-57-28-RCall-dot-jl
:CUSTOM_ID: 2023-01-29-16-57-28-RCall-dot-jl
:END:

*** PyCall.jl                                                      :noexport:
:PROPERTIES:
:ID:       2023-01-29-16-57-28-PyCall-dot-jl
:CUSTOM_ID: 2023-01-29-16-57-28-PyCall-dot-jl
:END:

*** The Bad
:PROPERTIES:
:ID:       2023-01-29-16-57-28-The-Bad
:CUSTOM_ID: 2023-01-29-16-57-28-The-Bad
:END:
Sometimes
- your code might just slow down without a seemingly good reason,
- someone did bad, and Julia can't tell which method to call, or
- someone forces the Julia compiler to compile insane amounts of code

*** "Why is my code suddenly slow?"
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Why-is-my-code-suddenly-slow
:CUSTOM_ID: 2023-01-29-16-57-28-Why-is-my-code-suddenly-slow
:END:

One word: *type-instability*

Sometimes the Julia compiler can't quite infer what types fully

#+HTML: <div class="fragment (appear)">

*Result:* python-like performance (for those particular function calls)

#+begin_src julia 
# NOTE: this is NOT `const`, and so it could become some other type
# at any given point without `my_func` knowing about it!
global_variable = 1
my_func_unstable(x) = global_variable * x
#+end_src

#+RESULTS:
: my_func_unstable (generic function with 1 method)

#+begin_src julia 
@btime my_func_unstable(2.0);
#+end_src

#+RESULTS:
:   30.668 ns (2 allocations: 32 bytes)

#+HTML: </div>

#+REVEAL: split

Luckily there are tools for inspecting this

#+begin_src julia 
@code_warntype my_func_unstable(2.0)
#+end_src

#+RESULTS:
: MethodInstance for my_func_unstable(::Float64)
:   from my_func_unstable(x) in Main at In[121]:4
: Arguments
:   #self#::Core.Const(my_func_unstable)
:   x::Float64
: Body::Any
: 1 ‚îÄ %1 = (Main.global_variable * x)::Any
: ‚îî‚îÄ‚îÄ      return %1
: 

See that =Any= there? _'tis a big no-no!_

#+REVEAL: split

Once discovered, it can be fixed

#+begin_src julia 
const constant_global_variable = 1
my_func_fixed(x) = constant_global_variable * x
@code_warntype my_func_fixed(2.0)
#+end_src

#+RESULTS:
: MethodInstance for my_func_fixed(::Float64)
:   from my_func_fixed(x) in Main at In[124]:2
: Arguments
:   #self#::Core.Const(my_func_fixed)
:   x::Float64
: Body::Float64
: 1 ‚îÄ %1 = (Main.constant_global_variable * x)::Float64
: ‚îî‚îÄ‚îÄ      return %1
: 

So long Python performance!

#+begin_src julia 
@btime my_func_fixed(2.0);
#+end_src

#+RESULTS:
:   1.696 ns (0 allocations: 0 bytes)


#+REVEAL: split

/But/ this is not always so easy to discover (though this is generally rare)

#+begin_src julia 
# HACK: Here we explicitly tell Julia what type `my_func_unstable`
# returns. This is _very_ rarely a good idea because it just hides
# the underlying problem from `@code_warntype`!
my_func_forced(x) = my_func_unstable(x)::typeof(x)
@code_warntype my_func_forced(2.0)
#+end_src

#+RESULTS:
#+begin_example
MethodInstance for my_func_forced(::Float64)
  from my_func_forced(x) in Main at In[126]:4
Arguments
  #self#::Core.Const(my_func_forced)
  x::Float64
Body::Float64
1 ‚îÄ %1 = Main.my_func_unstable(x)::Any
‚îÇ   %2 = Main.typeof(x)::Core.Const(Float64)
‚îÇ   %3 = Core.typeassert(%1, %2)::Float64
‚îî‚îÄ‚îÄ      return %3
#+end_example

We can still see the =Any= in there, but on a first glance it looks like =my_func_forced= is type-stable

There are more natural cases where this might occur, e.g. unfortunate closures deep in your callstack

#+REVEAL: split

To discovery these there are a couple of more advanced tools:
- [[https://github.com/JuliaDebug/Cthulhu.jl][Cthulhu.jl]]: Allows you to step through your code like a debugger and perform =@code_warntype=
- [[https://github.com/aviatesk/JET.jl][JET.jl]]: Experimental package which attempts to automate the process

And even simpler: profile using [[https://github.com/timholy/ProfileView.jl][ProfileView.jl]] and look for code-paths that /should/ be fast but take up a lot of the runtime

#+REVEAL: split

#+begin_src julia 
using ProfileView
#+end_src

#+RESULTS:

#+begin_src julia :eval no
@profview foreach(_ -> my_func_unstable(2.0), 1_000_000)
#+end_src

#+DOWNLOADED: file:///tmp/Spectacle.wcviMK/Screenshot_20230125_011603.png @ 2023-01-25 01:16:13
#+ATTR_HTML: :height 350px
#+ATTR_ORG: :width 600
[[file:assets/attachments/2023-01-25_01-16-13_Screenshot_20230125_011603.png]]

Note that there's no sign of multiplication here

But most of the runtime is the =./reflection.jl= at the top there

That's Julia looking up the type at runtime

*** Method ambiguity
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Method-ambiguity
:CUSTOM_ID: 2023-01-29-16-57-28-Method-ambiguity
:END:
#+begin_src julia 
ambiguous_function(x, y::Int) = y
ambiguous_function(x::Int, y) = x

# NOTE: Here we have `ambiguous_function(x::Int, y::Int)`
# Which one should we hit?!
ambiguous_function(1, 2)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: MethodError: ambiguous_function(::Int64, ::Int64) is ambiguous. Candidates:
:   ambiguous_function(x, y::Int64) in Main at In[128]:1
:   ambiguous_function(x::Int64, y) in Main at In[128]:2
: Possible fix, define
:   ambiguous_function(::Int64, ::Int64)
: 
: Stacktrace:
:  [1] top-level scope
:    @ In[128]:6
:END:

But here Julia warns us, and so we can fix this by just doing as it says: define =ambiguous_function(::Int64, ::Int64)=

#+begin_src julia 
ambiguous_function(::Int64, ::Int64) = "neato"
ambiguous_function(1, 2)
#+end_src

#+RESULTS:
: "neato"

*** Long compilation times
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Long-compilation-times
:CUSTOM_ID: 2023-01-29-16-57-28-Long-compilation-times
:END:
In Julia, for better or worse, we can generate code

*Problem:* it can be /lots/ of code of we really want to

*Result:* first execution can be /slow/

#+HTML: <div class="fragment (appear)">

*Time to first plot (TTFP)* is Julia's worst enemy

But things are always improving

#+DOWNLOADED: file:///tmp/Spectacle.wcviMK/Screenshot_20230125_012853.png @ 2023-01-25 01:29:05
[[file:assets/attachments/2023-01-25_01-29-05_Screenshot_20230125_012853.png]]

#+HTML: </div>

*** Another example: mis-use of =@generated=
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Another-example-mis-use-of-generated
:CUSTOM_ID: 2023-01-29-16-57-28-Another-example-mis-use-of-generated
:END:

#+begin_src julia 
# NOTE: `@generated` only has access to static information, e.g. types of arguments.
# Here I'm using the special type `Val` to make a number `N` static.
@generated function unrolled_addition(::Val{N}) where {N}
    expr = Expr(:block)
    push!(expr.args, :(x = 0))
    for i = 1:N
        push!(expr.args, :(x += $(3.14 * i)))
    end

    return expr
end
#+end_src

#+RESULTS:
: unrolled_addition (generic function with 1 method)

When I call this with some =Val(N)=, Julia will execute this /at compile-time/!

#+begin_src julia 
# NOTE: At runtime, it then just returns the result immediately
@code_typed unrolled_addition(Val(10))
#+end_src

#+RESULTS:
: CodeInfo(
: 1 ‚îÄ     return 172.70000000000002
: ) => Float64

But if I just change the value =10= to =11=, it's a /completely/ different type!

#+REVEAL: split

So Julia has to compile =unrolled_addition= from scratch

#+begin_src julia 
@time @eval unrolled_addition(Val(11));
#+end_src

#+RESULTS:
:   0.010027 seconds (11.61 k allocations: 654.885 KiB, 8.32% compilation time)

Or a bit crazier

#+begin_src julia 
@time @eval unrolled_addition(Val(10_001));
#+end_src

#+RESULTS:
:   0.429549 seconds (1.19 M allocations: 48.946 MiB, 99.94% compilation time)

Here it took ~0.4s, of which 99.95% was compilation time

I think you get the idea

#+REVEAL: split

But boy is it fast to run!

#+begin_src julia 
@btime unrolled_addition(Val(10_001));
#+end_src

#+RESULTS:
:   1.637 ns (0 allocations: 0 bytes)

#+begin_src julia 
function not_unrolled_addition(N)
    x = 0
    for i = 1:N
        x += 3.14 * i
    end

    return x
end
#+end_src

#+RESULTS:
: not_unrolled_addition (generic function with 1 method)

#+begin_src julia 
@btime not_unrolled_addition(10_001);
#+end_src

#+RESULTS:
:   11.138 Œºs (0 allocations: 0 bytes)

#+REVEAL: split

*Funny side-note:* at first I did the following

#+begin_src julia 
@generated function unrolled_addition_old(::Val{N}) where {N}
    expr = Expr(:block)
    push!(expr.args, :(x = 0))
    for i = 1:N
        push!(expr.args, :(x += $i))  # NOTE: No 3.14!
    end
    return expr
end
function not_unrolled_addition_old(N)
    x = 0
    for i = 1:N
        x += i  # NOTE: No 3.14!
    end
    return x
end
#+end_src

#+RESULTS:
: not_unrolled_addition_old (generic function with 1 method)

#+begin_src julia 
@btime unrolled_addition_old(Val(10_001));
@btime not_unrolled_addition_old(10_001);
#+end_src

#+RESULTS:
:   1.538 ns (0 allocations: 0 bytes)
:   3.495 ns (0 allocations: 0 bytes)

LLVM probably recognized the pattern of =not_unrolled_addition_old= and unrolls it for us

Let's check!

#+REVEAL: split

#+begin_src julia 
# NOTE: The one LLVM failed to unroll
@code_llvm not_unrolled_addition(10_001)
#+end_src

#+RESULTS:
#+begin_example
;  @ In[135]:1 within `not_unrolled_addition`
define { {}*, i8 } @julia_not_unrolled_addition_53856([8 x i8]* noalias nocapture align 8 dereferenceable(8) %0, i64 signext %1) #0 {
top:
;  @ In[135]:3 within `not_unrolled_addition`
; ‚îå @ range.jl:5 within `Colon`
; ‚îÇ‚îå @ range.jl:393 within `UnitRange`
; ‚îÇ‚îÇ‚îå @ range.jl:400 within `unitrange_last`
     %.inv = icmp sgt i64 %1, 0
     %. = select i1 %.inv, i64 %1, i64 0
; ‚îî‚îî‚îî
  br i1 %.inv, label %L18.preheader, label %union_move16

L18.preheader:                                    ; preds = %top
;  @ In[135]:5 within `not_unrolled_addition`
; ‚îå @ range.jl:883 within `iterate`
; ‚îÇ‚îå @ promotion.jl:477 within `==`
    %.not30 = icmp eq i64 %., 1
; ‚îî‚îî
  br i1 %.not30, label %union_move, label %L51

L51:                                              ; preds = %L51, %L18.preheader
  %value_phi1032 = phi double [ %value_phi10, %L51 ], [ 3.140000e+00, %L18.preheader ]
  %value_phi431 = phi i64 [ %2, %L51 ], [ 1, %L18.preheader ]
; ‚îå @ range.jl:883 within `iterate`
   %2 = add i64 %value_phi431, 1
; ‚îî
;  @ In[135]:4 within `not_unrolled_addition`
; ‚îå @ promotion.jl:389 within `*`
; ‚îÇ‚îå @ promotion.jl:359 within `promote`
; ‚îÇ‚îÇ‚îå @ promotion.jl:336 within `_promote`
; ‚îÇ‚îÇ‚îÇ‚îå @ number.jl:7 within `convert`
; ‚îÇ‚îÇ‚îÇ‚îÇ‚îå @ float.jl:146 within `Float64`
       %3 = sitofp i64 %2 to double
; ‚îÇ‚îî‚îî‚îî‚îî
; ‚îÇ @ promotion.jl:389 within `*` @ float.jl:385
   %4 = fmul double %3, 3.140000e+00
; ‚îî
;  @ In[135] within `not_unrolled_addition`
  %value_phi10 = fadd double %value_phi1032, %4
;  @ In[135]:5 within `not_unrolled_addition`
; ‚îå @ range.jl:883 within `iterate`
; ‚îÇ‚îå @ promotion.jl:477 within `==`
    %.not = icmp eq i64 %2, %.
; ‚îî‚îî
  br i1 %.not, label %L18.union_move_crit_edge, label %L51

post_union_move:                                  ; preds = %union_move16, %union_move
  %tindex_phi1429 = phi i8 [ 2, %union_move16 ], [ 1, %union_move ]
;  @ In[135]:7 within `not_unrolled_addition`
  %5 = insertvalue { {}*, i8 } { {}* null, i8 undef }, i8 %tindex_phi1429, 1
  ret { {}*, i8 } %5

L18.union_move_crit_edge:                         ; preds = %L51
;  @ In[135]:5 within `not_unrolled_addition`
  %phi.cast = bitcast double %value_phi10 to i64
  br label %union_move

union_move:                                       ; preds = %L18.union_move_crit_edge, %L18.preheader
  %value_phi10.lcssa = phi i64 [ %phi.cast, %L18.union_move_crit_edge ], [ 4614253070214989087, %L18.preheader ]
;  @ In[135]:7 within `not_unrolled_addition`
  %6 = bitcast [8 x i8]* %0 to i64*
  store i64 %value_phi10.lcssa, i64* %6, align 8
  br label %post_union_move

union_move16:                                     ; preds = %top
  %7 = bitcast [8 x i8]* %0 to i64*
  store i64 0, i64* %7, align 8
  br label %post_union_move
}
#+end_example

#+REVEAL: split

#+begin_src julia 
# NOTE: The one LLVM seems to have unrolled.
@code_llvm not_unrolled_addition_old(10_001)
#+end_src

#+RESULTS:
#+begin_example
;  @ In[137]:9 within `not_unrolled_addition_old`
define i64 @julia_not_unrolled_addition_old_53858(i64 signext %0) #0 {
top:
;  @ In[137]:11 within `not_unrolled_addition_old`
; ‚îå @ range.jl:5 within `Colon`
; ‚îÇ‚îå @ range.jl:393 within `UnitRange`
; ‚îÇ‚îÇ‚îå @ range.jl:400 within `unitrange_last`
     %.inv = icmp sgt i64 %0, 0
     %. = select i1 %.inv, i64 %0, i64 0
; ‚îî‚îî‚îî
  br i1 %.inv, label %L18.preheader, label %L35

L18.preheader:                                    ; preds = %top
;  @ In[137]:13 within `not_unrolled_addition_old`
  %1 = shl nuw i64 %., 1
  %2 = add nsw i64 %., -1
  %3 = zext i64 %2 to i65
  %4 = add nsw i64 %., -2
  %5 = zext i64 %4 to i65
  %6 = mul i65 %3, %5
  %7 = lshr i65 %6, 1
  %8 = trunc i65 %7 to i64
  %9 = add i64 %1, %8
  %10 = add i64 %9, -1
;  @ In[137]:14 within `not_unrolled_addition_old`
  br label %L35

L35:                                              ; preds = %L18.preheader, %top
  %value_phi10 = phi i64 [ 0, %top ], [ %10, %L18.preheader ]
  ret i64 %value_phi10
}
#+end_example

*** The Ugly
:PROPERTIES:
:ID:       2023-01-29-16-57-28-The-Ugly
:CUSTOM_ID: 2023-01-29-16-57-28-The-Ugly
:END:

#+REVEAL: split

_*Reverse-mode automatic differentiation*_

ForwardDiff.jl is a pure joy, but slows down as dimensionality grows

Then one should reach for ReverseDiff.jl or Zygote.jl

#+HTML: <div class="fragment (appear)">
Most of the time it works really well, but sometimes you hit a real sharp edge

And sharp edges cut; they cut /deep/

Like _"16X slower when the function is implemented more efficiently"-deep_

#+DOWNLOADED: file:///tmp/Spectacle.wcviMK/Screenshot_20230125_010111.png @ 2023-01-25 01:01:31
[[file:assets/attachments/2023-01-25_01-01-31_Screenshot_20230125_010111.png]]

#+HTML: </div>

#+HTML: <div class="fragment (appear)">

If you want to see a man in pain, you can find the full issue [[https://github.com/TuringLang/Turing.jl/issues/1934][here]]

On the flip-side, once addressed (a type-instability), it's [[https://github.com/TuringLang/DistributionsAD.jl/pull/231][3X faster than before]]

#+HTML: </div>

*** Overall
:PROPERTIES:
:ID:       2023-01-29-16-57-28-Overall
:CUSTOM_ID: 2023-01-29-16-57-28-Overall
:END:

Julia is pretty darn awesome

Easy to get going, and you can always make it faster by just optimizing _Julia_ code

No need to drop down to C++

#+REVEAL: split
Buuuut it can't beat Python at deep learning

#+REVEAL: split
Otherwise, it's worth a try

Godspeed to you

* Fin

* Going fast                                                       :noexport:
:PROPERTIES:
:header-args:julia: :tangle no
:END:

#+begin_src julia :exports none
using TorsWorkshop, Turing, StatsPlots
#+end_src

#+RESULTS:

Consider the following item-response model

#+begin_src julia
using StatsFuns

@model function irt(y, i, p; I = maximum(i), P = maximum(p))
    theta ~ filldist(Normal(), P)
    beta ~ filldist(Normal(), I)

    for n in eachindex(y)
        y[n] ~ Bernoulli(logistic(theta[p[n]] - beta[i[n]]))
    end

    return (; theta, beta, y)
end
#+end_src

#+RESULTS:
: irt (generic function with 2 methods)

Throughout this tutorial, we will see how we can improve this model step-by-step and make it run /much/ faster.

But before we do that, let's simulate some data so we can test our models.

#+begin_src julia 
P = 100   # number of users
I = 3     # number of items
N = I * P # number of observations
i_and_p = vec(collect(Iterators.product(1:I, 1:P)))
i = map(first, i_and_p); p = map(last, i_and_p);
model_generation = irt(Vector{Union{Missing,Int}}(missing, N), i, p)
#+end_src

#+RESULTS:
: Model(
:   args = (:y, :i, :p)
:   defaults = (:I, :P)
:   context = DynamicPPL.DefaultContext()
: )

#+begin_src julia :results scalar
theta_true, beta_true, y = model_generation()
#+end_src

#+RESULTS:
: (theta = [-0.8125131033205886, 0.40222461650587743, 0.4847315071119002, 0.4334098121490582, 1.2448742400518944, 0.026456640814830863, 0.1125570605015704, -0.03663608541182643, -0.2797565154042482, 1.2019992206388352  ‚Ä¶  1.9895510032951704, 1.5619189619672569, 1.5726087337065626, 0.11589158272898376, 0.1920180971700441, 1.0391944034277607, 0.5389881966315481, -0.8299382479664033, 0.06017106559407176, 0.13481559604773133], beta = [0.31975216222261077, -0.3608499802930717, 1.5117710713737413], y = Union{Missing, Int64}[1, 0, 0, 0, 1, 0, 1, 1, 0, 0  ‚Ä¶  0, 0, 0, 1, 1, 1, 1, 0, 1, 1])

#+begin_src julia :results scalar
# `y` has `eltype` `Union{Missing,Int}`, so let's just make this a vector of `Int`s
y = map(identity, y)
#+end_src

#+RESULTS:
#+begin_example
300-element Vector{Int64}:
 1
 0
 0
 0
 1
 0
 1
 1
 0
 0
 0
 0
 1
 ‚ãÆ
 1
 1
 0
 0
 0
 1
 1
 1
 1
 0
 1
 1
#+end_example

And then we can =condition= the model on the data to try and infer the true parameters

#+begin_src julia :results scalar :async yes
model = irt(y, i, p)
chain = sample(model, NUTS(), 1000);
#+end_src

#+RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mFound initial step size
: [36m[1m‚îî [22m[39m  œµ = 0.8
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:05[39m
:

Let us remind ourselves of the true parameters

#+begin_src julia :results scalar
beta_true
#+end_src

#+RESULTS:
: 3-element Vector{Float64}:
:   0.31975216222261077
:  -0.3608499802930717
:   1.5117710713737413

And compare them to the inferred parameters

#+begin_src julia :results scalar
density(group(chain, :beta))
#+end_src

#+RESULTS:
[[file:assets/outputs/more-julia/57117de3e36d8de7f9e01b01af01e3b1fdeae3d7.svg]]

Okay neat, so the inference seems to have worked.

** Improvement #1: =BernoulliLogit= instead of =Bernoulli= and =logistic=

The first improvement is a simple one: instead of using =Bernoulli= and =logistic=, we can use =BernoulliLogit=, which is a more efficient implementation of the same thing.

=BernoulliLogit= should be:
1. Faster.
2. Numerically more stable.

#+begin_src julia 
@model function irt_01(y, i, p; I = maximum(i), P = maximum(p))
    theta ~ filldist(Normal(), P)
    beta ~ filldist(Normal(), I)

    for n in eachindex(y)
        y[n] ~ BernoulliLogit(theta[p[n]] - beta[i[n]])
    end

    return (; theta, beta, y)
end
#+end_src

#+RESULTS:
: irt_01 (generic function with 2 methods)

#+begin_src julia :async yes
model_01 = irt_01(y, i, p)
chain = sample(model_01, NUTS(), 1000);
#+end_src

#+RESULTS:
: [36m[1m‚îå [22m[39m[36m[1mInfo: [22m[39mFound initial step size
: [36m[1m‚îî [22m[39m  œµ = 0.8
: [32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:05[39m
:

Okay, so it doesn't seem to be so much faster that we notice it in the actual sampling time.

But if we want to make sure, we can perform some benchmarks! For this we'll use [[https://github.com/TuringLang/TuringBenchmarking.jl][=TuringBenchmark.jl=]].

** TuringBenchmarking.jl

#+begin_src julia 
using TuringBenchmarking
#+end_src

#+RESULTS:

Equipped with this, we can easily check the performance of the original model

#+begin_src julia :async yes
# Limit ourselves to `ForwardDiff` since this is what we used above.
benchmark_model(model, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(7.500 Œºs)
	  "standard" => Trial(7.436 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(135.579 Œºs)
		  "standard" => Trial(135.739 Œºs)
#+end_example

And then of the model with =BernoulliLogit=

#+begin_src julia :async yes
benchmark_model(model_01, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(8.516 Œºs)
	  "standard" => Trial(8.039 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(122.274 Œºs)
		  "standard" => Trial(106.949 Œºs)
#+end_example

Look at that! The =gradient= computations are indeed slightly faster! We're not looking at much, but that's a solid ~10% improvement so we're going to take that.

/But/ all of these computations are only for =3= items and =100= users, which resulted in =300= observations; what happens when the dimensionality increases to, say, =20= items and =1_000= users, i.e. =20_000= observations?

Before we check, we make a few observations about the performances above:
1. =gradient= computation is roughly 15-20X slower than =evaluation=.
   - This will be a useful metric to keep track of as we increase the dimensionality.
2. =linked= computation is roughly 10-15% faster than =standard=.
   - The =linked= computation includes the transformation from unconstrained to constrained parameters.
   - Most gradient-based samplers, e.g. =HMC= and =NUTS=, need to work in unconstrained space, so this is the main runtime we'll be looking at.
   - Even though =linked= is what we really care about, it's useful to keep an eye out for a large discrepancy between =linked= and =standard=, as this would indicate that the transformation is expensive relative to the model itself, which shouldn't /usually/ be the case (exceptions exist).

** Increasing dimensionality

#+begin_src julia :results scalar
P = 1_000   # number of users
I = 20     # number of items
N = I * P # number of observations
i_and_p = vec(collect(Iterators.product(1:I, 1:P)))
i = map(first, i_and_p); p = map(last, i_and_p);
model_generation = irt(Vector{Union{Missing,Int}}(missing, N), i, p)
theta_true, beta_true, y = model_generation()
y = map(identity, y) # convert to Vector{Int}
length(theta_true), length(beta_true), length(y)
#+end_src

#+RESULTS:
: (1000, 20, 20000)

Let's now see how our two models perform on this new data.

#+begin_src julia :async yes
model = irt(y, i, p)
benchmark_model(model, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(400.827 Œºs)
	  "standard" => Trial(400.451 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(59.337 ms)
		  "standard" => Trial(57.017 ms)
#+end_example

#+begin_src julia :async yes
model_01 = irt_01(y, i, p)
benchmark_model(model_01, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(522.404 Œºs)
	  "standard" => Trial(590.827 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(43.888 ms)
		  "standard" => Trial(44.386 ms)
#+end_example

Okay, that is /much/ slower. A few observations:
1. =evaluation= computation is roughly 100X larger than before.
2. =gradient= computation is roughly 100X slower than =evaluation=.
   - This is a huge increase from the 15-20X we saw before.

/But/ is this surprising?
1. Not particularly so. We increased the number of observations from =300= to =20_000=, i.e. a 1000X increase, the number of parameters from =3 + 100= to =1_000 + 20=, i.e. ~3X increase, hence it's not too surprising that the computation is now taking ~100X longer.
2. This is maybe a bit more surprising, /but/ forward-mode AD is known to scale poorly with increasing dimensionality in the number of parameters (keeping the number of outputs fixed), so this is not too surprising either.

So, what can we do here?

(1) requires optimizing the underlying computations, but given how simple our model is, this is probably not what we should try first.

(2) seems like something we can easily improve on: let's try using reverse-mode AD instead.

** Improvement #2: Reverse-mode AD

A few reverse-mode AD backends are supported in Turing.jl:
- ReverseDiff.jl
- Zygote.jl
- Tracker.jl (though this is being phased out)

Given that Tracker.jl is being phased out, we'll focus on the first two.

Doing a deep-dive on how the different backends work and their differences is beyond the scope of this tutorial, but it's worth pointing out some simple differences between ReverseDiff.jl and Zygote.jl.

*** ReverseDiff.jl

ReverseDiff.jl is a tape-based AD system, i.e. it records the computation as it happens and then computes the gradient by traversing the tape in reverse.

Moreover, the type of computations that are actually recorded is limited. For example

#+begin_src julia 
using ReverseDiff: ReverseDiff
#+end_src

#+RESULTS:

#+begin_src julia
f(x) = 2 .* x
g(x) = sum(f(x))
#+end_src

#+RESULTS:
: g (generic function with 1 method)

#+begin_src julia
tape = ReverseDiff.GradientTape(g, ([1.0],))
#+end_src

#+RESULTS:
: typename(ReverseDiff.GradientTape)(g)

#+begin_src julia
tape.tape
#+end_src

#+RESULTS:
#+begin_example
2-element Vector{ReverseDiff.AbstractInstruction}:
 SpecialInstruction((broadcast, *)):
  input:  (2,
           [TrackedReal<IMM>(1.0, 0.0, 62v, 1, 7yl)])
  output: [TrackedReal<CEM>(2.0, 0.0, 62v, 1, 12c)]
  cache:  (nothing,
           CartesianIndex(1,))
 SpecialInstruction(sum):
  input:  [TrackedReal<I6g>(2.0, 0.0, 62v, 1, 12c)]
  output: TrackedReal<onZ>(2.0, 0.0, 62v, ---)
  cache:  nothing
#+end_example

Here we see that the tape has only recorded /two/ operations:
1. =broadcast=, which is a special instruction that is used to record element-wise operations.
2. =sum=, which is a special instruction that is used to record reductions.

Importantly, there are _no instructions referencing =g= nor =f=!_ But this makes sense: we don't need to know that =sum= occurs in =g=, nor that =broadcast= occurs in =f=, we just need to know that these operations occurred and what their inputs and outputs were. Hence, that's all ReverseDiff.jl records in its tape.

To compute the gradient of =g= wrt. =[1.0]=, the above tape is traversed and each of the instructions has a special pullback that is executed to eventually bring the gradient back to the inputs.

**** Tape compilation

As we will see, ReverseDiff.jl has two "modes" of operation: an interpreted mode and a compiled mode.

The default is the "interpreted" mode, which just means that the tape we saw above is /not/ compiled but interpreted. In effect, it just means that Julia will treat the tape as a =Vector{Any}=, and so every pullback call will be a dynamic dispatch.

This is not ideal, so we can instead compile the tape, which will result in a concretely type =Vector=, where each function is the pullback for the corresponding instruction. This will then allow Julia to do static dispatch, which will be much faster.

The *downside* of the compiled mode is that it does /not/ support conditional statements! Consider the following example:

#+begin_src julia 
h(x) = sum(x) > 0 ? 2 .* x : x
#+end_src

#+RESULTS:
: h (generic function with 1 method)

#+begin_src julia
# `sum(x) > 0` here so we get the first branch
ReverseDiff.GradientTape(h, ([1.0],)).tape
#+end_src

#+RESULTS:
#+begin_example
2-element Vector{ReverseDiff.AbstractInstruction}:
 SpecialInstruction(sum):
  input:  [TrackedReal<DrI>(1.0, 0.0, JTv, 1, 4fG)]
  output: TrackedReal<99F>(1.0, 0.0, JTv, ---)
  cache:  nothing
 SpecialInstruction((broadcast, *)):
  input:  (2,
           [TrackedReal<Bmd>(1.0, 0.0, JTv, 1, 4fG)])
  output: [TrackedReal<Gsu>(2.0, 0.0, JTv, 1, Emj)]
  cache:  (nothing,
           CartesianIndex(1,))
#+end_example

#+begin_src julia
# `sum(x) < 0` here so we get the second branch
ReverseDiff.GradientTape(h, ([-1.0],)).tape
#+end_src

#+RESULTS:
: 1-element Vector{ReverseDiff.AbstractInstruction}:
:  SpecialInstruction(sum):
:   input:  [TrackedReal<4eI>(-1.0, 0.0, FPK, 1, 3Ak)]
:   output: TrackedReal<LoT>(-1.0, 0.0, FPK, ---)
:   cache:  nothing

_The tape changes with the input!_

This is not a problem when we're working in "interpreted mode" because in that scenario, we will re-record the tape everytime we call it on a new input.

But when we work in "compiled mode", we will execute record the tape /once/, compile it, and then execute the same (compiled) tape over and over again /for different inputs/!

Hence, if there are conditionals like the above in our function, the gradient computations could easily end up being incorrect if we decide to compile the tape.

*** TODO Zygote.jl

** Speed

/But/ this was only for =3= items and =100= users, which resulted in =300= observations and it already took us 5s.

What if we had =20= items and =1_000= users, i.e. =20_000= observations?

Sure, we could just run inference and check, but an alternative is to just benchmark the important computations using [[https://github.com/TuringLang/TuringBenchmarking.jl][=TuringBenchmark.jl=]]

#+begin_src julia 
using TuringBenchmarking
#+end_src

#+RESULTS:

Equipped with this, we can easily check the performance of the model

#+begin_src julia :async yes
# Limit ourselves to `ForwardDiff` first since this is what we used above.
benchmark_model(model, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(7.647 Œºs)
	  "standard" => Trial(7.581 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(155.313 Œºs)
		  "standard" => Trial(155.458 Œºs)
#+end_example

Here we see that the gradient computation takes roughly 20X the time of the evaluation; this is a useful metric to look at when trying to gauge whether we can gain anything from, say, switching AD backend. 20X is not too crazy, so we will stick with =ForwardDiff= for now.

** How long will =NUTS= take?

Using these numbers we can calculate a rough upper-bound on how long =NUTS= should take.
- =NUTS= with a =max_tree_depth= of =10= (which is the default), means we will /at most/ perform =2^10= leapfrog steps.
- Each leapfrog step requires a single evaluation of the model and its gradient.

Hence, if we want to perform, say, 1000 iterations, then

#+begin_src julia 
using Unitful
#+end_src

#+RESULTS:

#+begin_src julia
nuts = NUTS()
nuts.max_depth
#+end_src

#+RESULTS:
: 10

#+begin_src julia
num_iterations = 1_000
time_per_gradient = 155u"Œºs"
time_per_iteration = time_per_gradient * 2^nuts.max_depth

# Total sampling time is then:
uconvert(u"s", float(num_iterations * time_per_iteration))
#+end_src

#+RESULTS:
: 158.72 s

Let's just convert the above into a function while we're at it

#+begin_src julia 
function maximum_runtime_nuts(nuts::NUTS, time_per_gradient, num_iterations)
    time_per_iteration = time_per_gradient * 2^nuts.max_depth
    return uconvert(u"s", float(num_iterations * time_per_iteration))
end

maximum_runtime_nuts(nuts, time_per_gradient, num_iterations)
#+end_src

#+RESULTS:
: 158.72 s

Clearly we didn't need ~160s in the above call to =sample=, so we most certainly didn't perform the full =2^10= leapfrog steps at every iteration.

We can inspect this

#+begin_src julia :display text/plain
MCMCChains.get_sections(chain, :internals)
#+end_src

#+RESULTS:
#+begin_example
Chains MCMC chain (1000√ó12√ó1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 4.9 seconds
Compute duration  = 4.9 seconds
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
                    parameters        mean       std      mcse    ess_bulk     ‚ãØ
                        Symbol     Float64   Float64   Float64     Float64     ‚ãØ

                            lp   -299.4536    7.4833    0.3839    378.9357     ‚ãØ
                       n_steps      7.0000    0.0000       NaN         NaN     ‚ãØ
                     is_accept      1.0000    0.0000       NaN         NaN     ‚ãØ
               acceptance_rate      0.8079    0.1646    0.0050   1120.9592     ‚ãØ
                   log_density   -299.4536    7.4833    0.3839    378.9357     ‚ãØ
            hamiltonian_energy    351.1155   10.6849    0.5821    334.9187     ‚ãØ
      hamiltonian_energy_error      0.0025    0.5267    0.0114   2092.6571   1 ‚ãØ
  max_hamiltonian_energy_error      0.2286    0.8456    0.0259   1066.4405     ‚ãØ
                    tree_depth      3.0000    0.0000       NaN         NaN     ‚ãØ
               numerical_error      0.0000    0.0000       NaN         NaN     ‚ãØ
                     step_size      0.5232    0.0000    0.0000         NaN     ‚ãØ
                 nom_step_size      0.5232    0.0000    0.0000         NaN     ‚ãØ
                                                               3 columns omitted

Quantiles
                    parameters        2.5%       25.0%       50.0%       75.0% ‚ãØ
                        Symbol     Float64     Float64     Float64     Float64 ‚ãØ

                            lp   -315.5843   -304.2502   -298.9775   -294.0920 ‚ãØ
                       n_steps      7.0000      7.0000      7.0000      7.0000 ‚ãØ
                     is_accept      1.0000      1.0000      1.0000      1.0000 ‚ãØ
               acceptance_rate      0.4489      0.7020      0.8355      0.9554 ‚ãØ
                   log_density   -315.5843   -304.2502   -298.9775   -294.0920 ‚ãØ
            hamiltonian_energy    332.6281    343.4749    350.6393    357.9514 ‚ãØ
      hamiltonian_energy_error     -1.1342     -0.3142      0.0001      0.3238 ‚ãØ
  max_hamiltonian_energy_error     -1.4096     -0.5314      0.4361      0.8492 ‚ãØ
                    tree_depth      3.0000      3.0000      3.0000      3.0000 ‚ãØ
               numerical_error      0.0000      0.0000      0.0000      0.0000 ‚ãØ
                     step_size      0.5232      0.5232      0.5232      0.5232 ‚ãØ
                 nom_step_size      0.5232      0.5232      0.5232      0.5232 ‚ãØ
                                                                1 column omitted
#+end_example

Here we see that =n_steps= is on average =7= (in fact, it seems to be /constantly/ =7=).
And so we can see that we indeed should be spending much less than ~160s to obtain our chain.

Note that in the above, we have actually performed 1000 + 500 iterations since we have a warmup phase of 500 iterations.
In addition, the above chain does not include the statistics from those initial 500 iterations, so it could be that the average number of leapfrog steps is higher than =7=.

Nonetheless, the above analysis is useful to gaige roughly how long we should expect =NUTS= to take.

So. With this in mind, when we're trying to figure out which way to express our model, we really only need to consider the time it takes to evaluate the log-joint probability and its the gradient.

** Back to benchmarking

Now, let's try and increase to our hypothetical =20= items and =1_000= users as we mentioned before, and see what this does to our runtime.

#+begin_src julia 
P = 1_000   # number of users
I = 20      # number of items
N = I * P   # number of observations
i_and_p = vec(collect(Iterators.product(1:I, 1:P)))
i = map(first, i_and_p); p = map(last, i_and_p);
model_generation = irt(Vector{Union{Missing,Int}}(missing, N), i, p)

# Generate some data.
theta_true, beta_true, y = model_generation()
y = map(identity, y);

# Condition on the data.
model = irt(y, i, p)
#+end_src

#+RESULTS:
: Model(
:   args = (:y, :i, :p)
:   defaults = (:I, :P)
:   context = DynamicPPL.DefaultContext()
: )

#+begin_src julia
benchmark_model(model, adbackends=[:ForwardDiff], verbose=false)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(456.722 Œºs)
	  "standard" => Trial(455.808 Œºs)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(61.859 ms)
		  "standard" => Trial(61.893 ms)
#+end_example

Okay, so that's quite the increase in the runtime for the gradient evaluation: it went 20X the evaluation time to now 120X the evaluation time!
If we were to run =NUTS= for this model, we would potentially be looking at

#+begin_src julia 
uconvert(u"hr", maximum_runtime_nuts(nuts, 61.859u"ms", num_iterations))
#+end_src

#+RESULTS:
: 17.59544888888889 hr

That's quite long.

** Can we do better?

This far, we've only been using the default =ForwardDiff= backend for automatic differentiation.
As we saw, there was a drastic increase in the difference between the evaluation time and the gradient time once we increased the dimensionality of the problem.
This sort of behavior is very typical for forward-mode automatic differentiation (AD) approaches: these scale poorly with increasing dimensionality in the input (assuming the dimensionality of the output is fixed).

In contrast, reverse-mode AD have, generally speaking, much better scaling properties for the input dimensionality.
And in Julia, we have several reverse-mode AD packages available to us:
- ReverseDiff.jl
- Zygote.jl
- Tracker.jl

Let's give ReverseDiff.jl and Zygote.jl a go and see how they compare to ForwardDiff.jl.

#+begin_src julia 
results = benchmark_model(
    model,
    adbackends=[:ForwardDiff, :ReverseDiff, :ReverseDiff_compiled, :Zygote];
    verbose=false
)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(475.519 Œºs)
	  "standard" => Trial(475.309 Œºs)
  "gradient" => 4-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ReverseDiffAD{false}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(17.669 ms)
		  "standard" => Trial(17.599 ms)
	  "Turing.Essential.ReverseDiffAD{true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(6.165 ms)
		  "standard" => Trial(5.637 ms)
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(65.857 ms)
		  "standard" => Trial(65.289 ms)
	  "Turing.Essential.ZygoteAD()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["Zygote"]
		  "linked" => Trial(1.916 s)
		  "standard" => Trial(1.915 s)
#+end_example

Pffft, here we see /lots/ of variability! We can use =@tagged= from BenchmarkTools.jl, which is re-exported from TuringBenchmarking.jl, to filter out the results we're interested in.

#+begin_src julia 
results[@tagged :Zygote]
#+end_src

#+RESULTS:
: 1-element BenchmarkTools.BenchmarkGroup:
:   tags: []
:   "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
: 	  tags: []
: 	  "Turing.Essential.ZygoteAD()" => 2-element BenchmarkTools.BenchmarkGroup:
: 		  tags: ["Zygote"]
: 		  "linked" => Trial(1.916 s)
: 		  "standard" => Trial(1.915 s)

Wow, this is even /slower/ than ForwardDiff; we're looking at a ~40X increase in the runtime for the gradient computation!

In fact, this is not too surprising: Zygote is, for reasons that are beyond the scope of this tutorial, particularly slow for models involving for-loops, which we do have in our =itr= model.

In contrast, ReverseDiff.jl does a much better job with this model:

#+begin_src julia 
results[@tagged :ReverseDiff]
#+end_src

#+RESULTS:
#+begin_example
1-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "gradient" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ReverseDiffAD{false}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(17.669 ms)
		  "standard" => Trial(17.599 ms)
	  "Turing.Essential.ReverseDiffAD{true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(6.165 ms)
		  "standard" => Trial(5.637 ms)
#+end_example

Note that we have two different results for ReverseDiff.jl:
- =ReverseDiffAD{false}= is ReverseDiff.jl /without/ compilation of the resulting tape.
- =ReverseDiffAD{true}= is ReverseDiff.jl /with/ compilation of the resulting tape.

As we see above, compilation gets us a ~3X speedup in the gradient computation vs. not compiling the tape, /but/ both approaches are still much, much faster than ForwardDiff.jl (and most certainly Zygote.jl)!

If we redo our calculation for "how long does NUTS take" with =ReverseDiffAD{true}=, we now instead get

#+begin_src julia
uconvert(u"hr", maximum_runtime_nuts(nuts, 6.165u"ms", num_iterations))
#+end_src

#+RESULTS:
: 1.7536 hr

That is /much/ better than 18 hours!

** Can we do better?

So we've identified ReverseDiff.jl with tape-compilation as our best bet for automatic differentiation for this particular model, but can we improve it even further?

For example, can we maybe implement the model in a slightly different way that would make it easier for the AD package to compute the gradient?

*** Avoiding for-loops

#+begin_src julia 
@model function irt_01(y, i, p; I = maximum(i), P = maximum(p))
    theta ~ filldist(Normal(), P)
    beta ~ filldist(Normal(), I)

    # NOTE: We've now replaced the for-loop with a single multivariate distribution
    y ~ product_distribution(Bernoulli.(logistic.(theta[p] .- beta[i])))

    return (; theta, beta, y)
end

model_01 = irt_01(y, i, p)
#+end_src

#+RESULTS:
: Model(
:   args = (:y, :i, :p)
:   defaults = (:I, :P)
:   context = DynamicPPL.DefaultContext()
: )

#+begin_src julia :async yes
results_01 = benchmark_model(
    model_01,
    adbackends=[:ForwardDiff, :ReverseDiff, :ReverseDiff_compiled, :Zygote];
    verbose=false
)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Trial(356.451 Œºs)
	  "standard" => Trial(355.911 Œºs)
  "gradient" => 4-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ReverseDiffAD{false}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(10.077 ms)
		  "standard" => Trial(10.758 ms)
	  "Turing.Essential.ReverseDiffAD{true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Trial(6.610 ms)
		  "standard" => Trial(4.262 ms)
	  "Turing.Essential.ForwardDiffAD{40, true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ForwardDiff"]
		  "linked" => Trial(131.610 ms)
		  "standard" => Trial(130.713 ms)
	  "Turing.Essential.ZygoteAD()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["Zygote"]
		  "linked" => Trial(61.949 ms)
		  "standard" => Trial(61.957 ms)
#+end_example

Here we see a few differences from our previous benchmarks:
- ForwardDiff.jl is even worse now.
- ReverseDiff.jl is also worse, albeit only slightly!
- Zygote.jl has improved by, well, /a lot/. We went from almost 2s down to ~60ms, which is almost 40X faster!

Now, it's fair to ask the question: is any of surprising?
- The fact that Zygote.jl has improved now that we've removed the for-loop in favour of a multivariate distribution is /not/ surprising; as we said, for-loop are bad for Zygote.jl.
- But it /is/ surprising that ReverseDiff.jl (and ForwardDiff.jl) are now slower than before; we would expect the broadcasted statement to be faster than a for-loop, so why should the gradient computation then suddenly be slower?
  - One thing to notice here is that only the /linked/ version of ReverseDiff.jl is slower; the /standard/ version is actually faster than before. This indicates that the problem lies with the transformations Turing applies to move the parameters from constrained to unconstrained space. 

To understand this, we need to do some _profiling_.

*** Profiling the gradient computation

Julia comes with [[https://docs.julialang.org/en/v1/manual/profile/][built-in profiling capabilities]], but, as mentioned in the official docs, viewing the profiling results is probably best done using an external package.

In the following, I will use [[https://github.com/JuliaPerf/PProf.jl][PProf.jl]] which lets you view the profiling results in a web browser.

First let us profile ReverseDiff.jl, which was the fastest but then got slower once we introduced the array-based distribution, which we intuitlvey expected to be faster.

BenchmarkTools.jl provides us with a convenient way of profiling a function, so let's use that.

#+begin_src julia
# 1. Construct the benchmarking suite for our model with ReverseDiff.jl
suite_01 = TuringBenchmarking.make_turing_suite(
    model_01,
    adbackends=[:ReverseDiff_compiled];
)
#+end_src

#+RESULTS:
#+begin_example
2-element BenchmarkTools.BenchmarkGroup:
  tags: []
  "evaluation" => 2-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "linked" => Benchmark(evals=1, seconds=5.0, samples=10000)
	  "standard" => Benchmark(evals=1, seconds=5.0, samples=10000)
  "gradient" => 1-element BenchmarkTools.BenchmarkGroup:
	  tags: []
	  "Turing.Essential.ReverseDiffAD{true}()" => 2-element BenchmarkTools.BenchmarkGroup:
		  tags: ["ReverseDiff"]
		  "linked" => Benchmark(evals=1, seconds=5.0, samples=10000)
		  "standard" => Benchmark(evals=1, seconds=5.0, samples=10000)
#+end_example

#+begin_src julia
# 2. Extract the benchmark of interest.
b = suite_01["gradient"]["Turing.Essential.ReverseDiffAD{true}()"]["linked"]
#+end_src

#+RESULTS:
: Benchmark(evals=1, seconds=5.0, samples=10000)

#+begin_src julia
using BenchmarkTools, PProf
# 3. Set up the benchmarking environment.
BenchmarkTools.warmup(b)
#+end_src

#+RESULTS:
: BenchmarkTools.Trial: 1 sample with 1 evaluation.
:  Single result which took 7.954 ms (0.00% GC) to evaluate,
:  with a memory estimate of 8.16 KiB, over 2 allocations.

#+begin_src julia
# 4. Clear the profiling data.
BenchmarkTools.Profile.clear()
# 5. Profile the running of the benchmark.
@pprof BenchmarkTools.run(b; seconds=30, gctrial=false, gcsample=false)
#+end_src

#+RESULTS:
: "profile.pb.gz"


